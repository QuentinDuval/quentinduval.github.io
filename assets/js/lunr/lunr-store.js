var store = [{
        "title": "Open Recursion (Haskell)",
        "excerpt":"There is a large class of problems that we can solve by nice mathematical recurrence relations.   The recurrence is usually simple to read, to reason about, and describes the solution with concision. But a naive translation of this recurrence into code will very often lead to a very inefficient algorithm.   When the sub-problems of the recurrence relation form a DAG, the usual trick is to use Dynamic Programming to speed up the computation. But it often results in a complete change of the code, hiding the recurrence, sometimes to the point we cannot recognize the problem anymore.   Thankfully, with open recursion, can have the best of both worlds!   Counting Binary Search Trees   Before introducing the technique, let us first take a nice example whose solution can be described by a simple recurrence relation: counting binary search trees.   We observe that we can cut any collection [X1, X2 .. Xn] in two parts, around one of its element Xi. Then, we can:      Recursively count all BST on the left part [X1 .. Xi).   Recursively count all BST on the right part (Xi .. Xn]   Multiply these values to get the count of BST rooted in Xi.   As we have to do this for all i in [1..N], the recurrence relation becomes:   bstCount :: Int -&gt; Integer bstCount n   | n &lt;= 1 = 1   | otherwise = sum [bstCount i * bstCount (n-1-i) | i &lt;- [0..n-1]]   But this algorithm is terribly inefficient: we keep recomputing the same sub-solutions over an over again.   We know the next step, which is to memoize the solutions to the sub-problems. However, as our original goal was to do it without compromising the code readability, let us first introduce open recursion.   Adding Open Recursion   Open recursion consists of avoiding direct recursion by adding an extra layer of indirection. It typically means transforming our recurrence relation to take a new parameter, a function that will be called instead of recurring.   By doing so, the recurrence formula looses its recursive nature. Here is how it would translate into Haskell:   bstCount :: (Int -&gt; Integer) -&gt; Int -&gt; Integer bstCount rec n   | n &lt;= 1 = 1   | otherwise = sum [rec i * rec (n-1-i) | i &lt;- [0..n-1]]   How can we get our recurrence relation back? By introducing a wrapper function that will give itself to the “bstCount” recurrence. Instead of having a direct recursion, we have a two-step recursion. This is best explained by example:   bstCountNaive :: Int -&gt; Integer bstCountNaive = bstCount bstCountNaive   By simple renaming, we can see that it can be expressed as: x = f x. So the naive recursive algorithm we had earlier is effectively the fixed point of the open recurrence relation. Which can be written in Haskell as:   import Data.Function(fix)   bstCountNaive :: Int -&gt; Integer bstCountNaive = fix bstCount   Adding memoization   We can now exploit this open recursion to insert some memoization in the middle of the recursion. In our specific case, the sub-problems exhibit a simple structure:      We can compute a vector of the results of each sub-problem 0..N   Then recurring part consist in indexing into this vector in O(1)   So instead of triggering a recursion, we search the sub-solution result into our memoization vector, which translates into the following Haskell code:   memoBstCount :: Int -&gt; Integer memoBstCount n = Vector.last memo   where     memo = Vector.generate (n+1) (bstCount (memo Vector.!))   How can it even work? You are witnessing here the magic of Haskell: laziness helps us refer to the item we are computing inside its own computation.   Following this change, at each N we now have N-1 steps to perform, each taking constant time, thanks to memoization. This gives us a quadratic complexity (the result of the sum from 1 to N).   Conclusion   Using open recursion in combination with Haskell laziness has effectively let us decoupled the following aspects:   The recurrence relation, solution to our problem The memoization strategy, indexing into a vector The order in which we compute these sub-solutions As a result, we get all the benefits of having a simple recurrence relation, untainted by the implementation details required to get an efficient implementation.   In the next post, we will see how to apply this trick in a more mainstream language: C++.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2016/11/27/open-recursion-haskell.html",
        "teaser": null
      },{
        "title": "Open Recursion (C++)",
        "excerpt":"In the previous post, we explored how we could leverage open recursion to solve a dynamic programming problem, while keeping the following aspect decoupled:      The recurrence relation: the solution to our problem   The memoization strategy: indexing into a vector   The order in we compute the sub-solutions   Today we will see how to apply this trick in a more mainstream language, C++.   Open recursion in C++   Our first step will be to translate the recurrence formula into a naive C++ and very inefficient implementation of our solution to the counting binary search trees problem:   long long bst_count(int n) {     if (n &lt;= 1) return 1;       long long sub_counts = 0;     for (int i = 0; i &lt; n; ++i)         sub_counts += bst_count(i) * bst_count(n-1-i);     return sub_counts; }   Adding open recursion results in a pretty simple change for our C++ implementation:      Adding a template parameter “recur” as first argument   Replace each recursive call by a call to “recur”   Following this recipe leads to the following C++ implementation:   template&lt;typename Recur&gt; long long bst_count(Recur recur, int n) { ­    if (n &lt;= 1) return 1;       long long sub_counts = 0;     for (int i = 0; i &lt; n; ++i)         sub_counts += recur(i) * recur(n-1-i);     return sub_counts; }   Similar to what we did in Haskell, we can get back back the naive algorithm by introducing a wrapper function handling the two step recursion:   long long best_count_naive(int n) {    auto recur = [](int k) { return best_count_naive(k); };    return bst_count(recur, n); }   This function still has the same terrible performance. It is time to improve our algorithm, by leveraging Dynamic Programming techniques.   Adding memoization   You know the drill: we can now exploit this open recursion to insert some memoization in the middle in the recursion.   We will use the same memoization strategy we used previously: indexing into a vector to seek the results of our previously computed sub-solutions.   long long bst_count_memo(int n) {     std::vector&lt;long long&gt; memo_table(n+1);     for (int i = 0; i &lt;= n; ++i)         memo_table[i] = bst_count([&amp;](int k) { return memo_table[k]; }, i);     return memo_table.back(); }   Even if we ignore the integer overflow issue (let us imagine we use a unbounded integer representation), there is still a big difference between this C++ implementation and the corresponding implementation in Haskell:   memoBstCount :: Int -&gt; Integer memoBstCount n = Vector.last memo   where     memo = Vector.generate (n+1) (bstCount (memo Vector.!))   In C++, the order of evaluation now has a direct impact on the correctness of our solution. Had we computed the sub-solutions in the wrong order, we would have got a completely erroneous solution.   So although we applied the same idea, we achieve less decoupling in C++ than in Haskell: the implementer of the memoization must still care about the insides of the recurrence formula. Can we do better?   Adding laziness   To get rid of the coupling to the order of evaluation, we will take some of the ideas from Haskell, and introduce laziness into our solution. We just need a helper function that will:      Index into the vector to check for a previously computed value   Return this value if it could be found   Perform the computation otherwise, and store it in the vector   This gives us to the following C++ implementation:   static long long lazy_impl(std::vector&lt;long long&gt;&amp; memo, int n) {     if (memo[n]) return memo[n];     auto recur = [&amp;](int k) { return lazy_impl(memo, k); };     return memo[n] = bst_count(recur, n); }   long long bst_count_lazy(int n) {     std::vector&lt;long long&gt; memo(n+1);     return lazy_impl(memo, n); }   You might wonder if we could have used a lambda instead of introducing a function. Unfortunately no, since a lambda has no name, it cannot refer to itself in its body.   The following would indeed not compile:   long long bst_count_lazy(int n) {     std::vector&lt;long long&gt; memo(n+1);     auto lazy_impl = [&amp;](int n) {         if (memo[n]) return memo[n];         auto recur = [&amp;](int k) { return lazy_impl(memo, k); };         return memo[n] = bst_count(recur, n);     }     return lazy_impl(memo, n); }   We now have the same level of decoupling as with our Haskell solution.   Conclusion   We proved that the open recursion trick known from the Haskell world can be very easily brought to C++. Using it, we can decouple the memoization strategy of a Dynamic Programming solution from the recurrence relation.   Although it might seem that we achieved a total decoupling between the recurrence relation and the memoization part, the implementer of the memoization strategy still needs to care about which sub-solutions to compute.   Can we do something about it? We will look into this subject in the next post  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2016/11/30/open-recursion-cpp.html",
        "teaser": null
      },{
        "title": "Open Recursion (Performance)",
        "excerpt":"In the two previous posts, we used open recursion to provide efficient solutions to dynamic programming problems, keeping the following aspects decoupled:      The recurrence relation: the solution to our problem   The memoization strategy: indexing into a vector   The order in we compute the sub-solutions   As a reminder, here is the open recurrence relation we based our examples upon:   template&lt;typename Recur&gt; long long bst_count(Recur recur, int n) {    if (n &lt;= 1) return 1;     long long sub_counts = 0;    for (int i = 0; i &lt; n; ++i)       sub_counts += recur(i) * recur(n-1-i);    return sub_counts; }   However, we observed that the memoization strategy was still depending on the sub-solutions space needed to compute the solution. The vector we used had to be of the right size.   Today, we will explore a general memoization strategy that does not require much knowledge about the content of the recurrence formula to memoize. In particular, it does not require prior knowledge of the sub-solution space.   Using hash map as generic memoization strategy   The simplest way to be decoupled from the sub-solutions space we need to compute, is to use a hash map. This hash map:      Will start empty   Will be filled gradually with new sub-solutions   Will be searched at each recursion   Here is a C++ implementation of this strategy, based on open recursion   static long long lazy_map(std::unordered_map&lt;int, long long&gt;&amp; memo, int n) {    auto&amp; computed = memo[n];    if (computed) return computed;    auto recur = [&amp;](int k) { return lazy_map(memo, k); };    return computed = bst_count(recur, n); }  long long bst_count_map(int n) {    std::unordered_map&lt;int, long long&gt; memo;    return lazy_map(memo, n); }   With this implementation the decoupling is nearly total. The only requirement left is that the sub-solutions form a DAG, a basic assumption when dealing with Dynamic Programming problems.   In particular, the memoization strategy does not have to care about:      The order of evaluation of the sub-problems   The number of sub-problems to compute   But by doing so, we went from a tightly packed vector to a more memory consuming and less local data structure. Surely there is a price to pay.   Performance implications   Rich Hickey said that nowadays “Programmers know the benefits of everything and the tradeoffs of nothing”. So we must ask ourselves: did our successive decoupling refinement had an impact on performance?   Note: The following measures were performed on the code we show previously. And we know this result is wrong (long long do overflow for N=1000): they only serve as approximation, only to have some idea of what we are talking about.   I measured the performance of each of these solutions, for 100 runs with N=1000, and got the following results:      Eager vector (coupling with evaluation order): 0.047s   Lazy vector (no coupling with evaluation order): 0.308s   Hash map (no coupling with sub-problem range): 2.306s   So there is approximately an order of magnitude performance drop at each refinement we did.   What about an implementation without open recursion, in which everything is coupled together? I tried benching the following C++ implementation:   long long bst_count_classic(int n) {    if (n &lt;= 1) return 1;         std::vector&lt;long long&gt; memo(n+1, 0);    memo[0] = memo[1] = 1;    for (int k = 2; k &lt;= n; ++k)       for (int i = 0; i &lt; k; ++i)          memo[k] += memo[i] * memo[k-i-1];    return memo.back(); }   Sure enough this implementation is faster than our “Eager vector” implementation: it takes 0.034s instead of 0.047s (a 28% improvement).   (All of my benchmarks were performed on Clang with -02)   No benefits without trade-offs   Open-recursion is a nice technique that allows to provide quick and easily readable solution to dynamic programming problems. It is also a nice cheat: I used it repeatedly in Hackerrank or TopCoder to get a fast working implementation of my algorithms.   But even in a language like C++, coined as “zero cost abstraction language” by its creator, there are tradeoffs to almost each abstraction mechanism we use.   Does it means that the different techniques we saw are useless? On the contrary, it means that each of these techniques has its specific spot. Here is a quick rule of thumb for C++ regarding when to use each of the techniques we walked through:      Use hash map when there is no simple indexing strategy (or when it leads to sparse vectors)   Use hash map when knowing which sub-solutions to compute in advance is hard (here is a nice example)   Otherwise, use the open recursion technique with vector-based memoization (eager if the order of evaluation is known)   Finally, if all sub-problems solutions do not need to stay in memory (example of fibonacci), or if you absolutely need the ultimate performance, write an custom algorithm   These rules are obviously not covering all cases, but they served me well until now.   Conclusion   This post concludes the series focused on open recursion technique, which I think is a really nice cheat for solving dynamic programming problems.   Here are some nice resources you may be interested about:      An absolute gem from Edward Kmett   Haskell Data.Function.Memoize package   Clojure memoize function   ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2016/12/04/open-recursion-performance.html",
        "teaser": null
      },{
        "title": "Meetup Report: The philosophy of FP",
        "excerpt":"Yesterday, I attended a meetup at Arolla, where Arnaud LEMAIRE (@lilobase) did a wonderful talk on the philosophy of Functional Programming. You can find the slides of the presentation here.   The presentation was an introduction to the concepts behind Functional Programming. It went over the pillars of FP, before concluding with practical advices on how to use this knowledge in our (most probably object-oriented) code base.   Arnaud summarized complex ideas into simple definitions and managed to find analogies and make interesting parallels that made these concepts easily understandable.  So I thought it would be a good idea to write down here what notes I took, and share it with you in this post.   What is a state?   The result of combining a value with time. This is how you get variables and overall, this is a good recipe to get bugs.   The functional paradigm language is about getting rid of (or more realistically controling) this complexity by getting rid of time (or more realistically introducing an explicit model of time), and play with immutable values instead. The trick is to avoid variables in large portion of our programs, and create new values for each modification we would do in imperative programming style.   Creating these new values can be done very efficiently. Persistent data structures are based on structural sharing, the ability to re-use part of the old data value to construct the new one.   But persistent data structures do not make the cost of creating new values disappear entirely. They do consume more memory than their respective counterparts. They also add indirections that may cost in terms of computation time. This cost can often be offset by the whole range of possible optimization they make possible in exchange. In particular:      Much easier use of parallel or distributed computations   No need to use defensive locking mechanisms   What are pure functions?   Pure functions can be seen as delayed values: they just miss some arguments to be able to deliver their value. Give them the same arguments twice, and they output the same value. This has important consequences:   Memoization: Instead of recomputing the values of a pure functions called with the same argument, we can keep the result in store for the next time it is called. Pure functions make caching almost trivial.   Lazy evaluation: We can emulate the lazy evaluation of languages like Haskell by wrapping a computation inside a lambda that takes no arguments. Forcing the computation is just calling that closure with no arguments.   First class functions: If functions are like values, there is no reason you could not manipulate them as values. In particular, it means having functions returning functions, and functions taking functions as parameters, both of which are called higher-order functions.   Objects and closures   OOP is based on smart data structures, classes that carry with them the functions that operate on them. Functional Programming is based on simpler data structures: functions that operate on the data structure are moved outside of it.   The FP view makes for easier composition of functions, especially if you see the functions as transformation between two sets of values. Chaining functions becomes function composition, and can be done without utilizing side effects.   Arnaud ended this sections with a wonderful comparison of Closure and Objects. He pointed out that Closures can be seen as the inverse of Objects:      Objects are data that carry some functions with them   Closures are functions that carry some data with them   On type systems   Functional programming is usually based on structural typing, whereas Object Oriented Programming is usually based on nominative typing.   Structural typing checks if types are equivalent by matching their structure. If two values have a similar structure, they can be considered of the same type.   Nominative typing checks if types are equivalent by matching their “name”. If two values have the name class name, they are considered of the same type.   As an example of structural typing, if a coordinate is made of two doubles, and if a function expects a coordinate, providing it two doubles will work fine. In the case of nominative typing, this would not type-check: you would need an explicit coordinate data structure to be instantiated.   Structural typing is more loose and flexible than nominative typing. It makes it easier to build generic functions that can apply on different data structures. But it comes at a price: nominative type systems are better at ensuring correctness of your program.   In reality, this dichotomy is not as strict as it may sound. Some languages reinforce the structural typing by putting a name on the structure. This ensures the same correctness guaranty as nominative type systems, but provides a greater expressiveness.   Pattern matching and Polymorphism   Pattern matching in Functional Programming can be seen as the opposite of polymorphism in Object Oriented Programming:      Interfaces in OOP are closed under the addition of new functions, but not on a addition of new types. The dispatch is based on the name of the type.   Algebraic data types are closed under addition of new types, but open in terms of addition of new functions. The dispatch is based on the structure.   We can see there a reference to the Expression Problem coined by Philip Wadler. Both use cases exists: for example in Haskell, you can switch to typeclasses when you need to be open to new types and closed to new functions.   This is why Arnaud talked about not being a zealot and advised against the strict segregation of paradigms.   Practical advices   The talk ended by a collection of practical advices for all of us that do not program into a natively functional programming language. These pieces of advice were especially useful since most of attendees did not have access to languages like Haskell or Clojure at their workplace:      Try to use immutability as much as you can: use const everywhere you possibly can. This will catch a lot of bugs.   Use algorithms like map, filter and reduce to avoid states in your looping constructs. It makes the code more declarative and less error prone.   Try to use Algebraic Data Types. They are available in most languages: JS, Python, std::variant in C++, etc.   To handle concurrency, try to rely on concepts like actors to avoid the synchronization nightmares (dead-lock and other performances issues).   Use concepts like Functional Core, Imperative Shell to make your business logic code as pure as possible.   ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2016/12/20/fp-meetup-report.html",
        "teaser": null
      },{
        "title": "Folding merge sort (Haskell)",
        "excerpt":"Back in September 2016, I was lucky enough to attend a talk from Ben Deane entitled std::accumulate: Exploring an Algorithmic Empire. In this talk, he presents the unknown possibilities of std::accumulate, an algorithm also known as fold or reduce depending on the language.   In his talk, he announced he had implemented almost all the algorithms of the STL based on std::accumulate (41st minute in the video), including std:stable_sort, which was a bit surprising to me.   So I searched his blog and could not find a hit on how he did it. So I decided to write this post to describe the solution I found. I hope you will find it as elegant as I do.   Small ranges and binary counters   The solution relies on using a binary counter like data-structure:      Our binary counter will hold at each level $L$ a range of size $2^L$. The binary counter will thus be limited in size to $\\log N$ if $N$ is the number of elements of the collection to sort.   We populate the binary counter by successively adding ranges of size one to the counter.   Each time we have a collision of “bit” (range of the same size), we merge them and consider it as a “carry”.   We keep propagating the carry up the levels, until we reach an empty slot.   This is best explained by an example:   Initially Counter = [[1, 2], [3, 4, 5, 6]]   Adding element 7 Counter = [[7], [1, 2], [3, 4, 5, 6]]   Adding element 8 Counter = [merge [8] and [7], [1, 2], [3, 4, 5, 6]] Counter = [merge [7, 8] and [1, 2], [3, 4, 5, 6]] Counter = [merge [1, 2, 7, 8] and [3, 4, 5, 6]] Counter = [[1, 2, 3, 4, 5, 6, 7, 8]]   Adding elements 9, 10 and 11 Counter = [[11], [9, 10], [1, 2, 3, 4, 5, 6, 7, 8]]   At this point, we are almost done, but not quite. We still need to collapse all the remaining “bits” of our counter into one answer. We do this by accumulating over these “bits” with a merge operation.   [[11], [9, 10], [1, 2, 3, 4, 5, 6, 7, 8]] [[9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8]] [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]   We are done! Let us try to implement this in Haskell.   Haskell implementation   The implementation in Haskell follows pretty closely the description we gave of the solution in the previous paragraph.   The main difference lies in the use of an auxiliary integer to keep the length of the list. Had we not do that, our solution would have been much less efficient: computing the length of a list in Haskell is linear in the size of the list.   foldMergeSort :: (Ord a) =&gt; [a] -&gt; [a] foldMergeSort =   foldl1 (flip merge) . map snd . foldl addToCounter []   where     addToCounter counter x = propagate ((1::Int,[x]) : counter)     propagate [] = []     propagate [x] = [x]     propagate counter@(x:y:xs) -- x arrived last =&gt; combine on right       | fst x == fst y = propagate ((fst x + fst y, merge (snd y) (snd x)) : xs)       | otherwise      = counter      The head of the counter list is the lowest level bit   The function propagate implements the carry propagation   The function addToCounter add a “bit” in the counter   The map snd allows to get rid of the integer holding the list length   The foldl1 (flip merge) implements the collapse of the counter   To ensure our merge sort is stable, ranges that came last must be passed as right parameters to the merge function. This is the reason why we collapse our counter with flip merge instead of merge (which would also type check but result in unstable sort).   This implementation assumes the existence of a merge function that combines two sorted lists into one bigger sorted list. You can implement it as follows (it requires a bit of care to make it stable):   merge :: (Ord a) =&gt; [a] -&gt; [a] -&gt; [a] merge xs [] = xs merge [] ys = ys merge l@(x:xs) r@(y:ys)   | y &lt; x     = y : merge l ys -- Keeps it stable   | otherwise = x : merge xs r   As map (std::transform in the STL) can be itself implemented in terms of fold (std::accumulate in the STL), this is one way to implement a “out of place” stable sort in Haskell based only on folds and composition of functions.   Generalizing to Monoids   Looking back at the code of our solution, we can observe that this algorithm would work for any Monoid. So we can make our algorithm more general, and fold any Monoid following a tree like structure.   foldMonoidTree :: (Monoid a) =&gt; [a] -&gt; a foldMonoidTree =   foldl1 (flip (&lt;&gt;)) . map snd . foldl addToCounter []   where     addToCounter counter x = propagate ((1::Int,x) : counter)     propagate [] = []     propagate [x] = [x]     propagate counter@(x:y:xs) -- x arrived last =&gt; combine on right       | fst x == fst y = propagate ((fst x + fst y, snd y &lt;&gt; snd x) : xs)       | otherwise      = counter   To get our stable merge sort back, we can create a type for sorted lists, and make it an instance of Monoid. Here is one possible implementation:   newtype SortedList a = SortedList { unSortedList :: [a] }  instance (Ord a) =&gt;  Monoid (SortedList a) where   mempty = SortedList []   mappend (SortedList a) (SortedList b) = SortedList $ merge a b  foldMergeSort :: (Ord a) =&gt; [a] -&gt; [a] foldMergeSort = unSortedList . foldMonoidTree . map (\\x -&gt; SortedList [x])   Conclusion and what’s next   I was quite astonished how elegant the solution was and how simple the resulting code. But somehow, you should feel unsatisfied with the performance.   I cheated. I did not use C++ as the original presentation did. And this implementation of stable_sort creates a new list. Haskell did not give me the choice.   So next time we will have a look at an implementation in C++ that stable sorts the container provided as input.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2016/12/22/folding-merge-sort.html",
        "teaser": null
      },{
        "title": "Accumulating merge sort (C++)",
        "excerpt":"Back in September 2016, I was lucky enough to attend a talk from Ben Deane entitled std::accumulate: Exploring an Algorithmic Empire. In this talk, he presents the unknown possibilities of std::accumulate, an algorithm also known as fold or reduce depending on the language.   In his talk, he announced he had implemented almost all the algorithms of the STL based on std::accumulate (41st minute in the video), including std:stable_sort, which was a bit surprising to me.   So I searched his blog and could not find a hit on how he did it. So I decided to write this post to describe the solution I found.   The subject of today’s post is therefore to:      Implement this algorithm in C++   Make it work on the input container directly   Make it work for more than just lists   In the process, we will build a std::stable_sort variant that works for ForwardIterators, whereas std::stable_sort only works for RandomAccessIterator.   Small ranges and binary counters   The solution relies on using a binary counter like data-structure:      Our binary counter will hold at each level $L$ a range of size $2^L$. The binary counter will thus be limited in size to $\\log N$ if $N$ is the number of elements of the collection to sort.   We populate the binary counter by successively adding ranges of size one to the counter.   Each time we have a collision of “bit” (range of the same size), we merge them and consider it as a “carry”.   We keep propagating the carry up the levels, until we reach an empty slot.   This is best explained by an example:   Initially Counter = [[1, 2], [3, 4, 5, 6]]   Adding element 7 Counter = [[7], [1, 2], [3, 4, 5, 6]]   Adding element 8 Counter = [merge [8] and [7], [1, 2], [3, 4, 5, 6]] Counter = [merge [7, 8] and [1, 2], [3, 4, 5, 6]] Counter = [merge [1, 2, 7, 8] and [3, 4, 5, 6]] Counter = [[1, 2, 3, 4, 5, 6, 7, 8]]   Adding elements 9, 10 and 11 Counter = [[11], [9, 10], [1, 2, 3, 4, 5, 6, 7, 8]]   At this point, we are almost done, but not quite. We still need to collapse all the remaining “bits” of our counter into one answer. We do this by accumulating over these “bits” with a merge operation.   [[11], [9, 10], [1, 2, 3, 4, 5, 6, 7, 8]] [[9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8]] [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]   We are done! Let us try to implement this in C++.   Impementing the binary counter   Following a quick youtube search, I was able to find an episode of the A9 Stepanov lectures that dealt with the implementation of a binary counter in C++.   The following code is greatly inspired (almost copy-pasted, except for the std::find_if) from these amazing lessons:      The add_to_counter function handles the carry propagation, and returns the carry if it ran out of bits   The reduce_counter allows to collapse all the remaining bits at the end of the accumulation   The binary_counter class maintains the vector of bits, and is responsible for gluing the algorithms together   template&lt;typename Iterator, typename Value, typename BinaryOp&gt; Value add_to_counter(Iterator first, Iterator last,                      Value carry, Value const &amp;zero,                      BinaryOp op) {     assert(carry != zero);     for (; first != last; ++first) {         if (*first == zero) {             *first = carry;             return zero;         }         carry = op(*first, carry);         *first = zero;     }     return carry; }  template&lt;typename Iterator, typename Value, typename BinaryOp&gt; Value reduce_counter(Iterator first, Iterator last,                      Value const &amp;zero, BinaryOp op) {     first = std::find_if(first, last, [&amp;zero](auto &amp;v) { return v != zero; });     if (first == last)         return zero;      Value result = *first;     for (++first; first != last; ++first) {         if (*first != zero)             result = op(*first, result);     }     return result; };   template&lt;typename BinaryOp, typename Value&gt; class binary_counter { public:     binary_counter(BinaryOp const &amp;op, Value const &amp;zero)         : m_bits(), m_zero(zero), m_op(op) {}      void add(Value carry) {         carry = add_to_counter(begin(m_bits), end(m_bits), carry, m_zero, m_op);         if (carry != m_zero)             m_bits.push_back(std::move(carry));     }      Value reduce() const {         return reduce_counter(begin(m_bits), end(m_bits), m_zero, m_op);     }  private:     std::vector&lt;Value&gt; m_bits;     Value m_zero;     BinaryOp m_op; };   As for the Haskell implementation in our previous post, the C++ implementation of the binary counter is able to deal with any Monoid. It only requires:      An associative binary operation   That admits a neutral element   This implementation also shows a great usage of object orientation to structure a program: the class is used to combine some algorithms with the data their operate on (to guaranty invariants), while the algorithms are kept outside of the class for greater re-use.   The merge binary operation   Now that we have a binary_counter that works on any Monoid, we need to define the equivalent of the SortedList Monoid instance on which to apply it.      The neutral element will be the empty range   The binary operation will be something close to std::merge.   Why something close and not std::merge directly? Because we need some kind of auxiliary buffer to perform the merge.   This is the implementation I came to:   template&lt;typename Iterator&gt; struct merger {     using Value = typename std::iterator_traits&lt;Iterator&gt;::value_type;     using SortedRange = std::pair&lt;Iterator, Iterator&gt;;      SortedRange operator()(SortedRange const &amp;lhs, SortedRange const &amp;rhs) const {         assert(lhs.second == rhs.first);         std::vector&lt;Value&gt; tmp(lhs.first, lhs.second); //Copy the left range         std::merge(                 std::begin(tmp), std::end(tmp), // Left container copy (source)                 rhs.first, rhs.second,          // Right container (source)                 lhs.first);                     // Left container (destination)         return SortedRange(lhs.first, rhs.second);     } };   I found this implementation more tricky than I first thought it would be. In particular, we need to ensure that the two ranges we merge are always:      Next to each other (one range end is the beginning of the other)   In the right order (left range is before the right range)   I claim these two propositions will always hold if we accumulate our container from left to right. The argument is based on the implementation of add_to_counter and reduce_counter and the properties of Monoids.   Indeed, reduce_counter initializes its result from the lower level “bit” (which is the latest arrived in the counter) and combines it on the right with op(*first, result). So the latest arrived range is always provided as right argument of the merge operation.   The same goes for add_to_counter that combines the carry on the right side of the binary operation. Again, the latest arrived range is provided as right argument of the merge operation.   This property of the binary_counter algorithm is crucial. The Monoid property guaranties our operation is associative but not necessarily commutative. So the binary_counter must have this property to be correct, and as a result we can rely on it.   Accumulating with iterators   It is now time to combine our different elements to build our std::stable_sort based on a std::accumulate. But there is a catch…   As observed by Ben Deane in std::accumulate: Exploring an Algorithmic Empire, we cannot really use the std::accumulate of the STL here. It deals with values while we need ranges here, which means iterators.   An easy way to get past this is to create our own accumulate_iter algorithm, that provides an iterator to the accumulating function (instead of a value):   template&lt;typename Iterator, typename Value, typename Accumulator&gt; Value accumulate_iter(Iterator first, Iterator last,                       Value val, Accumulator fct) {     for (; first != last; ++first)         val = fct(val, first);     return val; };   Based on this algorithm, we are now able to assemble the different parts needed to build a std:stable_sort working on ForwardIterators:   template&lt;typename ForwardIterator&gt; void stable_sort_forward(ForwardIterator first, ForwardIterator last) {     using Range = std::pair&lt;ForwardIterator, ForwardIterator&gt;;     using Counter = binary_counter&lt;merger&lt;ForwardIterator&gt;, Range&gt;;        Counter c { merger&lt;ForwardIterator&gt;{}, { last, last } };     accumulate_iter(first, last, &amp;c,                     [](auto c, auto it) {                         c-&gt;add({it, std::next(it)});                         return c;                     })-&gt;reduce(); }   Now we are truly done. You can convince yourself that it does stable sort a container by trying it on some examples.   Wrapping it up   We managed to write a std::stable_sort using a variant of std::accumulate that sorts a container provided as parameter. I do not know if this is the same solution Ben Deane used to implement his own, but it is definitively doable.   One interesting consequence is that our stable sort algorithm also works for ForwardIterator. So you can sort a std::list and even a std::forward_list with it.   Now, I would not be offended if you told me you found accumulate_iter usage neither beautiful, nor concise, nor simple. If you do, you might be more interested in this version of the algorithm, where we use a raw loop:   template&lt;typename ForwardIterator&gt; void stable_sort_forward(ForwardIterator first, ForwardIterator last) {     using Range = std::pair&lt;ForwardIterator, ForwardIterator&gt;;     using Counter = binary_counter&lt;merger&lt;ForwardIterator&gt;, Range&gt;;      Counter c { merger&lt;ForwardIterator&gt;{}, { last, last } };     for (; first != last; ++first) {         c.add(std::make_pair(first, std::next(first)));     }     c.reduce(); }   It gives the same results, so it is mostly a matter of taste here. Indeed, C++ may not be the best language to play with fold algorithms. You might prefer the imperative style when programming in C++. Ultimately, deciding which tool and which paradigm to use is a choice you and your team have to make.  ","categories": ["modern-cpp"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2016/12/26/accumulating-merge-sort.html",
        "teaser": null
      },{
        "title": "Meetup Report: Better tests Kata night",
        "excerpt":"Two days ago, I went at a Crafting Software Meetup at Arolla. The goal was to join other developers and improve our skills as a group by practicing kata. The chosen Kata was the simple Fizz Buzz kata.   Together with my pair, we developed it using Haskell, following a TDD approach. Then went on improving our test coverage by using Property Based Testing. The night ended with Romeu Moura doing a quite amazing demonstration on how he did tests and TDD.   I found the lessons valuable and this post will attempt at retranscribing them.   Our initial solution for the Kata   Fizz Buzz is a simple program that takes a positive integer as input, and outputs a string. It should:      Return “0” if the input is 0   Return “Fizz” if the input is a multiple of 3   Return “Buzz” if the input is a multiple of 5   Return “FizzBuzz” if the input is a multiple of 3 and 5   Echo its input as a string otherwise (example “7” for 7)   Here is the implementation of Fizz Buzz we ended with:   fizzBuzz :: Int -&gt; String fizzBuzz 0 = \"0\" fizzBuzz n =   let res = fizzBuzzImpl [newRule 3 \"Fizz\", newRule 5 \"Buzz\"] n   in if res == \"\"       then show n       else res  type Rule = Int -&gt; String  newRule :: Int -&gt; String -&gt; Rule newRule divisor out n   | isMultiple n divisor = out   | otherwise = \"\"  fizzBuzzImpl :: [Rule] -&gt; Int -&gt; String fizzBuzzImpl rules n = concatMap ($ n) rules  isMultiple :: Int -&gt; Int -&gt; Bool isMultiple n divisor = mod n divisor == 0   Here are the tests we ended up with to test this implementation:   testCases :: [(Int, String)] testCases = [ (0, \"0\"), (1, \"1\"), (3, \"Fizz\"), (5, \"Buzz\")             , (7, \"7\"), (15, \"FizzBuzz\"), (100, \"Buzz\")]  tests :: Test tests = TestList $ map createTestCase testCases   where     createTestCase (input, expected) =       let label = \"FizzBuzz of \" ++ show input       in TestCase $ assertEqual label expected (fizzBuzz input)   After that, we went a bit crazy and did our best to leverage property based testing to check some properties of our algorithm. We managed not to replicate the implementation of the fizz buzz in the properties (which is an error we can easily fall into). You can check the result of this experiment at the following link if your are curious.   Great lesson on How To Test   Writing test is not easy. Deriving good practices on how to test is not easy either. This section is about restituting some of the great advices from the amazing demonstration of TDD done by Romeu.   Tell a story   Use naming to make your tests such as they read like a story. Use the name of the Fixture, of the tests, and even the parameters to help you. The ordering of the tests inside the Fixture might also be important.   For example, in Java, you could have something like this:   class FizzBuzzShould {     @Test   void fizz_buzz_for(int multiple_of_3_and_5) {     assertThat(fizzBuzz(multiple_of_3_and_5)).isEqualTo(\"FizzBuzz\");   }     @Test   void otherwise_fizz_for(int multiple_of_3) {     assertThat(fizzBuzz(multiple_of_3)).isEqualTo(\"Fizz\");   }     @Test   void otherwise_buzz_for(int multiple_of_5) {     assertThat(fizzBuzz(multiple_of_5)).isEqualTo(\"Buzz\");   }     @Test   void otherwise_echo_its(int input) {     assertThat(fizzBuzz(input)).isEqualTo(Integer(input).toString());   } }   Use bad faith   After adding tests, write the least amount of work needed to make the test pass. This include writing code that no-one would on purpose: special “if” cases.   Why would we do that? The goal is to show that the tests actually test something and are able to catch errors. If a new test is never going red, how can we ensure it is really a useful tests?   Where does it stop? Writing special case code can go on for quite a long time, so we need something to stop the cycle. One such rule is the rule of three which states that upon 3 code repetition, the code must be factorized.   Make it work, then make it right   Refactor only if all tests are green. Mixing refactoring and fixing bugs might make you loose time if something bad happens.   For example, to end up the “bad faith cycle”, start by making the 3 repetitions to make the test pass. Once green, you can get rid of this DRY violation.   Lazy naming   Delay the correct naming of your tests as late as you possibly can. Use inaccurate name at first, then revisit them at the end.   Naming your test accurately at the beginning is quite hard. Naming early might lead you to use names too close from the implementation. It might also lead you to rely on badly conceived notions that will be very hard to get rid of later.   As a consequence, naming your test “fizz_buzz_0” is fine when building the test suite: most of the tests will disappear in the end.   Fix something   Resist the temptation of writing a very generic test that take a list of (input, output) pairs. The problem with this approach is that it does not provide much of the intent behind each the test cases. As a consequence, when a test will fail, the reader will have a hard time figuring out why.   If you look at our tests in the initial part, this is a mistake we did: our tests take a list of pairs of (input, output) and run them all.   Instead, try to fix either a given input or output, as it will help giving meaning to your test cases. A good approach is to divide by equivalence class. For example, all inputs that produces “Fizz” could end up in one parameterised test.   Show the rules   Instead of writing a test that asserts that fizzBuzz of 30 is equal to “FizzBuzz”, explicit what 30 is.   For example, 30 is a shortcut for 2 * 3 * 5. Using the shortcut in the test means that the next reader will spend time figuring out the rules. Providing the rules explicitly will diminish the mental load needed to understand the test.   Keep tests small   Avoid conditional statements and looping constructs in your tests. The test should be as simple as a single assertion.   Use parameterised testing to get rid of the loops on the inputs. Rework your design to leverage value types to keep the number of assertions limited.   Putting these lessons to practice   The initial test suite we developed with my pair was clearly not up to the level of quality that Romeu described. We violated several of the rules:      Our test suite is very generic and does not show its intent.   We used shortcuts like 30 instead of 2 * 3 * 5 that show the rules   Our test cases do not tell a story at all   Here is an attempt (that might maybe go a bit too far) to make the tests readable:   tests :: Test tests =   let multiples_of_3_and_5 = [3 * 5, 2 * 3 * 5, 3 * 3 * 5]       multiples_of_3 = [3, 1 * 3, 2 * 3, 3 * 3]       multiples_of_5 = [5, 1 * 5, 2 * 5, 3 * 5]       other_numbers = [0, 1, 2, 4]   in TestList     [ fizzBuzz `should_equal` \"FizzBuzz\" `for_all` multiples_of_3_and_5     , fizzBuzz `should_equal` \"Fizz\" `for_all` multiples_of_3     , fizzBuzz `should_equal` \"Buzz\" `for_all` multiples_of_5     , fizzBuzz `should_do_like` show `for_all` other_numbers     ]   It requires some helpers to be defined for us (fortunately, these are quite generic function we could put in a separate file):   should_equal :: (Show t, Show a, Eq a) =&gt; (t -&gt; a) -&gt; a -&gt; t -&gt; Test should_equal underTest expected input =   let label = \"Expects \" ++ show expected ++ \" for \" ++ show input   in TestCase $ assertEqual label expected (underTest input)  should_do_like :: (Show t, Show a, Eq a) =&gt; (t -&gt; a) -&gt; (t -&gt; a) -&gt; t -&gt; Test should_do_like underTest refFct input   = should_equal underTest (refFct input) input  for_all :: (a -&gt; Test) -&gt; [a] -&gt; Test for_all fct inputs = TestList (map fct inputs)  ","categories": ["software-design"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2016/12/31/tdd-meetup-report.html",
        "teaser": null
      },{
        "title": "Catamorph your DSL (Introduction)",
        "excerpt":"I recently had the pleasure to go to a Haskell workshop on Domain Specific Languages (DSL). The goal was to teach us the basics on how to build a DSL.   The workshop covered a lot of ground, too much to cover here. I will instead focus on one specific notion that this workshop made me discover (and which I found pretty useful and amazing): catamorphisms.   This is a vast subject that will require several posts to explore. Across the following posts, we will:      Start by describing and designing a small toy DSL in Haskell.   Introduce catamorphisms to improve its flexibility and performance   Then discuss the trade-offs involved in introducing it in your DSL   Conclude by looking at how the concept translates to other languages   The goal of today’s post is to tackle the first point: introducing a small DSL which will be used across all the following posts.   A small arithmetic DSL   We will create a small DSL that resemble the DSL introduced in the Boost Variant Tutorial. This is a classic example illustrated in many other blogs like this post on Simplify C++, but it is quite instructive nevertheless.   The goal is to perform some basic integer arithmetic operations, like addition and multiplication, on both integer constants and integer variables.   Our DSL will be named Expr and is based on several possible sub-types (Haskell constructors):      Cst to represent constant integer values   Var to represent unknown integer values (variables)   Op to represent an operation (addition or multiplication)   This translates into the following Haskell code:   type Id = String data OpType = Add | Mul deriving (Show, Eq, Ord)  data Expr   = Cst Int   | Var Id   | Op OpType [Expr]   deriving (Show, Eq, Ord)   You can notice in the code above that the Op constructor is recursive: an operation is itself based on sub-expression of the same Expr DSL. This is something that will be very important when introducing catamorphisms.   Creating an arithmetic expression   To be help testing early, our first tasks will be to facilitate the creation of an expression. We will do this by introducing what is called in Haskell “smart constructors”, basically factory functions:   cst = Cst var = Var add = Op Add mul = Op Mul   This makes it slightly easier to create an expression. It also helps abstracting away the details of the construction. In general, factory functions buy us some precious degrees of liberty by removing the need to know the exact constructor we use.   Let us create our first expression:   add [ cst(1)     , cst(2)     , mul [cst(0), var(\"x\"), var(\"y\")]     , mul [cst(1), var(\"y\"), cst(2)]     , add [cst(0), var(\"x\") ]]   This is not as readable as we could make it by by leveraging standard type classes (like fromInteger). But this is not the focus of this post. Instead, we will build a first interpreter to pretty print an expression of our DSL.   The trick to implement an interpreter is simply to make it follow the structure of our data. We will call the printer interpreter prn and make it output a lispy representation of our DSL (to honor Clojure):   prn :: Expr -&gt; String prn (Cst n) = show n prn (Var v) = v prn (Op Add xs) = \"(+ \" ++ unwords (map prn xs) ++ \")\" prn (Op Mul xs) = \"(* \" ++ unwords (map prn xs) ++ \")\"   We can try our interpreter on our previous expression:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]  &gt; prn e \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"   Evaluating and arithmetic expression   Our next move should be to evaluate our expression, given some values for the variables that appear in it. We will need a supplier for these variables, that we will call an environment. Four our purpose, a simple map from string to int will do.   To perform the evaluation itself, we will create a new interpreter. We will call this function “eval”. Again, the function just has to follow the recursive structure of its input:   type Env = Map.Map String Int  eval :: Env -&gt; Expr -&gt; Int eval env (Cst n) = n eval env (Var v) = env Map.! v eval env (Op Add xs) = sum $ map (eval env) xs eval env (Op Mul xs) = product $ map (eval env) xs   Let us try this interpreter with an environment binding x to 1 and y to 2:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]  &gt; let env = Map.fromList [(\"x\", 1), (\"y\", 2)]  &gt; prn e \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"  &gt; eval env e 8 -- (+ 1 2 (* 0 1 2) (* 1 2 2) (+ 0 1)) -- (+ 3 4 1) -- 8   Note that we throw an key-not-found exception when the environment does not contain the appropriate variables. We will improve on this later.   Optimizating our arithmetic expressions   We covered the basic interpreters we could define for our DSL. At this point there is not much interest in having built a DSL in the first place.   One interesting power DSLs offer is the ability to manipulate their Abstract Syntax Tree (AST). For example, we might be interested in optimizing our arithmetic operations to collapse the known terms once and for all.   We will design our optimizer to perform the following improvements:      Collapse the constants pertaining to the same operation: (+ 1 2) becomes 3.   Remove the constants equal to the neutral element: (+ 0 x) becomes x.   Simplify the operations which only have one argument: (+ x) becomes x.   Get rid of a multiplication operation if it contains any 0 argument.   The function optimize implements our interpreter and, again, follows the structure of the data. The function optimizeOp factorizes the similarities between the additional and the multiplication (both are Monoids):   optimize :: Expr -&gt; Expr optimize op@(Op Add ys) = optimizeOp Add (map optimize ys) 0 (+) optimize op@(Op Mul ys)   | not (null (dropWhile (/= cst 0) xs)) = cst 0   | otherwise = optimizeOp Mul xs 1 (*)   where xs = map optimize ys optimize e = e  optimizeOp :: OpType -&gt; [Expr] -&gt; Int -&gt; (Int -&gt; Int -&gt; Int) -&gt; Expr optimizeOp opType xs neutral combine =   let (constants, vars) = partition isCst xs       constantsVal = map (\\(Cst x) -&gt; x) constants       sumCst = foldl' combine neutral constantsVal   in case vars of       [] -&gt; cst sumCst       [y] | sumCst == neutral -&gt; y       ys  | sumCst == neutral -&gt; Op opType ys       ys  -&gt; Op opType (cst sumCst : ys)   We can try our optimizer on our initial expression to see how it performs:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]  &gt; prn e \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"  &gt; prn (optimize e) \"(+ 3 (* 2 y) x)\"   Pretty nice!   But is this optimize function that useful? The user might have trivially optimized the expressions by hand when providing them as input.   It might be true in that case, but for more complex examples of DSL or more complex expressions, it might not be as easy. Besides, the next interpreter will show us a use case in which optimization is very useful.   Partial application   Let us imagine we have a really complex arithmetic expression, featuring several variables, and we want to “fix” some of them? For example, we might want to replace all occurrences of “x” with the value 1.   This use case is quite common in practice. It is similar to partial application of functions. In the finance software industry, it could correspond to the fixing of some of the unknowns of a payoff depending on the EURIBOR interest rate.   Let us write a simple interpreter for this use case. As for the evaluation, we will need an environment holding values associated to variables. But instead of returning an integer, we will return another expression, in which known variable occurrences will be replaced by their associated value.   partial :: Env -&gt; Expr -&gt; Expr partial env e@(Var v) =   case Map.lookup v env of     Nothing -&gt; e     Just n -&gt; cst n partial env (Op opType xs) = Op opType (map (partial env) xs) partial env e = e   Let us try it with our initial expression and an environment binding “y” to 0:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]  &gt; let env = Map.fromList [(\"y\", 0)]  &gt; prn (partial env e) \"(+ 1 2 (* 0 x 0) (* 1 0 2) (+ 0 x))\"   Disappointed by how stupid this expression looks? Now is the time for our optimizer to really shine and clean that expression:   &gt; prn (partial env e) \"(+ 1 2 (* 0 x 0) (* 1 0 2) (+ 0 x))\"  &gt; prn (optimize (partial env e)) \"(+ 3 x)\"   I told you this optimize function was useful!   Partial + Optimize = Eval   The last example of optimization might have raised some questions in you. What if our partial evaluation was in fact total? What if we tried to optimize an expression with no variables left? How is that different from evaluating our expression?   It is not different. In fact, we could implement implement eval in terms of partial followed by optimize. If the resulting optimized expression is a simple constant, the evaluation just returns it.   We could even leverage this to provide better error messages. We only need to create another interpreter that would list all dependencies to variables inside an expression. We could call it dependencies and it would return a set of variable names.   dependencies :: Expr -&gt; Set.Set Id dependencies (Var v) = Set.singleton v dependencies (Op _ xs) = foldl1' Set.union (map dependencies xs) dependencies e = Set.empty  eval' :: Env -&gt; Expr -&gt; Int eval' env e =   case optimize (partial env e) of     Cst n -&gt; n     e -&gt; error $ \"Missing vars: \" ++ show (dependencies e)   Let us try this error handling on evaluations that are bound to fail:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]  &gt; let env = Map.fromList [(\"x\", 1)]  &gt; eval' env e *** Exception: Missing vars: fromList [\"y\"]  &gt; eval' Map.empty e *** Exception: Missing vars: fromList [\"x\",\"y\"]   The limits of our model   The previous section showed that we could in theory implement our eval function in terms of partial and optimize.   But it would be much less efficient to do it. There are indeed 2 traversals of our AST: one due to partial and one due to optimize (and three in case of missing variables in our environment).   The same goes with our partial application function: we would like to automatically have the optimizer triggered after fixing a variable to avoid creating expressions that look stupid.   We could simply couple the two features together, together in the same function. It would however make the test of the partial function much more complex, as it would depend on the content of the optimization step. So it is not such a good idea, but the alternative is to do two traversals of the tree, which is not ideal either.   What then should we do? When we are faced with such dilemma, the best approach is almost always to take some distance, and rethink our design.   Easy composition favors decoupling   The problem with our design is that it makes it hard to compose several tree traversals together efficiently.   When composition is not efficient or not made easy, there is less incentive to decompose problems into separate responsibilities. It often leads to hand-crafted special traversals.   For example, if addition and multiplication were operations that required different expertise, it could make sense to have different teams working on each operation. It would be better then to split the optimization code in two as well, for example to simplify code ownership. But because it would lead to two traversals, keeping it as a single traversal would be more efficient and likely preferred.   Conclusion and what’s next?   We built a DSL to perform arithmetic operations on both constant integer and variable integers. We did it using a simple design, in which function recursion follows the recursive structure of our data.   Playing and enriching this DSL we found out the limits of this simple and naive approach: a code coupled with the traversal of the tree, that does not favor composition of different operations on our AST.   The next post will introduce catamorphisms, as a way to decouple the traversal of our tree from the operations we perform on it, and solve our problems of composition.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/01/17/catamorph-dsl-intro.html",
        "teaser": null
      },{
        "title": "Catamorph your DSL (Deep Dive)",
        "excerpt":"This post is a second of the series of post dedicated to notion of Catamorphisms and its application to build Domain Specific Languages (DSLs).   Our last post introduced an Arithmetic DSL that allowed to build expression composed of operations like addition and multiplication integer constants and integers variables. On top of this DSL, we built several interpreter functions:      prn to pretty print our Arithmetic expressions   eval to compute the value of an expression, given the value of all variables   optimize to simplify and optimize our expression   partial to partially evaluate our expression, given the value of some variables   dependencies to retrieve not yet resolved variables from our expression   At the end of the last post, we noticed that eval could be written in terms of partial and optimize. The impossibility to compose these interpreters efficiently showed us the limits of our model. Our design that coupled the traversal and the transformation on the Abstract Syntax Tree (AST) was simply not good enough.   The post of today will introduce the notion of Catamorphisms as a nice way to:      Decouple the traversal from the actions to perform   Get efficient composition of our interpreters back   Open type recursion   One of the first step to do in order to get to Catamorphisms is to deconstruct the recursion. Practically, it means getting rid of the recursive nature of the data structure by introducing a template.   type Id = String data OpType = Add | Mul deriving (Show, Eq, Ord)  data Expr   = Cst Int   | Var Id   | Op OpType [Expr]   deriving (Show, Eq, Ord)   Becomes the following, where recursion on Expr is replaced by the templated type r:   type Id = String data OpType = Add | Mul deriving (Show, Eq, Ord)  data ExprR r   = Cst Int   | Var Id   | Op OpType [r]   deriving (Show, Eq, Ord)   This looks innocent, but this is a very powerful trick. We already covered a similar trick for functions in my very first blog post when we were concerned about dynamic programming.   Back then, open recursion allowed us to plug memoization to our recurrence formula. Deconstructing our type recurrence relation will allow us to separate the recurrence from the action to perform during it.   If you read this previous post, you know the drill. Our first step is to get back our naive recurrence by computing the fix point of our recurrence. For types, this is a bit more complex (as we cannot create infinite types) and is achieved using the following trick:   newtype Fix f = Fix { unFix :: f (Fix f) }  -- Analog to Expr = ExprR Expr type Expr = Fix ExprR   Fortunately, there is a Haskell package on hackage that help you automating this, in the data-fix package.   Building an expression   To construct an Expr instance, we need to adapt our “smart constructors” (Haskell’s name for factory functions) introduced in our previous post:   cst = Fix . Cst var = Fix . Var add = Fix . Op Add mul = Fix . Op Mul   Having introduced this layer of abstraction allows us to keep the exact same syntax as before to construct our expressions:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]   Although our expression type got more complex by the introduction of a template, we can still instantiate it as easily as we used to, as we do not need to know the exact constructors needed at construction.   Getting to catamorphisms   Let us start by demystifying the big word. A Catamorphism is a just a name for a recursion scheme. A kind of design pattern to decouple the traversal of a recursive data structure from the work to do inside the traversal.   Our cataphormism implementation will make use of the open recursion we introduced in ExprR to implement a kind of post-order depth first search traversal.   Functor instance   Let us start by the first building block of the Catamorphism, making ExprR a Functor instance. It allows to apply a function on the type parameter r for the ExprR r. The Functor basically allows us to transform the type that represents the recurrence (for example to remove the recurrence).   DerivingFunctor could have generated the Functor instance for us as follows, but doing manually is really instructive:   instance Functor ExprR where   fmap _ (Cst c) = Cst c   fmap _ (Var v) = Var v   fmap f (Op opType xs) = Op opType (map f xs)   Now, if we consider a function with a prototype ExprR a -&gt; a, we see that providing it to fmap will get us a function ExprR (ExprR a) -&gt; ExprR a. Somehow, using fmap is like navigating between levels of recursion.   But we are not done yet. There is an unbound number of levels of recursions to deal with. Moreover, fmap does not quite fit our recursion: we have to take into account the Fix constructor wrapping each ExprR.   FMAP at each level   So we need to build a function that will apply our transformation through fmap, at each level of recursion. This function is the catamorphism function below which morphs a function ExprF a -&gt; a to a function Expr -&gt; a:   cataExpr :: (ExprR a -&gt; a) -&gt; Expr -&gt; a cataExpr algebra =   algebra   . fmap (cataExpr algebra)   . unFix   In simpler terms, it provides a way to lift a local transformation (that applies to one stage of the Abstract Syntax Tree) into a global transformation on the whole expression.   It proceeds in three steps:      unFix allows to extract the ExprF from the Fix constructor   fmap (cataExpr algebra) recurs on the sub-trees: each sub expression becomes a a   The resulting ExprR a is given to the function algebra to finish the job   Generalization to all Functors   We can generalize this cataExpr function to work on any fixed point of an open recursive data structure that is an instance of Functor. It means we can replace our ExprR by a Functor instance, as follows:   cata :: Functor f =&gt; (f a -&gt; a) -&gt; Fix f -&gt; a cata algebra =   algebra   . fmap (cata algebra)   . unFix   This is a bit abstract, so do not worry if you do not quite get this one. Just remember that applied to our ExprR, this function will resolve to the same cataExpr function we saw earlier.   Revisiting pretty printing   To best understand how catamorphisms work, examples are key. Let us start by reworking our first interpreter, the pretty printer, in terms of cata.   One cool thing about using this recursion scheme is that we can reason locally: we only need to care about what happens at one given stage (one node of our AST). Namely, we know that pretty printing a:      Constant is calling show on the numeric value   Variable is returning the name of variable   Addition is concatenating the sub-expression textual representation with +   Multiplication is concatenating the sub-expression textual representation with *   This translates almost directly into the following code. We can observe that algebra function is only concerned about implementing the local transformations listed above. The cata function takes entirely care of the recursion:   prn :: Expr -&gt; String prn = cata algebra where   algebra (Cst n) = show n   algebra (Var x) = x   algebra (Op Add xs) = \"(+ \" ++ unwords xs ++ \")\"   algebra (Op Mul xs) = \"(* \" ++ unwords xs ++ \")\"   To convince ourselves it works, we can test our function:   &gt; let e = add [ cst(1)               , cst(2)               , mul [cst(0), var(\"x\"), var(\"y\")]               , mul [cst(1), var(\"y\"), cst(2)]               , add [cst(0), var(\"x\") ]]  &gt; prn e \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"   Evaluation and dependencies   Let us continue our exploration of catamorphisms by rewriting our two next most straightforwards evaluators, eval and dependencies.   Our eval function is based on an algebra function that only has to deal with integers:      The evaluation of constant and variables is just as before   Addition is a simple call to sum on the sub-expression results   Multiplication is a call to product on the sub-expression results   eval :: Env -&gt; Expr -&gt; Int eval env = cata algebra where   algebra (Cst n) = n   algebra (Var x) = env Map.! x   algebra (Op Add xs) = sum xs   algebra (Op Mul xs) = product xs   The dependencies function is based on an algebra function that is only concerned in joining sets of variables identifiers:      Variables terms have only one dependency: the variable itself   Operations have for dependencies the total dependencies of their sub-expressions   dependencies :: Expr -&gt; Set.Set Id dependencies = cata algebra where   algebra (Cst _) = Set.empty   algebra (Var x) = Set.singleton x   algebra (Op _ xs) = Set.unions xs   In both cases, and because cata takes care of the recursion, the implementation almost reflects the specification textually!   Optimized combination of optimizations   Let us now move on the fun part, decomposing our optimization functions bit by bit, before recombining them with great efficiency. We will adapt the optimize function we introduced in our previous post, but with two big differences:   We extracted the algebra from the recursion: to actually run the optimizations, these functions should be given as argument to cata.   Optimizations for Add and Mul are separated: this is to reflect possible real situations in which two teams (and two sets of functions) are specialized and focused on dealing one complex optimization each.   optimizeAdd :: ExprR Expr -&gt; Expr optimizeAdd op@(Op Add _) = optimizeOp op 0 (+) optimizeAdd e = Fix e  optimizeMul :: ExprR Expr -&gt; Expr optimizeMul op@(Op Mul xs)   | not (null (dropWhile (/= cst 0) xs)) = cst 0   | otherwise = optimizeOp op 1 (*) optimizeMul e = Fix e  optimizeOp :: ExprR Expr -&gt; Int -&gt; (Int -&gt; Int -&gt; Int) -&gt; Expr optimizeOp (Op optType xs) neutral combine =   let (constants, vars) = partition isCst xs       constantsVal = map (\\(Fix (Cst x)) -&gt; x) constants       sumCst = foldl' combine neutral constantsVal   in case vars of       []  -&gt; cst sumCst       [y] | sumCst == neutral -&gt; y       ys  | sumCst == neutral -&gt; Fix (Op optType ys)       ys  -&gt; Fix (Op optType (cst sumCst : ys))   We already know how to run these optimizations inefficiently in two tree traversals. Thanks to our previous labour though, we can do much better. Because the algebra are not coupled to the traversal, we combine two algebra into a single algebra before running one single traversal.   We introduce below the means to compose our algebras:      comp combines two algebra by function composition with unFix   compAll combines several algebra by reducing with comp over them   type Algebra f = f (Fix f) -&gt; Fix f  comp :: Algebra f -&gt; Algebra f -&gt; Algebra f comp f g = f . unFix . g  compAll :: Foldable t =&gt; t (Algebra f) -&gt; Algebra f compAll fs = foldr1 comp fs   Using these composition functions, we can write an efficient optimize function:   optimize :: Expr -&gt; Expr optimize = cata (optimizeMul `comp` optimizeAdd)   We did manage to combine several actions in a single traversal. This is a quite important feature which might remind you of our traversal combinators for simple ranges in this post.   This ability to compose easily will allow us to build modular yet efficient software as we will see in the next section.   Partial + Optimize = Eval   Let us take back from where we failed in the last post. We will now build an efficient evaluation function from three different building blocks:      A partial evaluation algebra to replace the known variables by constants   Our addition optimization and multiplication optimization algebra   Our dependencies interpreter that identifies remaining unknowns   Our partial evaluation algebra function will be named replaceKnownVars. It replaces variables bound in its environment argument by their value:   replaceKnownVars :: Env -&gt; ExprR Expr -&gt; Expr replaceKnownVars env = go where   go e@(Var v) =     case Map.lookup v env of       Just val -&gt; cst val       Nothing -&gt; Fix e   go e = Fix e   To finish up the work, we just need to assemble the pieces together:      partial combines the replacement of known variables with the optimization steps   eval runs a partial evaluation, checks whether the expression was reduced to a constant and reports an error with remaining dependencies if it was not   partial :: Env -&gt; Expr -&gt; Expr partial env = cata (compAll [optimizeMul, optimizeAdd, replaceKnownVars env])  eval :: Env -&gt; Expr -&gt; Int eval env expr =   case partial env expr of     (Fix (Cst n)) -&gt; n     e -&gt; error $ \"Missing vars: \" ++ show (dependencies e)   That’s it! Three steps in one traversal in case of success, and a second traversal in case of error, all obtained from modular and independently testable pieces of software.   Note: you can notice there another advantage of working with catamorphisms: pattern matching does not have to be concerned with every possible cases. Since the recursion is handled outside, algebra that transform the AST can make use of the default case.   Conclusion and what’s next   This concludes our introduction of catamorphisms in Haskell.   We went through the mechanisms needed to introduce this recursion scheme, and demonstrated how it could be applied to combine several tree recursions into a single traversal.   We discovered how using this technique might improve the modularity and testability of our code, with minimum expenses in terms of efficiency.   The next posts will focus on discussing the limits of this technics, some of its trade-offs and show how it translates in some other languages.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/01/20/catamorph-dsl-deep-dive.html",
        "teaser": null
      },{
        "title": "Catamorph your DSL (Trade-offs)",
        "excerpt":"This post is a third of the series of post dedicated to notion of Catamorphisms and its application to build Domain Specific Languages (DSLs).   Our first post introduced an Arithmetic DSL that allowed to build expression composed of operations like addition and multiplication integer constants and integers variables. We built several interpreters on top of it, to print, evaluate or optimize our arithmetic expressions. But then we faced an issue: our AST manipulation function could not be composed efficiently.   Our second post introduced the notion of Catamorphism as a way to solve the composability problem we identified in our first approach. Catamorphism allowed us to decouple our operations on the AST from the recursion. This powerful technic allowed us to specify our AST transformation and combine them before traversing our AST.   We have seen some of the benefits of using Catamorphism. Today’s post will discuss the trade-offs associated with it.   Complexity through un-familiarity   The first obvious drawback to the introduction of catamorphism is the increase in complexity they bring.   The addition of a template parameter surely makes our expression noisier. The fixed point of a recursion and the notion of Catamorphism themselves are clearly not straightforward.   However, we could argue that this complexity is mainly due to the pattern not being familiar. Object Oriented programming and design patterns like the Visitor are not straightforward either for most developers going out of university.   If on the contrary, we consider simplicity as defined by Rich Hickey, that means as a measure of complected-ness, Catamorphisms do simplify things quite a bit:      The cata function is only concerned about the recursion   The algebra function is only concerned about the transformation   Efficient composition favours modular and testable code   Post walk does not fit all recursions   Catamorphisms do not fit all of the recursions you might want to perform on your expression. They only deal with one recursion pattern, depth first search post-order traversal, in exchange of what they provide their benefits.   One such constraint is that catamorphisms do force to visit the whole AST of an arithmetic expression. This might not be always necessary.   For example, inside our optimize function, we might not need to visit the “(+ 1 x 2)” branch inside the expression “(* 0 (+ 1 x 2))” to deduce the output of the expression.   The laziness of Haskell might help to reduce this overhead in some particular cases, but it is important to realize that like most algorithms, Catamorphisms are specialised in solving a particular kind of problem.   This should not neither be surprising nor considered a drawback though. Although map (std::transform in C++) is more specialized than fold (a.k.a. reduce or std::accumulate), we use extensively. Using a more specialized algorithm declares our intent more effectively. The next developer might even thank you.   Termination guaranty   One nice thing about catamorphisms is that this recursion scheme is guaranteed to terminate for non-pathological cases (pathological cases include passing to cata a non terminating algebra or an infinite expression to traverse).   On the one side, this is quite an interesting property. We can forget about messing up the termination condition of our recursion and contributing excessively to global warming. The recursion is indeed managed by the catamorphism in a very safe way.   On the other side, it also sets some strict limits to what we can express with this recursion scheme. Some interpreters for some DSL might need to run something indefinitely.   For example, a LISP interpreter might need to be able to express things like a server loop. This is one limitation to keep in mind when choosing a recursion scheme.   Missing tail recursion   Another limitation of Catamorphisms is that this recursion scheme is not tail recursive. In particular, the implementation we provided will consume one additional layer of stack at each recursion.   This problem can however be mitigated by using continuation passing style in our implementation of cata. The advantage of having factored the recursion out is that we can tweak at will and affect all its usage, instead of having to chase down each recursion in our software to fix it.   Here is one implementation of catamorphism using continuation passing style:   import Control.Monad.Cont  cataCps :: (Traversable f) =&gt; (f a -&gt; a) -&gt; Fix f -&gt; a cataCps algebra expr = runCont (recur algebra expr) id  recur :: (Traversable f) =&gt; (f a -&gt; a) -&gt; Fix f -&gt; Cont a a recur algebra (Fix expr) = do   sub &lt;- sequence $ fmap (recur algebra) expr   return (algebra sub)   The Control.Monad.Cont monad will get rid of the stack consumption, by chaining functions instead of recursing. But our expression now needs to be an instance of the Traversable typeclass, a strictly more demanding requirement than Functor.   This is not a problem though. We can ask GHC to generate an instance for us:   {-# LANGUAGE DeriveFunctor, DeriveFoldable, DeriveTraversable #-}  data OpType = Add | Mul deriving (Show, Eq, Ord)  data ExprR r   = Cst Int   | Var Id   | Op OpType [r]   deriving (Show, Eq, Ord, Functor, Foldable, Traversable)   In the end, I do not think tail recursion is a real drawback of catamorphisms. Having extracted and isolated the recursion allows us to make sure we have an efficient of data that does not need to be tail recursive. Ensuring the same level of quality would be much harder if all recursion where done manually.   Conclusion and what’s next   Through this post, we discussed some of the tradeoffs related to the use of the catamorphism recursion scheme.   The main point to be aware of is that Catamorphisms embodies one specific recursion scheme that might not fit our problem. As a general rule, we should refrain from using a solution before having identified the problem. In particular, Catamorphisms allow to easily express terminating interpreters, which is both an interesting guaranty and a hard limitation.   The next and final two posts will conclude our study of Catamorphism by looking at how this concept translates in two other languages: Clojure and C++.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/01/23/catamorph-dsl-tradeoffs.html",
        "teaser": null
      },{
        "title": "Catamorph your DSL (Clojure)",
        "excerpt":"In the previous three posts, we went over the process of building a DSL for arithmetic operations and we introduced the concept of Catamorphism as a way to decouple the traversal of the AST of our DSL from he operations we want to perform on it.   We saw how it could help us compose operations before traversing the AST of our DSL, leading to more efficient composition and better testability.   But Haskell being quite unique, it is quite interesting to take some distance and take time to investigate at how applicable is this concept in other languages.   In this post, we will focus on Clojure, and will:      Build a small arithmetic DSL in Clojure   Look at how catamorphism translates in Clojure   Implement the same interpreters as in Haskell   Marvel at the beauty of coding in Clojure   In the process, we will illustrate that the concept of Catamorphism is related to post-order depth first search traversal of trees.   Growing our arithmetic DSL   Our first task will be to choose a representation for our DSL.   Clojure encourages to use simple data structures as much as possible. We will follow the philosophy of the language and represent our DSL using nested vectors, and two keywords for addition and multiplication.   [:add 1 2  [:mul 0 \"x\" \"y\"]  [:mul 1 \"y\" 2]  [:add 0 \"x\"]]   Using simple data structures does not forbid introducing abstractions. In the same spirit as in Haskell, we will introduce “smart constructor” (factory functions) to build our expression without having to know its internal structure:   (defn cst [n] n) (defn sym [s] s) (defn add [&amp; args] (into [:add] args)) (defn mul [&amp; args] (into [:mul] args))   The following code shows how to construct an arithmetic DSL from these constructors:   (def expr   (add     (cst 1) (cst 2)     (mul (cst 0) (sym \"x\") (sym \"y\"))     (mul (cst 1) (sym \"y\") (cst 2))     (add (cst 0) (sym \"x\"))))   To complete our arithmetic expression, and abstract away from its representation, we also offer some query and extraction functions on it. In particular:      op? returns whether the top expression is an addition or multiplication.   rator extracts the operator of an operation (addition or multiplication)   rands extracts the operands of an operation (addition or multiplication)   (defn rator [e] (first e)) (defn rands [e] (rest e))  (defn cst? [n] (number? n)) (defn sym? [v] (string? v)) (defn op?  [e] (vector? e)) (defn add? [e] (and (op? e) (= (rator e) :add))) (defn mul? [e] (and (op? e) (= (rator e) :mul)))   These query functions will allow us to implement the equivalent of the pattern matching logic of Haskell in our Clojure code.   Introducing Clojure Walk   We already discussed in the previous posts that catamorphisms relate to post-order depth first search traversal of the AST of our DSL. Clojure offers a really good implementation of tree traversals in its clojure.walk namespace.   Our code will rely on this namespace, as well as some additional standard namespaces inclusions. You can find them below:   (ns arithmetic   (:require     [clojure.string :as string]     [clojure.set :as set]     [clojure.walk :as walk]     ))   In particular, clojure.walk/postwalk will be of great interest to us. It visits all nodes in tree, apply a transformation on it, before visiting their father node recursively, until it reaches the root node.   Let us see how it works by tracing the visit of all nodes along the traversal:   (walk/postwalk   #(do (print (str % \" \")) %)   [:add 1 [:mul \"x\" 2]])  :add 1 :mul x 2 [:mul \"x\" 2] [:add 1 [:mul \"x\" 2]]      The walk starts by the leftmost element and goes as deep as it possibly can   Each node is scanned and transformed exactly once (we used the identity here)   The father of a group of node is visited right after all its children   Note that there is one big difference with the Catamorphism we had in Haskell: because we visit every single node, we will also visit the keywords :add and :mul of our DSL. This is something we will have to take this into account.   Pretty print walk   Let us put the postwalk function to use by translating in Clojure our most basic interpreter, the pretty printer.      walk/postwalk plays the role of the cata function in Haskell   The first argument of postwalk is the algebra (named for clarity only)   The :else handles the case of the keywords :add and :mul   The code below is the full Clojure implementation:   (defn print-expr [expr]   (walk/postwalk     (fn algebra [e]       (cond         (cst? e) (str e)         (sym? e) e         (add? e) (str \"(+ \" (string/join \" \" (rest e)) \")\")         (mul? e) (str \"(* \" (string/join \" \" (rest e)) \")\")         :else e))     expr))   Using the function results in the result we expect:   (def expr   (add     (cst 1) (cst 2)     (mul (cst 0) (sym \"x\") (sym \"y\"))     (mul (cst 1) (sym \"y\") (cst 2))     (add (cst 0) (sym \"x\"))))  (print-expr expr) =&gt; \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 y))\"   Except for the matching of the operation keywords, the Clojure implementation looks really much like the Haskell implementation of our previous post:   prn :: Expr -&gt; String prn = cata algebra where   algebra (Cst n) = show n   algebra (Var x) = x   algebra (Op Add xs) = \"(+ \" ++ unwords xs ++ \")\"   algebra (Op Mul xs) = \"(* \" ++ unwords xs ++ \")\"   Although it leverages very different means, Clojure achieves the same kind of simple, decoupled, and close-to-specification code than Haskell. Beautiful, right?   Evaluate and dependencies   We can as easily translate to Clojure our next two most straightforward interpreters, eval (renamed evaluate since eval already exists in Clojure) and dependencies.   The evaluate function below needs an environment holding the value of the variables in the arithmetic expression. To make it simple, we used a Clojure hash map (which we can consult using the get function).   (defn evaluate [env e]   (walk/postwalk     (fn [e]       (cond         (sym? e) (get env e)         (add? e) (reduce + (rest e))         (mul? e) (reduce * (rest e))         :else e))     e))   The implementation of dependencies, which lists all the variables of the expression, is also quite small and simple to follow. It makes use of Clojure standard sets to gradually accumulate all variable names from an arithmetic expression:   (defn dependencies [e]   (walk/postwalk     (fn [e]       (cond         (cst? e) #{}         (sym? e) #{e}         (op? e) (apply set/union (rands e))         :else e))     e))   Composable optimisations   After the appetizers, the main dish: the implementation of the arithmetic expression optimization functions.   To show how easy composition of tree walking functions, we will provide two separate functions to optimize the addition and the multiplication:   (defn optimize-add [e]   (if (add? e)     (optimize-op e + 0)     e))  (defn optimize-mul [e]   (if (mul? e)     (if (some #{(cst 0)} e)       (cst 0)       (optimize-op e * 1))     e))   These two functions make use of the optimize-op helper function that contains their common parts, which you can consult here.   Because our solution in Clojure did not have to include a mysterious Fix type to create an infinite type (as it was required in Haskell), composition of our “algebra” is the standard function composition:   (defn optimize [e]   (walk/postwalk     (comp optimize-mul optimize-add)     e))   It almost looks too simple to be true. Let us try it out to check if we are not dreaming in high definition:   (print-expr expr) =&gt; \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"  (print-expr (optimize expr)) =&gt; \"(+ 3 (* 2 y) x)\"   Partial application   Our last remaining challenge is to implement the partial evaluation of an arithmetic expression, which we will name partial-eval to avoid naming conflicts with existing Clojure functions.   To do so, we will create a replace-var function whose goal is to replace variables bound in the evaluation environment with their respective value. We can combine this function with our optimization functions to obtain a fully fledged partial application that simplifies expression in one single tree traversal.   (defn replace-var   [env x]   (if (string? x) (get env x x) x))  (defn partial-eval   [env e]   (walk/postwalk     (comp optimize-mul optimize-add #(replace-var env %))     e))   Let us see if it works. We will partially apply our initial expression with “y” bound to zero:   (print-expr expr) =&gt; \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"  (print-expr (partial-eval {\"y\" 0} expr)) =&gt; \"(+ 3 x)\"   Interestingly, if we partially evaluate our function with a environment holding all the variables appearing in the expression, the result is identical to a call to evaluate:   (print-expr (optimize expr)) =&gt; \"(+ 3 (* 2 y) x)\"  (evaluate {\"x\" 1 \"y\" 2} expr) =&gt; 8  (partial-eval {\"x\" 1 \"y\" 2} expr) =&gt; 8   Conclusion and what’s next   In a few lines of code, we managed to build an arithmetic DSL, with all the interesting features we built in Haskell. The code is about the same length, as simple and composable as in Haskell.   The main difference to me is the efforts we had to put in to get the same result. There was no need to invent anything complicated, like parameterized recursion, to get to this result.   But on the other hand, we were able to count on the amazing clojure.walk namespace, and we lost almost all the type safety we had in Haskell.   As for myself, I enjoyed implementing both of these solutions equally well. I hope you enjoyed the ride too!   This concludes our study of how catamorphism translates into Clojure. The next post will be dedicated in trying to do the same exercise in C++, a much more mainstream language than our previous candidate.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Clojure"],
        "url": "/blog/2017/01/26/catamorph-dsl-clojure.html",
        "teaser": null
      },{
        "title": "Catamorph your DSL (C++ Port)",
        "excerpt":"In the previous posts, we went over the process of building a DSL for arithmetic operations and we introduced the concept of Catamorphism as a way to decouple the traversal of the AST from the operations we want to perform on it.   We saw how it could help us compose operations before traversing the AST of our DSL, leading to more efficient composition and better testability.   Unless you are quite familiar with catamorphisms, you might want first to read these previous posts before this one:      Catamorph your DSL: Introduction   Catamorph your DSL: Deep Dive   Catamorph your DSL: Trade-offs   All these previous posts were based on Haskell. Because Haskell is such a special (wonderful) language, the last post started to explore whether this concept would port as nicely in other languages.   We translated our Haskell code into Clojure, a functional language that put much less emphasis on types as Haskell. We saw that this concept translated to a post-order depth first search. The resulting Clojure code was both short and elegant.   This post will be focused on exploring the limits of the applicability of this concept some more, by trying to bring it into C++.   Boost to the rescue   We could implement our DSL in C++ with only the STL available, using Design Patterns such as the Visitors. To keep the code short and concise, we will however rely boost as well. All the code that follows will assume the following Boost header inclusions:   #include &lt;boost/algorithm/string/join.hpp&gt; #include &lt;boost/range/algorithm.hpp&gt; #include &lt;boost/range/adaptors.hpp&gt; #include &lt;boost/range/numeric.hpp&gt; #include &lt;boost/variant.hpp&gt;   In particular, boost::variant will be one of the cornerstone of the design, as it allows to avoid the Visitor design pattern. You might want to have a look at the documentation of boost::variant before proceeding.   The rest of the header are mostly for convenience. We could do without it, but at the expense of some more code to write.   Arithmetic expressions in C++ Boost   There are many ways we could represent our expression DSL in C++. We could choose to use the Visitor design pattern for example. The solution below is based instead of boost::variant for convenience.   The recursive expression_r implements our open recursive data type. This type is implemented as a boost::variant on:      nb which represents an integer constant   id which represents a variable identifier   add_op which represents an addition operation   mul_op which represents an multiplication operation   The add_op and mul_op operations are themselves factorized as a single tagged op data type. Two tags represent the two operations, add_tag and mul_tag.   using nb = int; using id = std::string;  struct add_tag {}; struct mul_tag {};  template&lt;typename Tag, typename R&gt; struct op {    op() = default;     template&lt;typename Range&gt;    explicit op (Range const&amp; rng) : m_rands(rng.begin(), rng.end()) {}        std::vector&lt;R&gt; const&amp; rands() const { return m_rands; }     private:    std::vector&lt;R&gt; m_rands; };  template&lt;typename R&gt; using add_op = op&lt;add_tag, R&gt;; template&lt;typename R&gt; using mul_op = op&lt;mul_tag, R&gt;;  template&lt;typename R&gt; using expression_r = boost::variant&lt;int, id, add_op&lt;R&gt;, mul_op&lt;R&gt;&gt;;   To get our recursive expression, we will use the same trick as we used in Haskell: we will compute the fixed point of the type recursion.   As in Haskell, C++ is not able to create infinite types. The Fix wrapper type of Haskell needed to circumvent this limitation is replaced by the boost::recursive_wrapper. The overall design is the same:   struct expression    : boost::recursive_wrapper&lt;expression_r&lt;expression&gt;&gt; {    using boost::recursive_wrapper&lt;expression_r&lt;expression&gt;&gt;::recursive_wrapper; };   Note: this naive implementation triggers deep copies at each level of our AST. This might lead to a quadratic behaviour in the depth of our tree when playing with transformations on our AST. A production ready implementation would have to handle these aspects we voluntarily left out for simplicity. We will come back to this issue in the conclusion.   Factory functions and accessors   The trouble with constructors of class templates in C++ is that they require their explicit templates to be listed in the code. The usual trick is to define factory functions outside of the class to automatically deduce the template parameters.   We will define some factory functions to help us write code more easily. These functions are somehow similar to the “smart constructors” of Haskell:   expression cst(int i) { return expression(i); };  expression var(id id) { return expression(id); };  expression add(std::vector&lt;expression&gt; const&amp; rands) {    return expression(add_op&lt;expression&gt;{ rands }); }  expression mul(std::vector&lt;expression&gt; const&amp; rands) {    return expression(mul_op&lt;expression&gt;{ rands }); }   Having introduced this layer of “named constructors” allows us create expression more succinctly and to better declare our intent:   expression e = add({     cst(1),     cst(2),     mul({cst(0), var(\"x\"), var(\"y\")}),     mul({cst(1), var(\"y\"), cst(2)}),     add({cst(0), var(\"x\")})     });   Similarly, to “pattern match” on our boost::variant, we will introduce some helper accessors functions. Indeed, the trouble with boost::get is that it requires explicit templates to be listed in the code. Dedicated and correctly named functions will simplify the pattern matching greatly by removing noisy templates from our code:   template &lt;typename T&gt; int const* get_as_cst(expression_r&lt;T&gt; const&amp; e) {    return boost::get&lt;int&gt;(&amp;e); }  template &lt;typename T&gt; id const* get_as_var(expression_r&lt;T&gt; const&amp; e) {    return boost::get&lt;id&gt;(&amp;e); }  template &lt;typename T&gt; add_op&lt;T&gt; const* get_as_add(expression_r&lt;T&gt; const&amp; e) {    return boost::get&lt;add_op&lt;T&gt;&gt;(&amp;e); }  template &lt;typename T&gt; mul_op&lt;T&gt; const* get_as_mul(expression_r&lt;T&gt; const&amp; e) {    return boost::get&lt;mul_op&lt;T&gt;&gt;(&amp;e); }   Note: boost::variant also offers visitors to handle pattern matching as an alternative to boost::get. But as our interpreters will not need to exhaustively match all cases, sticking to boost::get ends up being less code. This is ultimately a matter of taste: we could have done the other choice instead.   Our C++ catamorphism   Now that we have our expression_r type, we will need to write the equivalent of the catamorphism function cata of Haskell. This function will be responsible for lifting local AST transformations into operations on the whole AST.   The details on how to build a catamorphism from an open recursive type were already covered in the previous post on catamorphism in Haskell. This section will only aim at translating this code into C++.   Functor Instance   The first step is to make our expression_r type an instance of a Functor. In C++, one way to do it is to implement fmap for our type:   The map argument represents the transformation to apply Constants and variable matches are left unchanged by this transformation For operations, we recursively apply the transformation on the sub-expressions We use boost::ranges to make the code more succinct:   template&lt;typename A, typename M&gt; auto fmap(M map, expression_r&lt;A&gt; const&amp; e) {    using B = decltype(map(std::declval&lt;A&gt;()));    using Out = expression_r&lt;B&gt;;        if (auto* o = get_as_add(e))       return Out(add_op&lt;B&gt;(o-&gt;rands() | transformed(map)));           if (auto* o = get_as_mul(e))       return Out(mul_op&lt;B&gt;(o-&gt;rands() | transformed(map)));        if (auto* i = get_as_cst(e)) return Out(*i);    if (auto* v = get_as_var(e)) return Out(*v);    throw_missing_pattern_matching_clause(); }   Catamorphism   Next, we need to write the catamorphism function, whose goal is to apply fmap at each level of our expression, starting from the lower levels.   The details behind the inner workings of this function are provided in a previous post on Haskell. We only translate here this definition to C++:      We replace function composition in Haskell by nested function call in C++   We use get to extract the expression from the recursive_wrapper   Some of the types listed below are deduced automatically. We left them in the code to show what is going on under the cover:   template&lt;typename Out, typename Algebra&gt; Out cata(Algebra f, expression const&amp; ast) {    return f(       fmap(          [f](expression const&amp; e) -&gt; Out { return cata&lt;Out&gt;(f, e); },          ast.get())); }   One noticeable drawback of this implementation is the need to provide the output type of the cata function explicitly. This could probably be dealt with.   Pretty printing our expressions in C++   We now have everything to start implementing our first interpreter, our expression pretty printer. It is noticeably more verbose than in both Haskell and Clojure, but not that much. I was quite surprised by the overall concision:      print_alg handles pattern matching and the two trivial cases   print_op handles the operations by joining the sub-expression strings, prepends the operation and wraps the whole with parentheses   template&lt;typename Tag&gt; std::string print_op(op&lt;Tag, std::string&gt; const&amp; e, std::string const&amp; op_repr) {    return std::string(\"(\") + op_repr + \" \" + boost::algorithm::join(e.rands(), \" \") + \")\"; }  std::string print_alg(expression_r&lt;std::string&gt; const&amp; e) {    if (auto* o = get_as_add(e)) return print_op(*o, \"+\");    if (auto* o = get_as_mul(e)) return print_op(*o, \"*\");    if (auto* i = get_as_cst(e)) return std::to_string(*i);    if (auto* v = get_as_var(e)) return *v;    throw_missing_pattern_matching_clause(); }   At call site, the code is not that verbose either. The main drawback is the need to specify the output type of the catamorphism (std::string in this case):   expression e = add({   cst(1),   cst(2),   mul({cst(0), var(\"x\"), var(\"y\")}),   mul({cst(1), var(\"y\"), cst(2)}),   add({cst(0), var(\"x\")})   });  std::cout &lt;&lt; cata&lt;std::string&gt;(print_alg, e) &lt;&lt; '\\n';  //Will output: \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"   Now, this is not the most efficient code that we could come up with. It does create quite a lot of intermediary strings. This is the subject for another time.   Eval and dependencies   We can as translate to C++ our next two most straightforward interpreters, eval and dependencies. The eval function needs an environment holding the value of the variables in the arithmetic expression. To make it simple and keep the code short, we will:      Rely on a std::map from id to integer to model this environment   Ignore errors such as an unbound variable in the environment   In addition, and to compensate for the absence of currying in Haskell, our eval function returns a lambda:   using env = std::map&lt;id, nb&gt;;  auto eval_alg(env const&amp; env) {    return [&amp;env] (expression_r&lt;int&gt; const&amp; e)    {       if (auto* o = get_as_add(e))          return boost::accumulate(o-&gt;rands(), 0, std::plus&lt;int&gt;());                 if (auto* o = get_as_mul(e))          return boost::accumulate(o-&gt;rands(), 1, std::multiplies&lt;int&gt;());              if (auto* v = get_as_var(e)) return env.find(*v)-&gt;second;       if (auto* i = get_as_cst(e)) return *i;       throw_missing_pattern_matching_clause();    }; }  int eval(env const&amp; env, expression const&amp; expr) {    return cata&lt;int&gt;(eval_alg(env), expr); }   The dependencies functions lists all the variables of the expression. It sub-expressions are transformed to a set of variable identifiers, which are combined (set union) while climbing up the AST.   template&lt;typename Tag&gt; std::set&lt;id&gt; join_sets(op&lt;Tag, std::set&lt;id&gt;&gt; const&amp; op) {    std::set&lt;id&gt; out;    for (auto r: op.rands())       out.insert(r.begin(), r.end());    return out; }  std::set&lt;id&gt; dependencies_alg(expression_r&lt;std::set&lt;id&gt;&gt; const&amp; e) {    if (auto* o = get_as_add(e)) return join_sets(*o);    if (auto* o = get_as_mul(e)) return join_sets(*o);    if (auto* v = get_as_var(e)) return {*v};    return {}; }  std::set&lt;id&gt; dependencies(expression const&amp; e) {    return cata&lt;std::set&lt;id&gt;&gt;(dependencies_alg, e); }   Composable C++ optimisations   Until now, the main advantage of introducing Catamorphism was to specify local transformations, which the cata function could lift to operations on the whole AST of our arithmetic DSL.   We will now leverage on the other advantage of Catamorphism, the ability to compose them efficiently, to implement our arithmetic AST optimization functions.   We left out the detailed implementation of the has_zero and optimize_op functions in the snippet below. The detailed implementation of these functions is available on GitHub.   This allows us to concentrate on the real value added by Catamorphisms, composability of transformations:      opt_add_alg is only concerned in optimising additions   opt_add_mul is only concerned in optimising additions   optimize_alg is only concerned in combining these algebra into one   This leads to the following code:   expression opt_add_alg(expression_r&lt;expression&gt; const&amp; e) {    if (auto* op = get_as_add(e))       return optimize_op(*op, 0, std::plus&lt;int&gt;());    return e; }  expression opt_mul_alg(expression_r&lt;expression&gt; const&amp; e) {    if (auto* op = get_as_mul(e))    {       if (has_zero(op-&gt;rands()))          return cst(0);       return optimize_op(*op, 1, std::multiplies&lt;int&gt;());    }    return e; }  expression optimize_alg(expression_r&lt;expression&gt; const&amp; e) {    return opt_mul_alg(opt_add_alg(e).get()); }   Note that how the optimize_alg function is able to combine the two algebra by composing them. The call to get allows to unwrap the expression of the first algebra, before calling the second algebra. We can give it a try:   expression e = add({   cst(1),   cst(2),   mul({cst(0), var(\"x\"), var(\"y\")}),   mul({cst(1), var(\"y\"), cst(2)}),   add({cst(0), var(\"x\")}) });  //Initial expression std::cout &lt;&lt; cata&lt;std::string&gt;(print_alg, e) &lt;&lt; '\\n';  //Will output \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"  //Optimized expression auto o = cata&lt;expression&gt;(optimize_alg, e); std::cout &lt;&lt; cata&lt;std::string&gt;(print_alg, o) &lt;&lt; '\\n';    //Will output \"(+ (* y 2) x 3)\"   Partial evaluation   Our last remaining challenge is to implement the partial evaluation of an arithmetic expression.   The partial_eval_alg simply replaces variables bound in the evaluation environment with their respective value. As for our evaluation function, our partial evaluation returns a lambda to compensate for the lack of currying in C++.   auto partial_eval_alg(env const&amp; env) {    return [&amp;env] (expression_r&lt;expression&gt; const&amp; e) -&gt; expression    {       if (auto* v = get_as_var(e))       {          auto it = env.find(*v);          if (it != env.end()) return cst(it-&gt;second);          return var(*v);       }       return e;    }; }   We can combine this function with our optimization functions to obtain a fully fledged partial application that simplifies expression in one single tree traversal.   expression partial_eval(env const&amp; env, expression const&amp; e) {    return cata&lt;expression&gt;(       [&amp;env](expression_r&lt;expression&gt; const&amp; e) -&gt; expression {          return optimize_alg(partial_eval_alg(env)(e).get());       },       e); }   We can also re-implement our evaluation function in terms of our partial evaluation:      If the resulting expression, after optimizations, is a constant, we output it.   Otherwise, we can use our dependency function to output the missing variables   This leads to the following evaluation function, which handles errors much nicer than our previous one:   int eval_2(env const&amp; env, expression const&amp; e) {   auto reduced = partial_eval(env, e);   if (auto* i = get_as_cst(reduced.get()))return *i;   throw_missing_variables(dependencies(reduced)); }   We can give it a try to convince ourselves that it works:   expression e = add({   cst(1),   cst(2),   mul({cst(0), var(\"x\"), var(\"y\")}),   mul({cst(1), var(\"y\"), cst(2)}),   add({cst(0), var(\"x\")}) });  //Environment of evaluation env full_env = {     {\"x\", 1},     {\"y\", 2} };  //Evaluations std::cout &lt;&lt; eval(full_env, e3) &lt;&lt; '\\n'; std::cout &lt;&lt; eval_2(full_env, e3) &lt;&lt; '\\n';  //Will output 8 8   Conclusion   In this post, we managed to port the Catamorphism notion in C++ to build a series of arithmetic DSL interpreters made of:      Composable local operations (our different algebra)   Decoupled from the traversal of the AST (handled by cata)   Avoiding any kind of mutations on our AST   The complete resulting code is about three times the length of the equivalent Haskell or Clojure code (320 lines give or take), which is quite good overall. But there is a catch: this implementation is unrealistically simplistic. This is the topic of the next section.   What’s the catch?   Our simplistic memory management did exhibit some problematic quadratic behaviour in terms of copy. Addressing this concern would require some manual work: C++ offers no standard support for immutable data structure with structural sharing in its standard library, so we would probably have to rely on move semantics.   We also had some remaining issues regarding type deduction, which would require some more tricks to improve. The biggest issue is however dealing with the long error messages GCC outputs upon the simplest type error. Try removing the .get() in the catamorphism function, or messing up with the types of an algebra function, and you shall see. Concepts could probably help there.   So I do not think that the 320 lines of C++ code do quite compare in maturity with the 120 corresponding lines in Haskell.   On catamorphims in C++   This concludes our study of the applicability of Catamorphism in C++. Overall, I felt like this design quite not as natural as it was in Haskell or Clojure. It sometimes felt like going against the idiomatic use of the language, which is not a good sign.   I recently read some good articles on the functional paradigm bursting in into C++ (like this series of posts on http://www.modernescpp.com).   Although this is true that C++ made great leaps in this direction by encouraging higher order functions usage with the addition of lambdas, it felt awkward using them in this context.   But the main difficulty in porting this concept to C++ is that it is implicitly based on efficient persistent data structure to exist in the language. And the support for immutable data and persistent data structures in C++ is simply not there.   To summarize, implementing catamorphisms in C++ was quite a fun exercise (except for the compilation error messages spanning over 2 or more screens), but it did not feel like it fits C++ as it does for Haskell or Clojure.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2017/01/30/catamorph-dsl-cpp.html",
        "teaser": null
      },{
        "title": "Code your own Quick Check",
        "excerpt":"In the next posts, we will go through a small implementation challenge. The goal will be to implement our own limited version of QuickCheck, the famous generative testing framework of Haskell.   Whether or not you do know about the concept of generative testing, I advice you to have a look at the original publication of QuickCheck. This is indeed a very good and quite enlightening read.   Our goal will be to reproduce something close to the features described in this publication, all on our own. Through this exercise, we will gain some better understanding of the magic that happens inside QuickCheck.      The goal of today is to implement the basic features of QuickCheck   The next post will be focused on testing higher order functions   Our last post will be focused on shrinking counter examples   We will name our own generative testing framework RapidCheck to avoid confusion when referring to the real QuickCheck.   Introduction   QuickCheck is a framework that allows to test properties that we think should hold on our functions. It is pretty versatile and can be used in many different contexts:      To test that the code your wrote does behave correctly   To investigate on the behaviour of some code you are reading   To test specifications against a working code   QuickCheck is not a proof system and is not a replacement for example based testing either. QuickCheck is more like a nasty user which will try everything he can to break your software.   Romeu Moura did a great talk explaining what property-based testing is and is not about. I encourage you to have a look at it.   Our goal for today   Our goal for today will be to implement a subset of our RapidCheck that supports checking some basic properties. We will keep the topic of testing higher order function for our next post.   More practically, we give ourselves the goal to test the two following properties on the Greatest Common Divisor with RapidCheck, all by the end of this post.   The prop_gcd is a valid property. Multiplying the Greatest Common Divisor of a and b with the Lowest Common Multiple of a and b should be equal to the produce of a and b. We expect this test to pass.   prop_gcd :: Integer -&gt; Integer -&gt; Bool prop_gcd a b = a * b == gcd a b * lcm a b  rapidCheck prop_gcd &gt; Success   The prop_gcd_bad is an invalid property. The Greatest Common Divisor of two numbers might be equal to 1 if these numbers are coprime. We expect this test to fail (with high probability) and we expect RapidCheck to provide us a counterexample.   prop_gcd_bad :: Integer -&gt; Integer -&gt; Bool prop_gcd_bad a b = gcd a b &gt; 1  rapidCheck prop_gcd_bad &gt; Failure {seed = -1437169021,            counterExample = [\"1076253199\",\"40866101\"]}   How does the rapidCheck function knows how to test these properties? How does it recognize which kind of input to generate? These are the questions that will be answered throughout this post.   We will use the same vocabulary used inside the original publication of QuickCheck. Our implementation will differ on several aspects from the one of the publication, in the spirit of simplifying things a bit.   Selecting our outputs   Let us start by addressing the simplest of our needs: returning useful results as output to the tests. Needless to say, because Property Based Testing is based on generating random inputs, returning “Test Failed” is not really helpful. The output should at the very least contain enough information to replay the failing scenario.   We will select two useful pieces of information in case of failure:      The counter example itself (the failure inputs) as strings   The random seed used to generate the counter example   This translates into the following Result type:   data Result   = Success                     -- In case of success, no additional information   | Failure {     seed :: Int,                -- The seed used to generate the counter example     counterExample :: [String]  -- The counter example (failing inputs to string)   } deriving (Show, Eq, Ord)    -- Useful instances to print and compare Results   To help dealing with the Failure case more easily, we create the following helper function overFailure. It takes a function, applies it on the Result if it is a Failure, and returns the updated value.   overFailure :: Result -&gt; (Result -&gt; Result) -&gt; Result overFailure Success _ = Success overFailure failure f = f failure   We also provide a Monoid instance for our result type. A Monoid instance is a type offering a default value, mempty in Haskell, and a binary associative operation, mappend in Haskell.   For Result, we will select a meaning that will make it easier for us to collapse several test results into one single result:      mempty: running no test case always results in Success   mappend: if at least one test case fails, the whole test fails   instance Monoid Result where   mempty = Success   mappend lhs@Failure{} _ = lhs   mappend _ rhs = rhs   Note that our implementation is left biased: it will report the leftmost failure if both test cases fail. Applied to a list of several test cases, it will therefore report the first error found in the list.   Generating random inputs   In order to be able to test properties over our functions, RapidCheck needs to be able to generate some random values. We model a generator of random input of type a by the type Gen parameterized on the type it generates.   This Gen a is a wrapper around a function that takes a pseudo-random generator (an instance of StdGen from the System.Random module) and returns an element a.   We also provide an typeclass (a kind of interface) named Arbitrary for types for which a standard generator is defined.   newtype Gen a = Gen {   runGen :: StdGen -&gt; a }  class Arbitrary a where   arbitrary :: Gen a   Note that the function wrapped in Gen is pure. Calling it twice with the same random generator will return the same result twice. It means that the caller of the function is responsible for providing an updated pseudo random generator to the function to get different results.   This might seem awkward, but we have to remember that our goal is to output reproducible test cases for the API user. Being able to replay a failing scenario deterministically is an important feature. A pure function is the safest way for us to guaranty this property.   Property   The goal of our RapidCheck library is to check to properties on our code. Properties are predicates we can run generative test against, to verify if they hold. We identify several characteristics of a Property:      We need to test it, and generate a Result from it   This result is based on randomly generated inputs   Presented differently, a Property is a computation that return a Result through a pseudo-random generation process. It means we can model a property as a wrapper around Gen Result:   newtype Property = Property {   getGen :: Gen Result }   To avoid systematic unwrapping of the Property, we provide the following helper function runProp. It just calls the generator function with the provided pseudo random generator StdGen.   runProp :: Property -&gt; StdGen -&gt; Result runProp prop rand = runGen (getGen prop) rand   This Property type might seem incomplete. In particular, there is no mention of the random inputs that drives the generation of the Result. Surely, this is a problem!   Not if we think of a Property as the result of a construction process that integrates the generation of the random inputs together with the predicate we want to verify. The actual “construction process” of a Property is the subject of the next section.   Testable inputs   The purpose of this section is to define the inputs of our rapidCheck function. Before we go further, let us go through an inventory phase, in which we will review what we already know and express on paper what we really want.   Inventory   Our ultimate goal is to test any property expressed as a function that returns something we could interpret as a Result. From now on, we will refer to such function as testable function. In particular, any function returning a Bool or a Result (like our prop_gcd function) should qualify.   prop_gcd :: Integer -&gt; Integer -&gt; Bool prop_gcd a b = a * b == gcd a b * lcm a b   Each of the argument of a testable function should have a random generator associated with it. We already know how to express this constraint: all arguments should implement the Arbitrary type.   We also have a nice target abstraction for our testable functions, the type Property we introduced earlier. We want a way to transform such testable functions into a Property.   For this transformation to make sense, the generator wrapped by the Property should represent the combined effect of the generators of each of the arguments of the original function.   Our problem   Our problem is that there are theoretically no limits to the number of arguments this function could take. We could try to take a shortcut and provide overloads until we reached a maximum number of arguments, but we can do better.   The solution is to break down our problem and think in terms of mathematical induction. This means finding a base case, a set of function with no arguments which we can convert to a Property, and identifying a induction step to grow the number of arguments supported one at a time.   We define Testable as the typeclass that represents the functions that can be transformed into a Property (our testable function, or alternatively, something we can generate a Result from):   class Testable a where   property :: a -&gt; Property   Our goal is identify a base case of known Testable instances, and implement an induction step to grow this set of instances.   Base case   Based on our inventory, we know that functions with no arguments (constants) that return a result or a boolean are convertible to a property.   These constants do not have any random inputs influencing them. As a consequence, a Property obtained from one such function should always produce the same consistent result. This is expressed in the code below:   -- Property is trivially convertible to Property instance Testable Property where   property = id  -- Result is convertible to Property by creating -- a generator that always return this same result instance Testable Result where   property r = Property (Gen (const r))  -- Bool can be converted to Result -- Result can be converted to a Property -- By composition we get that Bool is convertible to Property instance Testable Bool where   property = property . toResult where       toResult b = if b then Success                         else Failure { seed = 0, counterExample = []}   Induction step   The inputs of our induction step are an instance of a Testable function, named testable and a printable argument implementing Arbitrary. Our desired output is a testable instance for the function taking the additional argument as parameter.   Let us write this desire, with the implementation left undefined:   instance   (Show a, Arbitrary a,        -- Given a type `a` supporting random generation    Testable testable)          -- And an already existing testable function   =&gt; Testable (a -&gt; testable)  -- The function (a -&gt; testable) is also testable   where     property = undefined       -- With the provided implementation   Now, let us assume the existence of a function named forAll that takes a generator and our function a -&gt; testable and return a new testable instance.   Then we could define our instance as follows, by providing the generator of our argument a to the forAll function:   instance   (Show a, Arbitrary a,    Testable testable)   =&gt; Testable (a -&gt; testable)   where     property f = forAll arbitrary f  forAll :: (Show a, Testable testable) =&gt; Gen a -&gt; (a -&gt; testable) -&gt; Property forAll = undefined   We just pushed the problem a bit further down the road. But the forAll really needs its next section for it alone.   Implementing forAll   Before diving into the implementation of the forAll function, let us note that it is clearly more general than our Testable instance.   It does not require a type to implement Arbitrary and instead asks for a generator of argument. This function is both at the heart of QuickCheck and a very important tool when dealing with random generation of inputs.   This allows to define specialized random generator for the same argument. This in turns allows to test some properties that hold in specific equivalence classes only.   Now, to the implementation.   The code will rely on the use of the split function of the module System.Random module. This function allows to create two StdGen pseudo random generator from a single one. It is important to note it is a pure function, meaning its result is deterministic.   The Property created by forAll is a wrapper around a generator: it takes as input a StdGen, named rand, to output a Result. Inside the returned Property, we will split this pseudo random generator in two, named rand1 and rand2.      We use rand1 to generate the new argument arg to the testable function   We use arg to get subProp, which is already an instance of testable (by our induction hypothesis and the type of forAll)   We use rand2 to run subProp and generate our result   In case of failure, we enrich the counter-example with the value of arg   You can find the full implementation below:   forAll :: (Show a, Testable testable) =&gt; Gen a -&gt; (a -&gt; testable) -&gt; Property forAll argGen prop =   Property $ Gen $ \\rand -&gt;             -- Create a new property that will     let (rand1, rand2) = split rand     -- Split the generator in two         arg = runGen argGen rand1       -- Use the first generator to produce an arg         subProp = property (prop arg)   -- Use the `a` to access the sub-property         result = runProp subProp rand2  -- Use the second generator to run it     in overFailure result $ \\failure -&gt; -- Enrich the counter-example with `arg`         failure { counterExample = show arg : counterExample failure }   Implementing rapidCheck   The goal of rapidCheck is to take a Testable instance as parameter, and try its associated Property with different values of seeds, in an attempt to find a counter-example.   We will first define a function rapidCheckImpl that takes as parameter a starting seed for our pseudo random generator, and a maximum number of attempts to try to find a counter-example:      runOne will trigger one such attempt, with a seed provided as parameter. Upon failure, it will complete the error report with the seed.   runAll will run all attempts and exploit the Monoid instance for Result to collapse these results together   rapidCheckImpl :: Testable prop =&gt; Int -&gt; Int -&gt; prop -&gt; Result rapidCheckImpl attemptNb startSeed prop = runAll (property prop)   where     runAll prop = foldMap (runOne prop) [startSeed .. startSeed + attemptNb - 1]     runOne prop seed =       let result = runProp prop (mkStdGen seed)       in overFailure result $ \\failure -&gt; failure { seed = seed }   We can note that, once again, this function is side effect free. It will return a deterministic result.   We finally introduce the functions rapidCheck to get the non-determinism needed to solve our problem. This function produces a side-effect to get the initial seed to feed rapidCheckImpl. We also add rapidCheckWith, as a variation of rapidCheck that accept the maximum number of attempts as parameter.   rapidCheck :: Testable prop =&gt; prop -&gt; IO Result rapidCheck = rapidCheckWith 100  rapidCheckWith :: Testable prop =&gt; Int -&gt; prop -&gt; IO Result rapidCheckWith attemptNb prop = do   seed &lt;- randomIO   return $ rapidCheckImpl attemptNb seed prop   There they are, the only two functions with side effects of our RapidCheck module. It is quite remarkable how far we can push side effects away from the core implementation of a module whose main purpose is to generate random inputs to find counter-examples.   Enjoying rapidCheck   Now that we did all this work, it is time to enjoy. We will run our initial test cases and have a look at how it behaves.   Both of our test cases takes two integers and returns a boolean. We know from the previous sections that a function with no parameters (a constant) returning a boolean implements Testable. What is missing for the whole function to be Testable is an Arbitrary instance for our Integer type:      We use the pure function next of System.Random to generate a Int   We convert this Int to an Integer (an arbitrary large number)   Because we generated a Int, the random generator will not cover all the spectrum of values an Integer could have. We will ignore this here (*), as the only reason why we use an Integer was to avoid overflows:   instance Arbitrary Integer where   arbitrary = Gen $ \\rand -&gt;     fromIntegral (fst (next rand))   We expect our first test case to pass as it verifies a valid property of our GCD:   prop_gcd :: Integer -&gt; Integer -&gt; Bool prop_gcd a b = a * b == gcd a b * lcm a b  rapidCheck prop_gcd &gt; Success   Our second test case should fail with high probability. RapidCheck should be able to exhibit a counter example based on two coprime numbers. And it does:   prop_gcd_bad :: Integer -&gt; Integer -&gt; Bool prop_gcd_bad a b = gcd a b &gt; 1  rapidCheck prop_gcd_bad &gt; Failure {seed = -1437169021,            counterExample = [\"1076253199\",\"40866101\"]}   Note that if we had used Int instead of Integer, RapidCheck should be able to find a counter example to our valid prop_gcd properties. Because an Int has not an infinite precision, we expect RapidCheck to find integer overflow issues. And it does:   instance Arbitrary Int where   arbitrary = Gen $ \\rand -&gt; fst (next rand)  prop_gcd_overflow :: Int -&gt; Int -&gt; Bool prop_gcd_overflow a b = a * b == gcd a b * lcm a b  rapidCheck prop_gcd_overflow &gt; Failure {seed = -881134321,            counterExample = [\"171542757\",\"1235104953\"]}   _(*) In real code, we should avoid defining Arbitrary instances with bad statistical properties (what we did for the Integer). We always have the option to define custom generators and use forAll explicitly.   We can also note that writing a random generator for arbitrary long integers is not that easy. Thankfully, QuickCheck integrates a great deal of already defined Arbitrary instances. Practically, we do not need to worry about writing a generator of Integer._   Conclusion and what’s next   In this post, we went over the basic building block of the QuickCheck library, by implementing our own Property Based Testing framework, RapidCheck.   We used the same vocabulary as QuickCheck to better understand how the real library works. The details of implementations are not the exact reproduction of the original library though:      The Gen type is not a Monad in RapidCheck, to avoid the topic entirely. It also support less feature than the QuickCheck version.   The Result type is much simpler in RapidCheck to concentrate on the principles rather than trying to be exhaustive.   As a consequence, both forAll and rapidCheck functions, although quite similar in purpose, are quite different in terms of implementation.   But we are not done yet. The next post will go into another magic property of QuickCheck. We will add to our RapidCheck the ability to do something quite remarkable: generating function to test higher order functions.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/02/03/code-quick-check-1.html",
        "teaser": null
      },{
        "title": "Code your own Quick Check (Higher Order Functions)",
        "excerpt":"In the previous post, we started to build our own QuickCheck implementation in Haskell, which we named RapidCheck. We went over the basic concepts needed to build such a module, based on the original publication on QuickCheck.   In particular, we explained in details and implemented the following concepts from QuickCheck:      Gen a: a generator of value of type a   Result: a type to represent the outcome of a test (success or counter example)   Arbitrary: the class of types with a default Gen associated to it   Property: a testable predicate, from which we can derive a Gen Result   Testable: the class of types we can convert to a Property   In this post, we will add the support for generators of functions, which is critical to test properties expressed as higher order functions, while the next post will focus on adding the support for argument shrinking, which is critical to provide better counter examples for failing properties.   Motivating Example   In a functional language such as Haskell, we often modularize and factorize our code through the use of Higher Order Functions. Testing these functions with generative testing requires QuickCheck to support the generation of functions.   Our goal for today will be to enrich our RapidCheck implementation with everything needed to test the following properties.   The prop_partition is a valid property. It verifies that partition correctly does it jobs:      It checks that all elements on the left match the predicate   It checks that no elements on the right matches the predicate   It checks that no elements were lost in the process   We expect this property to pass:   prop_partition :: [Integer] -&gt; (Integer -&gt; Bool) -&gt; Bool prop_partition xs p =   let (lhs, rhs) = partition p xs   in and       [ all p lhs       , not (any p rhs)       , sort xs == sort (lhs ++ rhs) ]    rapidCheck prop_partition  &gt; Success   The prop_distributive is an invalid property. It asserts that every single functions from integer to integer is distributive over the operator plus. We expect this property to fail, and RapidCheck to provide us with a counter example:   prop_distributive :: Integer -&gt; Integer -&gt; (Integer -&gt; Integer) -&gt; Bool prop_distributive a b f = f (a + b) == f a + f b  rapidCheck prop_distributive &gt; Failure {seed = 7720540227186278723,            counterExample = [\"1716301762\",\"55093645\",\"&lt;function&gt;\"]}   You might feel quite disappointed by this counter example. The “function” string counter example is not that helpful. While this is true, understanding how to circumvent this issue goes beyond the scope of this post.   There is a brilliant presentation you can have a look at to better understand how the real QuickCheck manages to provide useful outputs for counter examples on functions.   Toward generating functions   How can we even generate functions? Functions can operate on a potentially infinite number of values, and it seems hard to conceive a way to generate such a complex structure.   Fortunately, the original publication on QuickCheck gives us a nice trick to understand where to start. The trick is based on playing with types.   Our goal is to be able to create a generator of functions from a to b: Gen (a -&gt; b). We know this Gen (a -&gt; b) type is just a wrapper around a function StdGen -&gt; (a -&gt; b). By getting rid of the parentheses and reordering the parameters of this function, we get the following prototype: a -&gt; StdGen -&gt; b.   We recognize in this last expression a generator of value of type b. This means we can rewrite Gen (a -&gt; b) as a -&gt; Gen b.   This play with types makes use realize that we can build a generator of functions from a function returning a generator, by merely moving the application of the function inside the generator.   We name this transformation promote:   promote :: (a -&gt; Gen b) -&gt; Gen (a -&gt; b) promote f =   Gen $ \\rand a -&gt;     runGen (f a) rand   Generators perturbation   The promote helper requires us to give it a function: a -&gt; Gen b. Finding a way to instantiate such a function is the focus of this section.   We can reason that implementing a function that instantiate a generator from a value of a completely different type is not conceivable unless this function is the result of a partially applied function. So let us add an argument in front of it to see how it could help us.   By adding Gen b, we get the following prototype: Gen b -&gt; a -&gt; Gen b. One way to see this is as a perturbation on a random generator driven by a value of type a. We capture this requirement on a with the CoArbitrary type class:   class CoArbitrary a where   coarbitrary :: Gen b -&gt; a -&gt; Gen b   The coarbitrary function is very close to what the function promote needs to create a generator of function. We just need to provide it a generator as first parameter.   To sum this up, it means we can make an Arbitrary (a -&gt; b) instances from the two following requirements:      Arbitrary b: the existence of a standard generator for the type b   CoArbitrary a: the ability for the type a to perturb another generator   Then we only need to provide the generator to coarbitrary to feed it to promote:   instance   (CoArbitrary a, Arbitrary b)   =&gt; Arbitrary (a -&gt; b)   where     arbitrary = promote (coarbitrary arbitrary)   Implementing perturbations   We saw that generating a function requires each of the argument of the function to implement the CoArbitrary type class.   We know that for a type a to be an instance of CoArbitrary it needs to be able to perturb generators of any other types. Let us now look at how we can implement such a perturbation.   General pattern   To influence a generator Gen, we can act on its StdGen parameter. This impact on the random generation process needs to be linked with the value of the type implementing CoArbitrary.   Applied to the integer data type, this translates into the following code, where perturb is yet to be defined:   instance CoArbitrary Integer where   coarbitrary gen n =     Gen $ \\rand -&gt;       runGen gen (perturb n rand)   This is the general pattern. We can use it to define any CoArbitrary instances: the only difference will be the implementation of the perturb function.   Implementing perturb   The implementation of perturb is critical to have good statistically properties. Matching the function prototype alone is not enough.   As an extreme example, let us imagine an implementation of perturb that would return its input generator unmodified. The resulting function generator would produce functions that systematically ignore all their parameters and return the same result for any inputs. Applied to our partition property, it would generate predicates that either return True on all inputs, or False on all inputs. Not that great.   To get good statistical properties, the implementation of perturb should instead try to map each possible value of a to a different perturbation on the generator Gen b.   This is the approach we have chosen for our CoArbitrary Integer instance, for which we provide different chains of split calls for each different number we get:      The sign of the number is taken into account   The value zero is not forgotten and does impact the generator   The decomposition of the number into digits further drives the perturbation   perturb :: (Integral n) =&gt; n -&gt; StdGen -&gt; StdGen perturb n rand0 =   foldl     (\\rand b -&gt; vary b rand)  -- Vary generator based on digit value     (vary (n &lt; 0) rand0)      -- Vary generator based on sign     (digits (abs n))          -- Decompose a positive number in digits   where     vary digit rand =       (if digit then snd else fst)       (split rand)     digits =       map ((== 0) . (`mod` 2))       . takeWhile (&gt; 0)       . iterate (`div` 2)   Although we must be careful, we are not limited: there are in practice many different valid implementations possible.   Leveraging   We can use the pattern we saw above in combination with our implementation of perturb to easily build more instances of CoArbitrary. Since we have a way to build a perturbation from an integer, we can use it as an intermediary step.   We can map the values of a type to an integer value to quickly get a CoArbitrary instance for it. We can also use perturb several times in a row:   instance CoArbitrary [Int] where   coarbitrary gen xs =     Gen $ \\rand -&gt;       runGen gen (foldr perturb (perturb 0 rand) xs)   The bottom line is that we do not need to re-invent the wheel each time we want to define a CoArbitrary instance.   In particular, QuickCheck offers a lot of helpers for building both Arbitrary and CoArbitrary in its Test.QuickCheck.Arbitrary module. This is a good place to look before starting implementing a new instance of either of those typeclasses.   Showable functions   We now have everything we need to run our tests cases… except for one small but important detail. Our code will not compile, due to the requirements associated with the Testable typeclass:   instance   (Show a, Arbitrary a,    Testable testable)   =&gt; Testable (a -&gt; testable)   where     property f = forAll arbitrary f   We need functions to implement Show for higher order functions to be valid instances of Testable. We will take a shortcut here and import the Text.Show.Functions module which defines it for us.   The problem with this approach is that we get “function” inside our counter example, when the property does not pass. This is clearly not very informative.   QuickCheck offers the Test.QuickCheck.Function to deal with this issue. It requires to transform the declaration of properties to use Fun a b instead of a -&gt; b. In exchange for this small change in syntax, it is both able to show and shrink functions, improving our user experience by that much.   Conclusion and what’s next   In this post, we went over how we could generate functions to test properties expressed as higher order functions.   We completed the code of our RapidCheck library with all that was needed to make our original test cases pass. You can find the current state of the code of our RapidCheck available in this GitHub Gist.   Adding this feature allowed us to test properties on an algorithm such as partition by generating predicates for it.   Our next post will aim at finishing the work and add one last important features of Property Based Testing, the ability to shrink counter examples.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/02/06/code-quick-check-2.html",
        "teaser": null
      },{
        "title": "Code your own Quick Check (Shrink)",
        "excerpt":"In the previous posts, we started to implement our own QuickCheck in Haskell, which we named RapidCheck, based on the original publication on QuickCheck.   The first post went over the basic concepts needed to build such a module, while our last post focused on how we can write generator for arbitrary functions. You might want to read them before continuing:      Code you own QuickCheck   Code you own QuickCheck (Higher Order Functions)   In today’s post, we will complete the implementation of our RapidCheck module, by adding the ability to shrink counter examples to make them more manageable.   This post will present two different strategies to implement this shrinking process. The first attempt will show the simplest solution that might come into mind. Although it will achieve the desired shrinking, we will explain in what sense it is badly designed. Identifying these defects will lead us to a second, much better solution to the problem.   Motivation   In our first post, we went over the process of building the basic blocks of our RapidCheck implementation. One of our success criteria was for our implementation to successfully find a counter example to following invalid property:   prop_gcd_bad :: Integer -&gt; Integer -&gt; Bool prop_gcd_bad a b = gcd a b &gt; 1  rapidCheck prop_gcd_bad &gt; Failure {seed = -1437169021,            counterExample = [\"1076253199\",\"40866101\"]}   While this counter example is perfectly valid, it is unnecessarily complex. This property could have failed with much smaller numbers:   gcd 1 1 &gt; 1  gcd 0 0 &gt; 0   The goal for today is to modify the implementation of our RapidCheck implementation to implement shrinking, one of the most amazing feature of QuickCheck.   At the end of this post, our implementation should be able to come up with much smaller counter examples for prop_bad_gcd:   rapidCheck prop_gcd_bad &gt; Failure {seed = 1034882204061803680,            counterExample = [\"1\",\"0\"]}   Meaning of shrinking   Our goal is to provide simpler counter examples to the user of the RapidCheck module, ideally a minimal test case. But what do we mean by “simpler” or “minimal”?   The general notion has to do with information. We want to remove noise from the test case. We want to get rid of artefacts that do not participate to the error. We want our arguments to contain only the information needed to make our test case fail.   We can therefore understand shrinking as the process of removing information from our arguments until we get to the point where all the information contained in these arguments is necessary for the test case to fail.   Enhancing Arbitrary   The first step toward being able to provide simpler counter examples is to figure out a way to reduce the amount of information of each of the arguments that lead to the property to fail.   To know where to start, we will enumerate some of the things we know and want about this shrinking process:      Quantifying information, thus reducing it, highly depends on the considered type   It involves search: there is no known universal solution to find a minimal test case   Shrinking might not make sense for all values (zero) or types (functions)   We would like equal values to shrink in a similar deterministic way   To sum up, we need a way to express an optional process that is neither random nor generic, and involves non-determinism. This is exactly what the shrink function of the Arbitrary type class has to offer:   type Shrinker a = a -&gt; [a]  class Arbitrary a where   arbitrary :: Gen a   shrink :: Shrinker a   shrink = const []      The list allows non-determinism: each output represents a different “path”   If the test case is already minimal, we can return an empty list   The default implementation helps for types that do not support shrinking   The shrink tree   To find the simplest counter arguments, several sequential calls to shrink might be needed. These recursive applications of shrink build a tree, whose root is the initial value that led to a counter example.   We will assume that this tree is built such that the children are ordered in such a way that it maximize the chances to find the smallest counter example. This assumption means we must be very careful in the ordering of the elements returned by shrink.   If this assumption holds, we can therefore explore the tree by finding the first children that makes the property fail, and dive deeper into this branch. If no children makes the property fail, the visit stops and we return our smaller counter example.   Arbitrary example   Now that we know what is expected from the shrink function, we can enrich the Arbitrary Integer instance to provide an implementation for it. Our implementation will stay very close to the one provided in Test.QuickCheck.Arbitrary:      We first try to remove the sign of negative integers   Then we try zero, the simplest possible integer value   Finally, we proceed with a right recursive dichotomy   instance Arbitrary Integer where   arbitrary = Gen $ \\rand -&gt; fromIntegral $ fst (next rand)   shrink n     | n == 0 = []     | otherwise = [abs n | n &lt; 0] ++ 0 : rightDichotomy where       rightDichotomy =             takeWhile               (\\m -&gt; abs m &lt; abs n)               [ n - i | i &lt;- tail (iterate (`quot` 2) n)]   The behavior of this Arbitrary Integer instance is better explained through examples:   shrink 2048 &gt; [0,1024,1536,1792,1920,1984,2016,2032,2040,2044,2046,2047]  shrink (-2048) &gt; [2048,0,-1024,-1536,-1792,-1920,-1984,-2016,-2032,-2040,-2044,-2046,-2047]   Plugging the shrinking in Testable   We know our Arbitrary type class has a new member shrink. We would like this ability to shrink to be automatically used inside the Testable properties that are made of shrinkable arguments.   From our first post, we know that the Testable properties are defined in terms of an induction on the number of arguments. We will need to enrich this induction to include shrinking.   To do so, we add a shrinker argument to forAll, the function that implements the induction step. For now, we keep the implementation unchanged:   forAll :: (Show a, Testable testable)           =&gt; Gen a -&gt; Shrink a -&gt; (a -&gt; testable) -&gt; Property forAll argGen shrink prop = ...   We can then adapt the Testable induction step to call forAll function one more argument:   instance   (Show a, Arbitrary a, Testable testable)   =&gt; Testable (a -&gt; testable)   where     property = forAll arbitrary shrink   We now reached the point where we need to implement the forAll function to plug all the pieces together. The next sections will present two different implementations:      We will start by the simplest implementation (and make it work)   We will then go for a better implementation (and make it work faster)   First try: visiting the shrink tree inside forAll   Our first implementation will consist in slightly adapting our forAll function to handle the shrinking. For reference, the current implementation of this function is listed below:   forAll :: (Show a, Testable testable) =&gt; Gen a -&gt; (a -&gt; testable) -&gt; Property forAll argGen prop =   Property $ Gen $ \\rand -&gt;             -- Create a new property that will     let (rand1, rand2) = split rand     -- Split the generator in two         arg = runGen argGen rand1       -- Use the first generator to produce an arg         subProp = property (prop arg)   -- Use the `a` to access the sub-property         result = runProp subProp rand2  -- Use the second generator to run it     in overFailure result $ \\failure -&gt; -- Enrich the counter-example with `arg`         failure { counterExample = show arg : counterExample failure }   We will enrich the lambda given to overFailure and inside this lambda, we will shrink the value arg of the initial counter example.   Shrinking implementation   Our shrinking process will take a function a -&gt; Result to test the property against an argument of type a. This a will take different value as we visit the shrink tree.   Our shrinking function will also need the root of the shrink tree and the shrink function, to get the children of a given node. We get the following prototype:   shrinking :: (Show a) =&gt; Shrink a -&gt; a -&gt; (a -&gt; Result) -&gt; Result shrinking = undefined   From a list of potential counter-example, we can write a search function that will return the first one that makes the property fail:   findFailing :: [a] -&gt; (a -&gt; Result) -&gt; Maybe (a, Result) findFailing smaller runSub =   let results = map runSub smaller   in find (isFailure . snd) (zip smaller results)   Applied to the output of shrink, the first match will provide us with the next branch of the shrink tree to explore. With that in mind, we can finish the implementation of the shrinking function:   shrinking :: (Show a) =&gt; Shrink a -&gt; a -&gt; (a -&gt; Result) -&gt; Result shrinking shrink arg runSub =   let children = shrink arg                 -- Get the children of the current branch       result = findFailing children runSub  -- Look for the first failure   in case result of       Nothing -&gt; Success       Just (shrunk, failure) -&gt;             -- In case a failure is found         shrinking shrink shrunk runSub      -- Try to shrink further the child         &lt;&gt;                                  -- OR (in case it fails)         addToCounterExample shrunk failure  -- Add child to the counter example   Plugging shrinking in forAll   We want the shrunk arguments to be used in place of the original randomly generated argument, and not trigger a full random test case again. So we must use the same random generator used to initially run the sub-properties for the shrinking.   Inside forAll, we can therefore add the shrinking inside the lambda given to overFailure. The shrinking uses the same runSub function (bound to the same seed) to search for a smaller counter example:   forAll :: (Show a, Testable testable)           =&gt; Gen a -&gt; Shrink a -&gt; (a -&gt; testable) -&gt; Property forAll argGen shrink prop =   Property $ Gen $ \\rand -&gt;             -- Create a new property that will     let (rand1, rand2) = split rand     -- Split the generator in two         arg = runGen argGen rand1       -- Use the first generator to produce an arg         runSub = evalSubProp prop rand2 -- Factorize a runner for the sub-property         result = runSub arg             -- Run the sub-property with value `arg`     in overFailure result $ \\failure -&gt; -- In case of failure,         shrinking shrink arg runSub     -- Attempt to shrink the counter example         &lt;&gt;                              -- OR (in case the shrinking failed)         addToCounterExample arg failure -- Add the argument to the counter example   This implementation makes use of the evalSubProp function, to get the (a -&gt; Result) function required to explore the shrink tree:   evalSubProp :: Testable t =&gt; (a -&gt; t) -&gt; StdGen -&gt; a -&gt; Result evalSubProp prop rand = (`runProp` rand) . property . prop   Resulting behavior   This implementation works in the sense that it will shrinking the counter example as we expect it would:   rapidCheck prop_gcd_bad &gt; Failure {seed = 1034882204061803680,            counterExample = [\"1\",\"0\"]}   But our implementation of forAll is deceptively simple. It looks like it tries to shrink the arguments sequentially, starting from the last argument of the property. But it is not what happens.   Our forAll is part of the induction process that builds a Property from a list of arguments from the last to the first of a Testable property. Since our forAll implementation now includes visiting the shrink tree, finding a counter example for an argument (this includes shrinking this same argument) also involves visiting the shrink tree of all subsequent arguments.   To illustrate this, let us take the following invalid property:   prop_gcd_bad :: Integer -&gt; Integer -&gt; Bool prop_gcd_bad a b = gcd a b &gt; 1      Finding an initial counter example for a involves evaluating the sub-properties prop_gcd_bad is built from. This includes shrinking argument b.   Shrinking a also involves re-evaluating the sub-properties prop_gcd_bad is built from. This also automatically includes shrinking the argument b.   So we shrunk argument b twice, and this will only grow with the number of arguments participating in the property.   So this is quite a waste. And there is nothing we can do about it: it is a natural consequence of a design that integrates visiting the shrink tree inside forAll.   Second try: visiting the shrink tree outside forAll   We know from our previous design that we need to search for better counter example outside of the forAll function. In this second design, the forAll function will only be responsible to build a search tree, for the rapidCheck function to explore it.   Result tree   To achieve this, we will have to modify our Property type to return a Result tree instead of a single Result.   data Tree a = Tree   { treeVal :: a   , children :: [Tree a] }   deriving (Functor)    newtype Property = Property { getGen :: Gen (Tree Result) }   In this design, our rapidCheck function is responsible for navigating the tree and seeking a better counter example (in case of failure). The only modification needed in rapidCheckImpl is a call to visitResultTree:   rapidCheckImpl :: Testable prop =&gt; Int -&gt; Int -&gt; prop -&gt; Result rapidCheckImpl attemptNb startSeed prop = runAll (property prop)   where     runAll prop = foldMap (runOne prop) [startSeed .. startSeed + attemptNb - 1]     runOne prop seed =       let result = visitResultTree (runProp prop (mkStdGen seed))       in overFailure result $ \\failure -&gt; failure { seed = seed }   Implementing the visitResultTree function is quite straightforward. We find the first children that preserves the failure, and dive deeper into it:   visitResultTree :: Tree Result -&gt; Result visitResultTree (Tree Success _) = Success visitResultTree (Tree failure children) =   let simplerFailure = find (isFailure . treeVal) children   in maybe failure visitResultTree simplerFailure   Building the result tree   Since a Property now returns a result tree, we need to adapt our forAll function accordingly to return a result tree instead of a single result.   Each argument inductively added by forAll to the Property will return a tree to the “father” forAll. For forAll to output a tree, we need a way to collapse a tree of tree of results into a tree of results.   This collapse must be very carefully designed to prioritize the shrinking of the outer argument over the shrinking of the inner arguments. Otherwise, the outer arguments would almost never be visited and thus shrunk. This is the job of joinTree:   joinTree :: Tree (Tree Result) -&gt; Tree Result joinTree (Tree (Tree innerArgResult innerArgShrinks) outerArgShrinks) =   Tree innerArgResult        (map joinTree outerArgShrinks ++ innerArgShrinks)   The creation of the tree of tree of results involves a bit of code:      We first need to create a shrink tree of all outer argument values   For each outer argument value, we evaluate the sub-property result tree   We enrich the sub-property result tree with the outer argument value   At the end, we join our tree of result tree into a result tree   resultTree :: (Show a, Testable t) =&gt; Shrink a -&gt; a -&gt; (a -&gt; t) -&gt; Property resultTree shrinker arg prop =   Property $ Gen $ \\rand -&gt;     let shrinkTree = buildTree shrinker arg   -- Build the shrink tree         resultTree = fmap toResult shrinkTree -- Transform it to a result tree         toResult x =                          -- To compute a result tree           addCounterExample x $               -- Add the outer arg to all failures             runProp (property (prop x)) rand  -- Inside the sub result tree     in joinTree resultTree                    -- At the end, join the result tree   This code makes use of the following helper functions:      buildTree creates a potentially infinite shrink tree from a root value   addCounterExample add a counter example across a whole result tree   buildTree :: Shrink a -&gt; a -&gt; Tree a buildTree shrinker = build where   build x = Tree x (map build (shrinker x))  addCounterExample :: (Show a) =&gt; a -&gt; Tree Result -&gt; Tree Result addCounterExample arg = fmap (\\r -&gt; overFailure r addToFailure)   where addToFailure f = f { counterExample = show arg : counterExample f }   Wrapping up   To finish up the implementation, we only need to adapt our forAll to do the necessary plumbing:      Split the pseudo random generator in two: rand1 and rand2   Use rand1 to generate the root value of the shrink tree of the outer argument   Use rand2 to evaluate the next result tree of the chain   forAll :: (Show a, Testable t) =&gt; Gen a -&gt; Shrink a -&gt; (a -&gt; t) -&gt; Property forAll argGen shrink prop =   Property $ Gen $ \\rand -&gt;               -- Create a new property that will     let (rand1, rand2) = split rand       -- Split the generator in two         arg = runGen argGen rand1         -- Use the first generator to produce an arg         tree = resultTree shrink arg prop -- Enrich the sub-property result tree     in runProp tree rand2    This is it: we know have an implementation that will shrink the outer arguments of a given property first, before proceeding with the inner arguments.   Enjoying shrinking   Now that our implementation works, we can play a bit with it. We will run it on our invalid property, and check that the results are satisfying:   rapidCheck prop_gcd_bad &gt; Failure {seed = 1034882204061803680,            counterExample = [\"1\",\"0\"]}   We can add traces in our property to check how it behaves. The following is an excerpt of log traces of the a and b values used to find a counter example. The full file is only 63 lines long:   925396436 234647012 925436450 1835767207 0         1835767207 462718225 1835767207 0         1835767207 231359113 1835767207 ... 4         1835767207 0         1835767207 2         1835767207 0         1835767207 1         1835767207 0         1835767207 1         0   Conclusion   In this post, we went over how we could add shrinking to provide better counter examples to invalid properties.   We completed the code of our RapidCheck module with a shrinking mechanism and tried two different implementations of it. The mistakes done in the first implementation allowed us to understand the second implementation better. The full code of our RapidCheck module is available in this GitHub Gist.   This second implementation is not quite the same as the one used in QuickCheck, due to the numerous additional features it supports. But this journey should still guide (the most adventurous of) you quite a bit in understanding the code behind the fabulous QuickCheck.   I hope you enjoyed the journey as much as I did, and that you learned something reading these last few posts.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/02/10/code-quick-check-3.html",
        "teaser": null
      },{
        "title": "Experimenting with QuickCheck on a DSL",
        "excerpt":"After having spent the last three posts exploring how to implement our own QuickCheck, the goal of the next two posts will be to play with it, to test and discover properties on our code and have fun as well.   The target of these experiments will be the Arithmetic DSL we built several posts back in January:      Catamorph you DSL: Introduction   Catamorph you DSL: Deep Dive   After a quick refresher on our Arithmetic DSL and what it is made of, we will use QuickCheck to conduct some experiments on it.   Today’s post will focus on creating the appropriate arithmetic expression generator and put them into use to unit test our code. The next post will deal with the more exotic (and less serious) usage we can make of QuickCheck.   Our arithmetic DSL   Our Arithmetic DSL is made of 4 primitives: integer constants, variables, addition and multiplication operations. In addition to these types, we introduced the notion of environment, a mean to retrieve an integer value from a variable identifier.   The following code snippet depicts all the types involved:   type Id = String    -- Variable identifier type Env =          -- Environment of evaluation   Map Id Int  data OpType         -- Types of operations   = Add             -- * Addition   | Mul             -- * Multiplication   deriving (Show, Eq, Ord)  data ExprR r        -- Open recursive expression type   = Cst Int         -- * Constant   | Var Id          -- * Variable   | Op OpType [r]   -- * Operation   deriving (Show, Eq, Ord)  -- The type of arithmetic DSL (fixed point of ExprR) type Expr = Fix ExprR   Our arithmetic DSL comes with a five different interpreters. We listed them with their description below:      prn: pretty prints an Arithmetic expression   eval: computes the value of an expression, given an Env   optimize: optimizes an expression by using known constants   partial: partially computes an expression, given an Env   dependencies: retrieve all variables names from an expression   The following short REPL interaction illustrate each of these interpreters:   let e = add [ cst(1)             , cst(2)             , mul [cst(0), var(\"x\"), var(\"y\")]             , mul [cst(1), var(\"y\"), cst(2)]             , add [cst(0), var(\"x\") ]             ]               -- Pretty printing an expression prn e &gt; \"(+ 1 2 (* 0 x y) (* 1 y 2) (+ 0 x))\"  -- Optimization of an expression prn (optimize e) &gt; \"(+ 3 (* 2 y) x)\"  -- Partial evaluation of an expression prn $ partial (Map.fromList [(\"y\", 0)]) e &gt; \"(+ 3 x)\"  -- Getting the list of variable names in an expression dependencies e &gt; fromList [\"x\",\"y\"]  -- Full evaluation of an expression eval (Map.fromList [(\"x\", 1), (\"y\", 0)]) e &gt; 4   We will stop there for the refresher. If you are curious and want to know how each of these interpreters is implemented, you are welcome to read the series on catamorphism linked in the introduction.   We will now dive into QuickCheck and play with it on our DSL.   Generator of arithmetic expressions   To play with QuickCheck on our DSL, our first task will be to implement the required generators of arithmetic expressions.   The wrong way   The initial temptation is to create a new Arbitrary instance for our Expression and stick all the code inside it. We will resist this temptation.   Indeed, and except for very few rare cases, we will likely need specialized generators in order to test different properties on our code. The arguments of a function often have distinct equivalence classes.   For instance, our arithmetic DSL makes emerge at least one very interesting class of expression: constant expressions, which are the expression that do not contain any variables.   Each equivalence classes will likely need to a specific generator. If we move all the implementation into the arbitrary function, we loose a lot of flexibility by having fused everything together. Arbitrary is better used to designate a default generator for a type.   A better way   We will define functions returning Gen Expr generators. Using standard function will allow us to mix and match them to get appropriate generators for our equivalence classes. We can then optionally select one of these generators as our default generator by instantiating Arbitrary Expr.   An interesting rule of thumb when dealing with Algebraic Data Types is to create one generator by constructor of our type. This is by no mean a rule, but it happens to give good results in general.   Let us start with constants and variables:      Our constant generator genCst use the standard integer generator   Our variable generator genVar will be letters from “a” to “z”   genCst :: Gen Expr genCst = fmap cst arbitrary  varNames :: [String] varNames = [[v] | v &lt;- ['a'..'z']]  genVar :: Gen Expr genVar = fmap var (elements varNames)   From these, we can define another useful generator that creates expressions made of only variable or constants with equal probability. We call these simple terms (as opposed to operations which are compound terms):   genSimpleTerm :: Gen Expr genSimpleTerm = oneof [genVar, genCst]   Our generator of operation will take as parameter a generator for simple terms as well as a size n. The bigger the n, the more complex the generated expression:      With a probability 1/n, we generate a simple term   Otherwise, we create an operation with m&lt;=n sub-expressions   We recursively generate sub-expressions for size n/m   opsGen :: Gen Expr -&gt; Int -&gt; Gen Expr opsGen simpleTermGen = go where   go n = do     m &lt;- choose (0, n)     if m == 0       then simpleTermGen       else elements [add, mul] &lt;*&gt; replicateM m (go (div n (m + 1)))   Since our operation generator can be parameterized by a simple term generator, we have the flexibility to defined two specialized generators:      genExpr: a generator of expression that may contain variables   genCstExpr: a generator of expression that contains no variable   genExpr :: Int -&gt; Gen Expr genExpr = opsGen genSimpleTerm  genCstExpr :: Int -&gt; Gen Expr genCstExpr = opsGen genCst   These generators will be quite handy in the following.   Environment generators   As well as generating arbitrary arithmetic expressions, we will need to generate environment of evaluation to test our eval and partial interpreters.   Again, we will likely need different generators, so we define the following functions instead of rushing for Arbitrary (*):      makeEnvWith allows us to create an environment holding random values for some predefined variable identifiers   genTotalEnv creates an environment associating a value to all possible variable identifiers used in our tests   makeEnvWith :: Set.Set String -&gt; Gen Env makeEnvWith deps = do   let n = Set.size deps   values &lt;- replicateM n arbitrary   return $ Map.fromList (zip (Set.toList deps) values)  genTotalEnv :: Gen Env genTotalEnv = makeEnvWith (Set.fromList varNames)   (*) QuickCheck can be quite helpful at showing us design defects in our code. We cannot create a new Arbitrary instance for our Env type because it is a type synonym of a Map, which already has one such instance defined. QuickCheck points to us the need for stronger type.   Verifying and discovering properties   Now that we have quite a few generators of expressions available, we can use them in combination with QuickCheck to verify some interesting properties on our Arithmetic expressions.   Identifying good properties to check   Before we start, we should remind ourselves that QuickCheck is no replacement for all our example based tests. QuickCheck is really great at ensuring that some invariants hold, but will not handle very specific test cases.   For example, checking that our eval function does output the right number cannot be easily done, except by replicating most of the logic of eval inside the test. This would somehow defeat the purpose of our test.   What we can do however is to check relations between our different interpreters. There are quite a few that should pop in our head. We selected some representative examples below.   Optimize should not change the value of expressions   This property points at an interesting relation between the optimize function and the eval function.   Evaluating an expression should yield the same value as evaluating the optimised expression in the same environment. This should hold for every environment that contains the variables appearing in the non-optimised expression (*).   prop_optimize_eval :: Expr -&gt; Property prop_optimize_eval e =   forAll genTotalEnv $ \\env -&gt;     eval env e == eval env (optimize e)  quickCheck prop_optimize_eval &gt; +++ OK, passed 100 tests.   (*) The “non-optimized” qualifier is necessary. Our last test will show us some interesting twists which make this distinction important.   Partial evaluation of constant expressions should yield a number   In the post describing our Arithmetic DSL, we pointed out that eval could be implemented in terms of partial evaluation. If the result of a partial evaluation is a constant term, we just had to unwrap it and get the value of the expression.   This argument was based on the assumption that the partial evaluation is able to fully optimize a constant expression into a single constant term. Since partial is based on optimize, this property should also hold for the later.   prop_optimize_constant :: Property prop_optimize_constant =   forAll (sized genCstExpr) (isCst . optimize)  prop_partial_constant :: Property prop_partial_constant =   forAll (sized genCstExpr) (isCst . partial Map.empty)   The sized function is a quite helpful QuickCheck helper that allows us to inject the size of the input into our generator genCstExpr.   Dependencies should return the variables needed for evaluation   This property points out at an interesting relation between our evaluation functions and the dependencies. If each variable identifier returned by dependencies appears in the environment, partial should be able to fully reduce an expression to a constant term.   prop_dependencies_allow_eval :: Property prop_dependencies_allow_eval =   forAll (sized genExpr) $ \\e -&gt;     forAll (makeEnvWith (dependencies e)) $ \\env -&gt;       isCst (partial env e)   We may have the feeling the converse should also hold: if a single variable from an dependencies does not appear in the environment, partial should not be able to fully evaluate an expression.   makePartialEnv :: Set.Set Id -&gt; Gen Env makePartialEnv deps = do   v &lt;- elements (Set.toList deps)   makeEnvWith (Set.delete v deps)  prop_missing_dependencies_forbid_eval :: Property prop_missing_dependencies_forbid_eval =   forAll (sized genExpr) $ \\e -&gt;     let deps = dependencies e     in Set.size deps &gt; 0 ==&gt;         forAll (makePartialEnv deps) $ \\env -&gt;           not (isCst (partial env e))   But actually, our property fails:   quickCheck prop_missing_dependencies_forbid_eval &gt; *** Failed! Falsifiable (after 4 tests):  &gt; (* g x) &gt; fromList [(\"x\",0)]  quickCheck prop_missing_dependencies_forbid_eval &gt; *** Failed! Falsifiable (after 4 tests):  &gt; (* 0 b q) &gt; fromList [(\"b\",2)]   And indeed, (* g x) does not necessarily require all variables to be bound to get a value out the expression. If either g or x is equal to zero, the expression is trivially equal to zero. The second counter example featuring (* 0 b q) is even more telling.   We discovered that our partial function was in fact able to evaluate expressions that do not have all their variable bound in the environment. QuickCheck discovered this knowledge for us, with only 4 tests.   Using QuickCheck, we can quickly encounter many similar experiences. QuickCheck is quite impressive at proving us wrong. Doing so, it participates rather effectively at increasing the knowledge on our own code.   Optimize does not necessarily preserve the dependencies   From the previous experiment, we can deduce that our optimize function does not systematically preserves the dependencies of an expression.   We can express the negation (that it should keep the dependencies of an expression unchanged), and indicate to QuickCheck we expected the property to fail:   prop_optimize_preserves_dependencies :: Property prop_optimize_preserves_dependencies =   forAll (sized genExpr) $ \\e -&gt;     dependencies e == dependencies (optimize e)  quickCheck (expectFailure prop_optimize_preserves_dependencies) &gt; +++ OK, failed as expected. Falsifiable (after 8 tests):  &gt; (* g r e m (* 0))   Going back to our first test, we now understand why the distinction “non-optimised” in the property definition was quite an important one.   Conclusion and what’s next?   We took as example our Arithmetic DSL we build in earlier posts, and used QuickCheck to build some generators and check some properties on it.   Through these experiments, we discussed strategies to build generators and discovered several interesting use cases of QuickCheck:      Its ability to reveal some design defects   Its ability to test high level relations between functions   Its ability to increase our knowledge by proving us wrong   Its ability to check that some property can be falsified   Next post will be dedicated to more “exotic” and maybe be less “serious” use cases for QuickCheck.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/02/14/quick-check-experiments.html",
        "teaser": null
      },{
        "title": "Quickcheck is fun, deal with it",
        "excerpt":"In our previous post, we played with QuickCheck on an arithmetic DSL and used it to check and discover properties on its associated interpreters.   Through these experiments, we explored some of the classic usage of QuickCheck and demonstrated through some examples:      Its ability to reveal some design defects   Its ability to test high level relations between functions   Its ability to increase our knowledge by proving us wrong   Its ability to check that some property can be falsified   It does not seem fair however to associate QuickCheck with serious testing business only. QuickCheck is really a fun library to use. You might have already found out that we can leverage its generators for many other purpose than just Property Based Testing.   This post is dedicated to do justice to QuickCheck by exploring some of those more exotic use cases of QuickCheck. Do not expect anything serious in this post: we will embrace the absurd world of generating random stuff.   Note: This post is built on top of our previous post. The experiments we will conduct with QuickCheck will feature the same arithmetic DSL. You might want to read this previous post first.   Generating random valid code   Generating random stuff is always quite a bit of fun. Why not break the boredom of doing serious test, by leveraging our generators to do stupid random things?   You surely noticed our prn interpreter was pretty printing our arithmetic expression in a LISP like syntax. Generating random Clojure function is not very far away:      We have a genExpr function to create random arithmetic expressions   Our prn interpreter can pretty print an expression in Clojure   Our dependencies interpreter can list the bound variables   We can easily create a generator of function names which satisfy good code convention: not too short, not too long, and (most importantly) not too understandable.   genName :: Gen String genName = do   n &lt;- elements [5..10]   replicateM n (elements ['a'..'z'])   We can assemble our function by pretty printing the arithmetic expression, print the dependencies inside brackets (for the parameters for the function), prefixed by a function name, and surround the whole with parentheses:   toClojureFunction :: String -&gt; Expr -&gt; String toClojureFunction name e =   unwords     [\"(defn\", name,      \"[\" ++ unwords (Set.toList $ dependencies e) ++ \"]\",      prn e, \")\"]   We now have everything we need to generate Clojure functions containing optimized (we would not like to produce inefficient code) arithmetic expressions:   clojureFunctionGen :: Int -&gt; Gen String clojureFunctionGen size =   toClojureFunction     &lt;$&gt; genName     &lt;*&gt; fmap optimize (genExpr size)  generate (clojureFunctionGen 30) &gt; \"(defn ptvkegely [c j m n t u y] (+ -64 m c t y n j u) )\"   We can check that our random generated function is valid Clojure code by firing up a Clojure REPL and play with it.   (defn ptvkegely [c j m n t u y] (+ -64 m c t y n j u)) =&gt; #'user/ptvkegely  (ptvkegely 1 2 3 4 5 6 7) =&gt; -36   Did you know that 64, the square of 8, negated and added to the sum of numbers from 1 to 7, was equal to 36, the square of 6? The proof that QuickCheck can be both fun and instructive.   Note: if your company pays you by the line, you know have a way to create an incredible amount of valid code in a very short amount of time.   Ending the infix VS prefix debate   Since we are already on the LISP subject, we can take this opportunity to solve the long lasting developer debate. Which is better, infix or prefix notation?   Since we have arithmetic expressions generators at hand, we can devise a fair experiments based on statistics:      We create a infix pretty printer of arithmetic expression prnInfix   We use QuickCheck to generate a bunch of arithmetic expressions   We serialize each of these expressions with prn and prnInfix   Because every developer’s life goal is to golf his code, the winner will be the format that results in the shortest string representation in average.   A first infix pretty printer   Let us start by creating our prnInfix pretty printer. We need to be careful with the parentheses. We would not want our pretty printer to modify the meaning of our arithmetic expressions.   As a first approximation, we could use the following strategy:      Systematically surround the arguments of a multiplication with parentheses   Do not add parentheses for the arguments of an addition   This lead us to the following implementation in which we use catamorphisms for concision (if you are not familiar with this recursion scheme, you can read our series dedicated to it).   prnInfix :: Expr -&gt; String prnInfix = cata infixAlg where    infixAlg (Op Add xs) = concat (intersperse \" + \" xs)   infixAlg (Op Mul xs) = concat (intersperse \" * \" (map parens xs))   infixAlg (Cst n) = show n   infixAlg (Var v) = v      parens x = \"(\" ++ x ++ \")\"   We can try our implementation on a complex enough example, to see if it leads to acceptable results:   let e = add [ cst(1)             , cst(2)             , mul [cst(0), var(\"x\"), var(\"y\")]             , mul [cst(1), var(\"y\"), add [cst(2), var(\"x\")]]             , add [cst(0), var(\"x\") ]]    prn e &gt; \"(+ 1 2 (* 0 x y) (* 1 y (+ 2 x)) (+ 0 x))\"  prnInfix e &gt; \"1 + 2 + (0) * (x) * (y) + (1) * (y) * (2 + x) + 0 + x\"   Quite disappointing to say the least. With that much noise induced by unnecessary parentheses, the infix notation clearly stands no chance. We will need to improve on our heuristic to have an entertaining fight.   Improving the infix pretty printer   To witness a fair fight, we need our prnInfix to use much less parentheses. We note that a multiplication only needs to add parentheses around sub-expressions that correspond to additions.   Catamorphisms are not a powerful enough recursion scheme to do this. We need to turn to Paramorphisms, which are Catamorphisms with context information. The context information will provide us with the sub-expression we need to make the right parenthesizing choice:   para :: (ExprR (a, Expr) -&gt; a) -&gt; Expr -&gt; a para alg = alg . fmap (para alg &amp;&amp;&amp; id) . unFix   Based on this construct, we can define our pretty printer to leverage the context to only add parentheses around parameters that correspond to addition sub-expressions:      The parensPlus handles the parentheses around multiplication sub-expressions   The addition discards the additional context (and never adds parentheses)   The simple terms are computed the same as before   prnInfix :: Expr -&gt; String prnInfix = para infixAlg where    infixAlg (Op Add xs) = concat (intersperse \" + \" (map fst xs))   infixAlg (Op Mul xs) = concat (intersperse \" * \" (map parensPlus xs))   infixAlg (Cst n) = show n   infixAlg (Var v) = v    parensPlus (s, Fix (Op Add _)) = \"(\" ++ s ++ \")\"   parensPlus (s, _) = s   We can test our new improved pretty printer and check the improvement. In our test expression, there is no unnecessary parentheses left for us to see:   let e = add [ cst(1)             , cst(2)             , mul [cst(0), var(\"x\"), var(\"y\")]             , mul [cst(1), var(\"y\"), add [cst(2), var(\"x\")]]             , add [cst(0), var(\"x\") ]]    prn e &gt; \"(+ 1 2 (* 0 x y) (* 1 y (+ 2 x)) (+ 0 x))\"  prnInfix e &gt; \"1 + 2 + 0 * x * y + 1 * y * (2 + x) + 0 + x\"    Our infix pretty printer is now fairly equipped for a fair contest.   Game, set and match   Our challengers are ready. The crowd is waiting. We only need to implement our contest. Here is how the game will be structured:      We generate a thousand of random expressions using QuickCheck   Each expression is optimised before being pretty printed   We return the sum of sizes for both prn and prnInfix (their scores)   A lower score means the pretty printer produced smaller string representations for the expression. The lowest score will thus designate our winner.   To finish up, our contest function will take as parameter the complexity of the arithmetic expressions to pretty print:   data ContestResult = ContestResult {     prefixScore :: Int ,     infixScore  :: Int }   deriving (Show)  runContest :: Int -&gt; IO () runContest size = do   expressions &lt;- generate (replicateM 1000 (genExpr size))   let run printer = sum $ map (length . printer . optimize) expressions   print $ ContestResult (run prn) (run prnInfix)   The results shows the quite stunning performance of the prefix notation, winner by quite a large margin:   runContest 30 &gt; ContestResult {prefixScore = 31951, infixScore = 42293}  runContest 100 &gt; ContestResult {prefixScore = 87662, infixScore = 125822}      25% characters less for prn for expressions of complexity 30   30% characters less for prn for expressions of complexity 100   We would not want to conclude too fast and declare that prefix notation completely owns the infix notation. Instead, we hope the reader will come to this same conclusion by himself/herself.   This madness is over   We are done: these random stupid experiments are over (for now). I cannot know if you found such experiments funny or even remotely enjoyable.   But I thought it was useful to cover one of the aspects of programming that maybe does not appear enough at work: we can have great fun doing crazy things. The experiments listed above were done in-between more serious work, just to try stupid things.   We must realize we have the luxury of having both powerful hardware and software available for us, at relatively cheap prices. We can use them for fun as much as for work. And who knows, we might even learn something in the process.   With this post, we concluded our series of five posts on QuickCheck. We tried to give a board spectrum of what QuickCheck and Property Based testing is about, how it can be implemented, and how we can use it for both serious tests and less serious experiments.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/02/17/quick-check-is-fun.html",
        "teaser": null
      },{
        "title": "Building a Clojurescript game",
        "excerpt":"In the next posts, we will implement a small web game using ClojureScript and Reagent. Our ultimate goal will be to build an equivalent of the old Tribolo DOS game as a Web game, including:      The graphics and the rendering of the game board in SVG   The game mechanics and the implementation of the rules   The implementation of an artificial intelligence   The interconnection of these aspects with state management   You can have a look at the working version of the game.   Through these posts, we will cover the basics of building a SVG game with ClojureScript, talk about ways to architecture such an application, and try to remove any remaining traces of bad memories associated to GUI programming.   This endeavor will require more than one post to go through:      In today’s post, we will describe the game and discuss our target architecture.   In our next post, we will do a proof of concept of the target architecture by trying it on a much simpler game, a Tic-Tac-Toe.   Then the next posts will dive into the implementation of the Tribolo itself, diving into each part of the implementation, one by one.   The rules of Tribolo   The sections below will do into details in the rules. They turn out to be pretty hard to explain in plain text. You can experiment them first hand by trying the game) while reading the rules.   Basic rules   Three players (Blue, Red and Green) play one after the other on board made of 16 times 11 cells. Each player tries to convert the maximum number of cells to their own color.   A player can convert cells of another player by “jumping” over them: the player targets an empty cell that has a direct line of sight (vertical, horizontal or diagonal) with one cell that he already controls.   At each turn, a player must do a valid jump. If no valid jump are available, the player pass his/her turn and the game proceeds with the next player.   Jumping   To be a valid jump, a line must only contain cells belonging to one single opponent. It means that Blue cannot convert a line if the line contains both Red and Green cells. In addition, the line cannot contain cells that are not owned by any player.   If multiple jumps are possible from a given empty cell, converting this empty cell triggers the conversion of the cells of each line jumped over. It means that Blue can convert at the same time a line containing exclusively Green cells and a line containing exclusively Red cells.   The game also features one special type of cells: walls. Walls cannot be converted and block line of sight, which means a player cannot jump over them.   Start and end conditions   The game starts with each player owning 12 random cells. The game continues until no player can convert any more cells. The winner is the player owning the most cells at the end of the game.   Each game has a fixed number of 12 walls, randomly placed on the board at the start of the game. Their position will never evolve.   Additinal requirements   Tribolo is a single player game. Blue is controlled by the only human player of the game, while Red and Green are controlled by an artificial intelligence. We will have to develop at least a rudimentary AI to play the game.   Because the board is quite big, identifying available jump might sometimes be challenging. We will therefore add a help feature, to reveal the available moves for the the human player, as the original game does.   Finally, we want our human player to be able to cancel his last move or restart the same game from the start. We will add these features as actions available in a menu.   Reagent   The GUI rendering of the game will be based on Reagent. We will thus need to spend some time providing an overview of the library.   There are plenty of good tutorials on Reagent available online, so we will only go through a refresher. You are greatly encouraged to look further on your own.   Overview   Reagent is a lightweight wrapper around the amazing React library for JavaScript. It handles the rendering of the HTML DOM and automatically deals with the refresh of the HTML DOM when the state of the application changes.   Reagent is not concerned with the update of the application state. Data flows from the application state to the view and to Reagent, and not the other way around.   Modifying the application state has to be handled through the use of callbacks or events, either manually or via another library (like re-frame). We will have to take this into account in our architecture.   Rendering with Reagent   From a user point of view, Reagent works in a beautiful simple way. Reagent understands a Hiccup-like format: it can transform nested data structures (vector and maps) that resemble the structure of an HTML tree, and build a HTML DOM from it.   If we provide Reagent with functions that produce HTML-like data structures, Reagent will wrap them in reaction. Reactions allow to automatically re-compute a function upon modification of a ratom on which the function depends.   A ratom is the name the community gave to the atom-like mutable state provided by Reagent. Each time a ratom is modified, rendering functions that dereference it will be automatically refreshed by Reagent.   One single state to rule them all   The usual design with Reagent consists in having a single ratom state for the whole Single Page Application. This design works great in combination with figwheel, the must have lein plugging to hot reload code while coding.   If you are not accustomed to Reagent yet, this one single state design might seem a bit awkward or even plain bad to you. It is actually quite reasonable if you look at it from a data-base perspective:      The single ratom represents the data-base for the application   Reactions represents views on the data-model (projections, unions, etc.)   The application queries these data-base views to get useful data   The application runs transactions (swap!) on the DB to update the data   Having a single state also helps dealing with time. It is easier to deal with coordination when there is no need for coordination. It might not be the best fit for all applications, but it will suit for our Tribolo game.   High level architecture   Now that we know what we have to build, and know more about Reagent, we can discuss the overall architecture of the game we will build.   The purpose of this architecture exercise is not to go deep into the details and set things into stones. Instead, it is to define “code zones”, along with the relations and the interaction patterns between these zones.   We define these zones to help us divide our tasks in small bits (problem decomposition) and also to enforce structurally some constraints that will help us better reason about and test our program.   Identifying responsibilities   Our game will have to deal with several different responsibilities. We list them below with their corresponding short description:      Rendering: transforming the current game state into HTML and SVG   Game logic: the rules governing transitions between game states   AI logic: selection of the best next move for an AI player   Store: the in-memory data-base holding the application state   Game loop: coordination and control of the different aspects   Each of these responsibilities will require further design refinement, which we will go through when the time comes to dive into each of them.   Responsibilities dependencies   In order to keep the game under control both in terms of design and testability, we will impose ourselves some reasonable constraints in terms of design:      The game logic is not allowed any dependency (on rendering, AI or store)   The AI logic might depend on the game logic but nothing else   The rendering should not depend the game loop   Assembling the elements (dependency) is the job of the game loop   Given the set of constraints we listed above, we can select our target architecture as something very close to the usual model-view-controler:      The game loop plugs the rendering with the ratom of the store   The game loop listens the GUI and triggers game logic and AIs   The game loop transmits the effect of game transitions to the store   This translates into the following ASCII Art diagram of interaction:      Store ----------------&gt; Rendering ---------------&gt; Reagent      ^      (reaction)         ^      (send hiccup)      |                         |      |                         | (listen)      |       (update)          |      \\-------------------- Game loop                                |                                |      ,-------------------------| (use to update store)      |                         |      v                         v  Game logic &lt;-------------- AI logic   The plan for the next posts   In this post, we described the rules of the game and covered the overall architecture we will follow to realize it.   Because it is dangerous to jump onto an architecture without second thoughts, our next post will go through a proof of concept of the architecture on a smaller game. We will implement a simple tic-tac-toe using it, to explain the architecture in more details, and see how it works.   The next posts will then dive deep into each of the responsibilities, one by one, covering them into enough details to reproduce them, until the game is done.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Clojure"],
        "url": "/blog/2017/02/27/building-clojure-game-1.html",
        "teaser": null
      },{
        "title": "Building a Clojurescript game (POC)",
        "excerpt":"This post is the second in the series of posts focused on the conception and implementation of a port in ClojureScript of the game named Tribolo.   In our previous post, we discussed the game, described its rule, and discussed its basic target architecture. This post will use this target architecture to build a much simpler game, a Tic-Tac-Toe, with the goal to make the architecture more explicit.   The Tribolo itself will indeed require several dedicated posts and so the architecture will be distilled through several posts. Building a Tic-Tac-Toe allows us to get the big picture through a Proof-Of-Concept.   To make our POC as useful as possible, our Tic Tac Toe will follow the same basic game mechanics and have the same kind of look and feel that our Tribolo game.   You can try both and see the parallel by yourself:      You can try the Tribolo game we want to build at the following address.   You can try the Tic Tac Toe we will build today at the following address.   Summary of the target architecture   We begin with a quick review of the target architecture we described in our last post. We first identified the following responsibilities:      Rendering: transforming the current game state into HTML and SVG   Game logic: the rules governing transitions between game states   AI logic: selection of the best next move for an AI player   Store: the in-memory data-base holding the application state   Game loop: coordinates and control of the different aspects   Our target architecture uses the traditional decoupling between the view, the game logic (the model) and plugs the elements together though the game loop (the controler):      Store ----------------&gt; Rendering ---------------&gt; Reagent      ^      (reaction)         ^      (send hiccup)      |                         |      |                         | (listen)      |       (update)          |      \\-------------------- Game loop                                |                                |      ,-------------------------| (use to update store)      |                         |      v                         v  Game logic &lt;-------------- AI logic   This is it for the refresher. We will now instantiate this very simple architecture by implementing our Tic Tac Toe, to get a better feel of how it looks like in code.   Tic Tac Toe   Tic Tac Toe is a pretty simple game. The interesting thing about Tic Tac Toe is that it is quite close to Tribolo. Both are turn based games, both feature a board, both have rules tied to the ownership of the cells of the board by the player, and both our games will feature an undo feature.   All of this makes the Tic Tac Toe a pretty good Proof-Of-Concept for our Tribolo game and its architecture. The only noticeable difference will be the absence of Artificial Intelligence in our Tic Tac Toe.   This part is left out for several reasons:      It will save us time and is not needed to explain the architecture   The AI is so simple that it would not inform much on the Tribolo AI   Selecting data structures   We will first begin by designing our data structure. The goal is to model our problem, identifying the entities and the relations between them, to help us reason about the code better during implementation.   Entities and relationships   We identify the following concepts: a cell, a board and a player.   A cell is something that a player can own and is identified by a coordinate (two integers). The game is made of 9 cells, which together form the board.   We are interested in the following relationships between these entities:      The notion of ownership of a cell by a player   Winning cell sets: a player owning one entire set wins the game   A turn represents a given state of Tic Tac Toe: the ownership of the cells by the different players, and the next player to play. We will define a game as a succession of turn with valid transitions between them.   Possible representations   We can represent cells by their natural identifier on the board, their coordinate x and y. We can use the two keywords :cross and :circle to represent each of our player. Winning cell sets can be represented as sets of coordinates. A game can be represented as a vector of turn.   Then, there are at least two ways we can represent the ownership of cells by players:   Choice 1: We could choose to maintain two sets of cells, one for each player. A cell (x,y) being owned by the player P would be represented as (x,y) being in the set of cells associated to player P. Identifying a winner is done by checking if the set of a player includes a winning cell set.   Technically, a turn would be represented as:   {:board {:owner/cross #{[0 0] [1 0]} ;; Cells owned by \"cross\"          :owner/circle #{[0 2]}}     ;; Cells owned by \"circle\"  :player :owner/circle}              ;; Next player to play   Choice 2: We could choose to model the ownership of the cells the other way around. Each cell would be associated a owner, or :none if not owned. The board could be an associative container from cells to players that own them. Identifying a winner is done by accessing the map for each winning cell set, and check if it is fully owned by a single player.   Technically, a turn would be represented as:   {:board {[0 1] :owner/none,          [1 2] :owner/none,          [0 0] :owner/cross,          [2 2] :owner/none,          [0 2] :owner/circle,          [1 1] :owner/none,          [2 1] :owner/none,          [1 0] :owner/cross,          [2 0] :owner/none},  :player :owner/circle}   There are potential variations on this representation as well. We could choose to omit the cells that do not have owners and use nil to represent the absence of owner. Or we could choose to use a vector of vector to hold the owners.   Choice of board representation   For our implementation, we will follow choice 2 and maintain a board associating cells to their respective owners. A game being is succession of turns. So our game will be a vector of maps that each represent a turn:   [{:board {[0 1] :owner/none,           [1 2] :owner/none,           ;; More associations ...           [2 0] :owner/none},   :player :owner/cross},  {:board {[0 1] :owner/none,           [0 0] :owner/cross,           ;; More associations ...           [2 0] :owner/none},   :player :owner/circle}]   Note: We could have tried the representation described in choice 1 or decided not omit cells that are not owned as well. If we tried these representations, we would need to provide a function to list explicitly all the valid coordinates of the board (for the rendering especially). But being more explicit about the valid coordinates allows to have a more generic implementation. For example, we could implement a more exotic Tic Tac Toe where the grid is replaced by a more funky shape. We encourage you to try this option.   Rendering   Because ClojureScript, Reagent and Fighwheel offer together such a dynamic experience, we will start with the rendering of turn. Doing so will help us have quick feedback on the game logic as we develop it.   Callbacks   A sound choice of architecture dictates us that our view must be independent of the statement management of the game, which we named game store.   The usual solution is to use some form of callbacks to decouple these two parts. Although we could make use of a protocol there, we will use a simpler alternative: a map holding the different callbacks functions.   In the rendering code that follows, this map of function will be referred to as callbacks. It will hold the keywords :on-move, :on-restart, :on-undo to represent each of the actions that can be triggered by the user.   Main frame   We want the main frame of our game to be composed of a top panel, holding actions like restart game and undo last move, on top of the representation of the game board, a 3 times 3 grid.   We can represent this easily by creating a namespace frame holding a function render that simply delegates the rendering of the different parts to their associated namespaces, panel and board.   (ns tictactoe.view.frame   (:require     [tictactoe.view.board :as board]     [tictactoe.view.panel :as panel]))   (defn render   \"Rendering the main frame of the game,    takes as input the callbacks to trigger events\"   [{:keys [board] :as turn} callbacks]   [:div    [panel/render-top-panel turn callbacks]    [board/render-board board callbacks]    ])   Top panel   Rendering the top panel of the game is pretty straightforward. We will display two buttons, surrounding a “Tic Tac Toe” title that changes to “Draw Game”, “Cross wins” or “Circle wins” when we reach the end of the game.   (defn- make-button   [on-click txt]   [:button.top-button {:on-click on-click} txt])  (defn render-top-panel   \"Render the top panel:    * The restart game button    * The title of the game    * The undo button\"   [turn {:keys [on-restart on-undo]}]   [:div.scores    [make-button on-restart utils/circle-arrow]    [:h1#title (title/get-title turn)]    [make-button on-undo utils/back-arrow]    ])   This code makes use of two callbacks on-restart-event and on-undo-event that are linked do their corresponding button. The caller of the frame will have to provide the associated callbacks in the map callbacks.   This code also makes use of utilities to create a circle arrow or back arrow. This code is not particularly interesting but is included in this Gist for completeness. The same goes for get-title that computes the title of the game available in this Gist.   Board   Rendering the board of the game consists in creating a SVG panel and filling it with the SVG representation of each cells. Using some helper functions, we can write it in a pretty simple way:   (defn render-board   \"Render the board:    * Creates a SVG panel    * Render the cells in it\"   [board {:keys [on-move]}]   (utils/square-svg-panel     {:model-size board/size      :pixel-size cst/board-pixel-size}     (for [cell board]       [cell/render-cell cell on-move]       )))   This code makes use of the rendering functions for the cells. Each cell is rendered differently based on the owner of the cell:   (defn render-cell   \"Dispatch the rendering of the cell based on the player\"   [[coord owner :as cell] on-move]   (let [renderer (case owner                    :owner/cross render-cross                    :owner/circle render-circle                    render-square)]     (renderer coord {:on-click #(on-move coord)})))   Although we could have used multi-methods to dispatch to the right rendering function, we choose not to. The number of player is fixed and we did not need any customization points.   To finish the rendering of the board, we need to take care of the cells. As this is a bit tedious to play with SVG, we will skip this part. You can refer to the link to the GitHub repo at the end of the post if you are curious.   Game logic   We now have everything we need to display our game. It is great time to move to the implementation of the game logic.   We will build this game logic from the bottom up:      Start with the board: the association of coordinates to their owner   Continue with the turn: the core of the game logic and its rules   Finish with the game: the succession of turn that make up a full game   Board   Our implementation of the board will rely on some useful constants:      The size of the board (width and height are equal)   The vector of valid coordinates on the board   The empty board where each cell has no associated owner   (def size \"The size of the board\" 3)  (def coordinates   \"All the valid coordinates on the board\"   (for [x (range size) y (range size)] [x y]))  (def coordinates? (set coordinates))  (def empty-board (zipmap coordinates (repeat :owner/none)))   The code of the board is rather boring. It merely consists in wrapping operations around the associative container from coordinates to owners. This wrapping is not necessary. We only introduced it to add some assertions and give more specific names.   (defn get-owner-at   \"Get the owner associated to the cell\"   [board coord]   {:pre [(coordinates? coord)]}   (get board coord))  (defn has-owner?   \"Check whether the coord has an owner associated to it\"   [board coord]   {:pre [(coordinates? coord)]}   (not= (get-owner-at board coord) :owner/none))  (defn convert-cell   \"Assign the cell [x y] to a new player\"   [board player coord]   {:pre [(coordinates? coord)          (not (has-owner? board coord))]}   (assoc board coord player))  (defn full-board?   \"Verifies whether the board has any empty cell left\"   [board]   (not-any? #{:owner/none} (vals board)))   Turn   The turn represents the state of the game at a particular point. It holds both the state of the board and the next player to play. The main function attached to a turn is the ability to compute the next-turn from a turn and a coordinate.   The next turn is obtained by converting the cell targeted at the provided coordinate to assign it to the current player. This process only makes sense if the game is not over and if the target coordinate is valid (not owned yet and inside the board):   (defn next-turn   \"Convert a cell to the player color and switch player\"   [turn coord]   (if-not (or (game-over? turn) (invalid-move? turn coord))     (-&gt; turn       (update :board board/convert-cell (:player turn) coord)       (update :player next-player))))   The function above makes use of several helper functions. We will focus on the most interesting one: game-over?. A game is over if either the board is entirely filled, or if a player has won:   (defn game-over?   \"The game is over if either:    * The board is full    * There is a winner\"   [{:keys [board]}]   (or     (board/full-board? board)     (has-winner? board)))   Identifying the winner consists in verifying if a given player owns at least one winning combination of cells. This get-winner functin makes use of the sole-owner function to check if a combination of cells is entirely owned by one given player:      We retrieve the owners of each of the cells   We put these owners in a set to remove duplicates   Singleton sets allow us to identify potential winners   (defn- sole-owner   \"Indicates whether all positions are owned by the same player\"   [board positions]   (let [owners (set (map #(board/get-owner-at board %) positions))]     (case owners       #{:owner/circle} :owner/circle       #{:owner/cross} :owner/cross       nil)))  (defn get-winner   \"Return the winner, or nil if the game has none\"   [{:keys [board]}]   (some #(sole-owner board %) winning-cell-sets))   The interesting part about this approach is that the rules specifying the winning conditions are entirely extracted as winning cell sets:   (def winning-diags   [(filter #(= (first %) (second %)) board/coordinates)    (filter #(= (dec board/size) (reduce + %)) board/coordinates)])  (def winning-rows (partition board/size board/coordinates)) (def winning-lines (algo/transpose winning-rows)) (def winning-cell-sets (concat winning-rows winning-lines winning-diags))   We can easily change these rules by playing with this data alone. For example we could decide that owning all the corners makes you a winner: to do so, we add a set of winning cell containing [0 0], [0 2], [2 0], and [2 2].   Game   To finish modeling our Tic Tac Toe game logic, we are left with implementing the game, the succession of turns. This is quite straightforward:      The start of the game is a vector with only the start turn (empty board)   Playing a turn calls next-turn and adds a new value onto the stack   The current turn of the game is therefore the one at the top of the stack   To undo the last a move is to pop the last turn from the stack   (defn new-game []   [turn/start-turn])  (defn current-turn   [game]   (peek game))  (defn play-move   \"Play current player move at the provided coordinate\"   [game coord]   (if-let [new-turn (turn/next-turn (current-turn game) coord)]     (conj game new-turn)     game))  (defn undo-last-move   \"Remove the last game if there is enough game played\"   [game]   (if (&lt; 1 (count game)) (pop game) game))  (defn handle-event   \"Callback to dispath the event on the game\"   [game event]   (cond     (= event :restart) (new-game)     (= event :undo) (undo-last-move game)     :else (play-move game event)     ))   Plugging it together   Our game logic is done. The rendering is ready to display a turn in our game. We only need to deal with state management and plug all these different parts together.   The state management is pretty light. It consists of an ratom to hold the current state of the game, a reation to access the current turn of the game, and a few functions to deal with event handling:   (defonce app-state (reagent/atom (logic/new-game))) (def current-turn (reaction (logic/current-turn @app-state))) (defn send-event! [e] (swap! app-state logic/handle-event e))  (defn handle-event   \"Dispath the event to the game logic, yielding a new game\"   [game event]   (cond     (= event :restart) (new-game)     (= event :undo) (undo-last-move game)     :else (play-move game event)))   To finish up, plugging the GUI with the state management and the callbacks to the game logic is done in main rendering function:   (defn tic-tac-toe   \"Main entry point, assemble:    * the game state    * the game view\"   []   [frame/render @store/current-turn    {:on-restart #(store/send-event! :restart)     :on-undo #(store/send-event! :undo)     :on-move #(store/send-event! %)}])  (reagent/render [tic-tac-toe]   (js/document.getElementById \"app\"))   We are done. Apart from some boring code that we did not listed in this post, the game is now fully functional (pun intended).   Conclusion and what’s next?   Through the implementation of a Tic-Tac-Toe, we went over the basic architecture we will follow to build our Tribolo game. You can find the full implementation of our Tic-Tac-Toe in this GitHub repository.   Doing this Proof-Of-Concept demonstrated us how simple and effective this architectural style is, and how good it is at separating concerns:      Our game logic is pure and not concerned with state management   Our GUI is only concerned about the turn representation   The top namespace of the software is the only one knowing all the pieces   As far as the game logic is concerned, the events could come from the network Now that our architecture is pretty clear and seems working, our next task will be to develop the Tribolo game based on it. This will be the subject of the next posts.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Clojure"],
        "url": "/blog/2017/03/03/building-clojure-game-2.html",
        "teaser": null
      },{
        "title": "Building a Clojurescript Game Logic",
        "excerpt":"This post is the third in the series of posts focused on the design and implementation of a port in ClojureScript of a board game named Tribolo.   In our first post, we discussed the game, described its rules and came up with a basic target architecture. In our second post, we tested this architecture on a Proof-Of-Concept. We built a Tic Tac Toe to make sure the architecture was sound.   This post will go through the development of the game logic of our Tribolo game, from the definition of the main entities and relationships, to the implementation choices made. The full game is available and playable at this address.   Note: This post builds on top of the previous two posts. In particular, it assumes the reader understands the rules of Tribolo. You can refer to our first post to review these rules.   Entities and relationships   Our first step before going into the implementation will be to think about the different concepts that make up the Tribolo game. Each of the words in bold below underlines an important concept of the game.   Like the Tic Tac Toe game we built in our earlier post, the game is all about player fighting for the ownership of cells. Cells can be identified by a two dimension coordinate. The board is the collection of the the cells of the game.   A game is made of a succession of turn. Each turn represents a valid point in time in a complete game. Unlike the Tic Tac Toe though, cells can change owners over the course of the game. The rules to transfer ownership of cells are specific enough to deserve a name.   We will designate as transition a valid progression from one turn a next turn. There might be several transitions available from a given turn. Each of these transition leads to a new turn. Playing a move can be viewed as following a transition.   A transition between turns consists in realizing one or several jump. Each jump does convert the set of cells it went over. A given jump can only convert cells belonging to one opponent.   The score of a player is the total amount of cells owned by the player. The player with the highest score at the final turn is the winner.   High level design   In the previous section, we figured the concepts we want to represent. Let us try to refine them by associated them some kind of high level API. This API will be our guide during the implementation.   Board   The Board allows to represent the concept of ownership of a cell. Much like in the Tic Tac Toe game, its main goal is to maintain a set of associations from coordinates to their associated owner. The main operations are:      The creation of a new board   The conversion of a cell to a new owner   The retrieval of a cell’s associated owner   The traversal of all associations (for rendering)   In Haskell-ish notation, it would match the following function prototypes (where IO characterizes impure functions):   new-board :: IO Board convert-cell :: Board -&gt; Coord -&gt; Player -&gt; Board get-owner-at :: Board -&gt; Coord -&gt; Player to-seq :: Board -&gt; [(Coord, Player)]   Turn   A turn represents a given state of the game. It gives access to the board, the scores, and the next player to play.   board :: Turn -&gt; Board player :: Turn -&gt; Player scores :: Turn -&gt; Scores   The main operations on a turn are:      To create a new starting turn (when we create a new game)   To compute the transitions available from this turn   To follow one of these transitions (playing a move)    new-init-turn :: IO Turn transitions :: Turn -&gt; Map Coord Transition next-turn :: Turn -&gt; Transition -&gt; Turn   Game   To finish up, we can provide a very simple API for the game. From a game, we should be able to extract the current turn, play a move at a given coordinate, and go back to the previous player move (undo).   new-game :: IO Game current-turn :: Game -&gt; Turn play-at :: Game -&gt; Coord -&gt; Game undo-player-move :: Game -&gt; Game   Board   We will start with the implementation of the board. The goal of this component is to maintain a list of associations from coordinates to their respective owners.   Data structures   In the Tic Tac Toe, we choose to implement the Board with an associative container from coordinates to players. For the sake of experimenting something else, we will settle for a vector of vector of owners.   The outer vector stores the column by column index. The inner vectors stores the player by row index. The main advantages of using this representation is that we can give it a nice spec with the size included in it:   (def width 16) (def height 11)  (s/def ::board   (s/every     (s/every ::player/owner :count height)     :count width))   We can provide an instance of an empty board, which will be helpful when we will need to instantiate a new board:   (def empty-board   \"An empty board of `width` columns times `height` owners\"   (let [empty-column (vec (repeat height :none))]     (vec (repeat width empty-column))))   Specs of the API   Given the high level API we provided in the last section, we can derive the following specs for our board API:   (s/fdef new-board   :ret ::board)  (s/fdef convert-cell   :args (s/cat :board ::board                :coord ::coord                :owner ::player/player)   :ret ::board)  (s/fdef get-owner-at   :args (s/cat :board ::board                :coord ::coord)   :ret ::player/player)  (s/fdef to-seq   :args (s/cat :board ::board)   :ret (s/every (s/tuple ::coord ::player/owner)))   These specifications make use of the specification for coordinates (which makes use of the fact that sets are predicates in Clojure):   (def coordinates   (vec (for [x (range width)              y (range height)]          [x y])))  (s/def ::coord (set coordinates))   Implementation   Most of the implementation for the board API is straightforward. The only interesting bit is the implementation of the new-board function.   A new board must contain 12 randomly located walls, and 12 randomly chosen cells owned by each player. These four sets of 12 cells must be disjoint.   We implement a generic algorithm that will handle the task of picking n elements and attribute them to each element of groups. The core algorithm pick-n-for-each is free of randomness:   (defn zip   \"Create a sequence of tuples, each element being drawn from one collection\"   [&amp; colls]   (apply map vector colls))  (defn pick-n-of-each   \"Pick n `elements` for each of the `groups` starting from the beginning\"   [n elements groups]   (zip elements (mapcat #(repeat n %) groups)))  (defn randomly-pick-n-of-each   \"Pick n `elements` for each of the `groups` randomly\"   [n elements groups]   (pick-n-of-each n (shuffle elements) groups))   Because we isolated the randomness side-effect from the core algorithm, we can convince ourselves that it works properly by writing some tests around it:   (deftest test-pick-n-of-each   (let [pick-n-of-each (comp vec algo/pick-n-of-each)]     (testing \"Varying number of each group\"       (are         [expected n] (= expected (pick-n-of-each n (range) [:a :b]))         [] 0         [[0 :a] [1 :b]] 1         [[0 :a] [1 :a] [2 :b] [3 :b]] 2         ))     (testing \"Varying number of groups\"       (are         [expected groups] (= expected (pick-n-of-each 2 (range) groups))         [] []         [[0 :a] [1 :a]] [:a]         ))     (testing \"No elements to choose from\"       (is         (= [] (pick-n-of-each 1 [] [:a]))         ))))   We can then use the algorithm to implement our new-board function by choosing as elements the coordinates on the board, and as groups the players plus the wall:   (defn new-board   \"Creates a new board with initial positions of each players\"   []   (-&gt;&gt;     (conj player/all :wall)     (algo/randomly-pick-n-of-each cst/init-block-count coordinates)     (reduce       (fn [board [coord owner]] (convert-cell board coord owner))       empty-board)))   Turn   We will continue our implementation with the turn. The turn is the component that hosts most of the game logic of our Tribolo. It is quite large. So we will split its implementation in two:      This section will deal with the turn itself and its representation   The next section will zoom on the computation of the transitions   Data structure   A turn gives us access to current state of the board, the next player to play and the scores. We will use a simple map to store that information, and encode its schema in the following spec:   ;; Imported from \"triboard.logic.scores.cljs\" (s/def ::scores   (s/map-of ::player/player int?))  (s/def ::turn   (s/keys :req-un     [::board/board      ::player/player      ::scores/scores]))   The representation of transitions is a bit trickier. There are many different possible implementations available. We could represent transitions as functions from turn to turn. We could try to create a protocol for it.   But because Clojure loves data, we will represent these transitions as data. A transition will be a collection jumps, with each jump being a standard map, holding:      The destination of the jump (an empty cell)   The player winning the cells jumped over   The player loosing the cells jumped over   The coordinates of the cells jumped over   We can therefore describe a jump and a transition using the specs that follow:   (s/def ::destination ::board/coord) (s/def ::taken (s/coll-of ::board/coord)) (s/def ::winner ::player/player) (s/def ::looser ::player/player)  (s/def ::jump   (s/keys :req-un [::destination ::taken ::winner ::looser]))  (s/def ::transition (s/every ::jump))   Specs of the API   We can also spec the main functions of our Turn API, based on the previous specs for jump and transitions (which we isolated to the namespace transition):   (s/fdef next-turn   :args (s/cat :turn ::turn                :transition ::transition/transition)   :ret ::turn)  (s/fdef transitions   :args (s/cat :turn ::turn)   :ret (s/map-of ::transition/destination ::transition/transition))   Implementatoin (transition)   We might expect the transitions function to be quite complex. Its implementation is in fact quite simple: we only access the field of the turn data structure:   (defn transitions   \"Return the transitions available for the next player\"   [turn]   (:transitions turn))   This is due to the rules of Tribolo. A player may not have any available transition to play. If so, he passes his turn and we consider the next player in the list. We must then repeat the same again or move to the next player.   As a consequence, to implement next-turn and find the next player to play, we must compute the transitions of the newly created turn. We keep this computation cached inside the turn for optimization purposes.   Implementation (next-turn)   To compute the next turn of a game from a previous turn and a transition, we will go through three steps:      We modify the board to take into account the jumps   We modify the scores to be aligned with the new board   We find the next player to play by looking at available transitions   (defn next-turn   \"Apply the transtion to the current turn, yielding a new turn\"   [turn transition]   (-&gt; turn     (update :board transition/apply-transition transition)     (update :scores scores/update-scores transition)     (with-next-player)))   The functions apply-transitions and update-scores scan the transitions and update the board and the scores respectively. The interesting part is the computation of the next player, which we will describe below.   Implementation (next-player)   As discussed earlier, finding the next player to play requires to evaluate the transitions available from our current turn.   We search for the first player that has at least a move to play. We temporarily assume the existence of a function transition/all-transitions that return a map from player to their respective available transitions.   (defn- who-can-play   \"Given the current player and the transitions for the next turn,    returns the next player that has at least one transition available\"   [player transitions]   (filter                         ;; Keep only the players which     #(contains? transitions %)    ;; have at least a valid move to play     (player/next-three player)))  ;; from the next three players  (defn- with-next-player   \"Complete the turn to compute to find the next player than can act    * Requires to look-ahead for the next possible transitions    * To save computation, keep this look-ahead available\"   [{:keys [board player] :as turn}]   (let [transitions (transition/all-transitions board)         next-player (first (who-can-play player transitions))]     (merge turn       {:transitions (get transitions next-player) ;; Keep the transitions of player        :player next-player})))                    ;; Inside the turn (caching)   This ends up the implementation of the turn. The only missing part is the implementation of all-transitions. This is the subject of the next section.   Computing transitions   We will now discuss the implementation of the Tribolo game logic core: the identification of all the valid transitions from a given board. This means identifying all the possible jumps that can be done by any player, before grouping them by winning player and jump destination coordinate.   Performance constraints   The computation of the transitions from a given turn is the most CPU intensive task of the whole game. This will be especially true when we will go into the design and implementation of our AI.   As a consequence, the code that follows makes use of JavaScript arrays over ClojureScript vectors. This simple optimization trick brought nearly a 2X improvement on the AI. The same motivation is behind the use of low level loop-recur constructs in the following algorithms.   Algorithm   The goal of the algorithm is to identify the jumps and then to group them by jump destination and player. A potential jump is a contiguous sequence of cells owned by the same player. It becomes a real jump if it is surrounded by:      A cell with no owner: the destination of the jump   A cell with another owner: the winner of the jump   This contiguous sequence of cell must follow an row, a column, or a diagonal of the board. A wall on either side means there can be no jump.   Thoughts on implementation   We can visualize an implementation based on the use of the partition and partition-by algorithms:      Using partition-by on cells to identify contiguous sequences of owners   Using partition to group contiguous sequences by window of three   This idea is demonstrated below in the REPL on the first row of a sample board. It would have to be done for each row, each column, and each diagonal:   ;; Partitioning by owner of the board gives contiguous sequences (let [first-line (map vector (repeat 0) (range 0 16))]   (partition-by #(board/get-owner-at board %) first-line))  ;; Contiguous sequences of coordinates =&gt; (([0 0]) ([0 1] [0 2] [0 3] [0 4]) ([0 5])  ([0 6]) ([0 7]) ([0 8] [0 9]) ([0 10])  ([0 11] [0 12] [0 13] [0 14] [0 15]))  ;; Making some windows out of it (partition 3 1 *1) =&gt; ((([0 0]) ([0 1] [0 2] [0 3] [0 4]) ([0 5])) ;; First window  (([0 1] [0 2] [0 3] [0 4]) ([0 5]) ([0 6])) ;; Second window  (([0 5]) ([0 6]) ([0 7]))  (([0 6]) ([0 7]) ([0 8] [0 9]))  (([0 7]) ([0 8] [0 9]) ([0 10]))  (([0 8] [0 9]) ([0 10]) ([0 11] [0 12] [0 13] [0 14] [0 15])))   This algorithm would “touch” every cell 4 times (one for each direction), leading to 16 times 11 times 4 cell reads, for a total of 704. This algorithm is nice and fine, but it is not the one we will implement. I could not find a way to make it fast enough.   Chosen algorithm   The algorithm we will implement is much more naive than the one described above. We will scan each empty cell and check in each direction if it is the destination of a jump.   This is not optimal: we will touch the cells more times than with our previous algorithm. It will require around 1200 cell reads at the start of the game, going down when the number of empty cells decreases.   This also looks quite naive as we could try to keep some of that computation between turns. It would require tracing what jumps are invalidated by another jump, which does not seem trivial.   Scanning and grouping   We will start by the implementation of the outer loop of the algorithm. This loop will scan every single cell of the board, compute all the available jumps from this position, and group them by player and jump destination.   As indicated before in the performance constraints section, this algorithm needs to be pretty fast, and makes use of a conversion to a JavaScript array at the start:   (defn all-transitions   [board]   (let [aboard (board/board-&gt;array board)]    ;; Convert to JS array     (transduce       (mapcat #(available-jumps-at aboard %)) ;; Compute jumps at a given position       (group-by-reducer :winner :destination) ;; Group by jump winner and destination       board/coordinates)))   This code makes use of the group-by-reducer helper function, which allows to group elements by on several projections into a nested map as output:   (defn group-by-reducer   \"Create a reducer that groups by the provided key\"   [&amp; key-fns]   (fn     ([] {})     ([result] result)     ([result val]       (let [keys ((apply juxt key-fns) val)]         (update-in result keys conj val)))))   Finding jumps from a destination point   To find the jumps available at a given position, the destination of the jump, we start at an empty cell (not owned by any player).   We then move from the destination point in a fixed direction. The first player we meet is the looser of the potential jump. We continue until we find a cell with a different owner. This player is the winner of the jump.   We collect the coordinates along the way to identify the “jumped over” cells (in the taken vector) until we reach the second player. In case we hit a wall or another empty cell first, we stop the exploration: there is no valid jump in the searched direction. We also watch for going out of the board.   This algorithm translates to the following code, which searches for a jump in a fixed direction from the destination of the jump:   (defn- ^boolean block-jump? [owner]   (or (= owner :none) (= owner :wall)))  (defn- ^boolean jump-start? [looser owner]   (and looser (not= looser owner)))  (defn- ^boolean in-board? [x y]   (and (&lt; -1 x board/width) (&lt; -1 y board/height)))  (defn- seek-jump-source-toward   \"Starting from the destination of a jump (a non-owned cell):    * Search for valid source for the jump    * Collect the jumped cells along the way\"   [board [x-init y-init :as jump-destination] [dx dy]]   (loop [x (+ x-init dx)          y (+ y-init dy)          looser nil          taken []]     (if (in-board? x y)       (let [owner (aget board x y)]         (cond           (block-jump? owner) nil           (jump-start? looser owner) {:winner owner                                       :looser looser                                       :destination jump-destination                                       :taken taken}           :else (recur                   (+ x dx)                   (+ y dy)                   owner                   (conj taken [x y])))         ))))   We have to repeat this algorithm for each possible jump direction. We ignore the empty cells since they cannot be the destination of a jump:   (defn- ^boolean empty-cell?   [board [x y]]   (= :none (aget board x y)))  (defn- available-jumps-at   \"Provides the list of jumps that can be done at a given `jump-destination`\"   [board jump-destination]   (if (empty-cell? board jump-destination)     (eduction       (keep #(seek-jump-source-toward board jump-destination %))       cst/directions)))   Game   The last missing piece of the game logic is the implementation of the game. The game is simply a succession of turn. We can translate the high level API we gave to it into the following specs:   (s/def ::game (s/coll-of ::turn/turn))  (s/fdef current-turn   :args (s/cat :game ::game)   :ret ::turn/turn)  (s/fdef play-move   :args (s/cat :game ::game                :coord ::board/coord)   :ret ::game)  (s/fdef undo-player-move   :args (s/cat :game ::game)   :ret ::game)   Its implementation is not terribly thrilling. It is like the implementation we used for Tic Tac Toe with one twist: the undo may go back several turns to find the last turn of the human player. The implementation is listed in this GitHub Gist for completeness.   Conclusion and what’s next?   In this (pretty long) post, we went over the complete game logic of the Tribolo game, from the high level design to the implementation.   In the next posts, we will continue this journey and see how we can implement the other aspects of the game (Artificial Intelligence, User Interface, Game Loop, etc.).   But before we do that, we will spend the next post on discussing the use we made of Clojure Spec inside the game logic we implemented today.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Clojure"],
        "url": "/blog/2017/03/10/building-clojure-game-3.html",
        "teaser": null
      },{
        "title": "Paramorph your DSL (C++)",
        "excerpt":"In previous posts, we went over the process of building a DSL for arithmetic operations and introduced the concept of Catamorphism as a way to decouple the traversal of an AST from the operations we want to perform on it.   We saw how it could help us compose operations before traversing the AST of our DSL, leading to more efficient composition and better testability.   We first did this exercise in Haskell, introducing the concept of Catamorphism through its wonderful type system before exploring the limits of its applicability in C++. The full series of post is available below for reference:      Catamorph your DSL: Introduction   Catamorph your DSL: Deep Dive   Catamorph your DSL: Trade-offs   Catamorph your DSL: Clojure   Catamorph your DSL: C++ Port   This post will build on top of the Catamorph your DSL: C++ Port. We will introduce, through a motivated use case, another very close and useful recursion scheme, Paramorphisms, and try to implement them in C++.   Reminder: our arithmetic DSL   Our Arithmetic DSL allows to build expression composed of operations like addition and multiplication of integer constants and integers variables. An arithmetic expression is one of the following:      A constant value (and integer for simplicity)   A variable (identified by a string for simplicity)   An addition of a vector of sub-expressions   A multiplication of a vector of sub-expressions   Because an AST alone is not very useful, we added several interpreters on our DSL to play with it:      prn to pretty print our Arithmetic expressions   eval to compute the value of an expression, given the value of all variables   optimize to simplify and optimize our expression   partial to partially evaluate our expression, given the value of some variables   dependencies to retrieve not yet resolved variables from our expression   Reminder: recursion schemes   Looking at our interpreters, we noticed in our previous post that they all had in common the need to traverse the full AST. We used Catamorphisms to factorize this concern out of our interpreters.   This section is a short overview of what Catamorphism are for and how we implemented them in C++. You can skip it if you feel comfortable with the notion already.   Open recursion on types   To use Catamorphisms, we first need to generalize our Arithmetic expression and make it an open recursive data type: expression_r templated on a parameter type R, which represents the type of the sub-expressions.   using nb = int; using id = std::string;  struct add_tag {}; struct mul_tag {};  template&lt;typename Tag, typename R&gt; struct op {    op() = default;     template&lt;typename Range&gt;    explicit op (Range const&amp; rng) : m_rands(rng.begin(), rng.end()) {}        std::vector&lt;R&gt; const&amp; rands() const { return m_rands; }     private:    std::vector&lt;R&gt; m_rands; };  template&lt;typename R&gt; using add_op = op&lt;add_tag, R&gt;; template&lt;typename R&gt; using mul_op = op&lt;mul_tag, R&gt;;  template&lt;typename R&gt; using expression_r = boost::variant&lt;int, id, add_op&lt;R&gt;, mul_op&lt;R&gt;&gt;;   An expression of our DSL is then defined such as the template parameter R is itself an expression. In more formal terms, expression is the fixed point of the expression_r type. We can compute it using CRTP and boost::recursive_wrapper.   struct expression    : boost::recursive_wrapper&lt;expression_r&lt;expression&gt;&gt; {    using boost::recursive_wrapper&lt;expression_r&lt;expression&gt;&gt;::recursive_wrapper; };   Functor instance   We made our expression_r type an instance of a Functor by implementing a fmap function for our type. Note that by Functor here, we mean the mathematical construct, and not function objects.   The transformation map given to fmap applies on the template parameter of the expression_r and may modify its type. In other words, fmap allows to transform the sub-expressions.   template&lt;typename A, typename M&gt; auto fmap(M map, expression_r&lt;A&gt; const&amp; e) {    using B = decltype(map(std::declval&lt;A&gt;()));    using Out = expression_r&lt;B&gt;;        if (auto* o = get_as_add(e))       return Out(add_op&lt;B&gt;(o-&gt;rands() | transformed(map)));           if (auto* o = get_as_mul(e))       return Out(mul_op&lt;B&gt;(o-&gt;rands() | transformed(map)));        if (auto* i = get_as_cst(e)) return Out(*i);    if (auto* v = get_as_var(e)) return Out(*v);    throw_missing_pattern_matching_clause(); }   Note: because the function provided to fmap can have different types as input and output, the type of the template parameter of expression_r can change under fmap, and with it, the nature of the recursion.   Generic tree traversal   We then defined the cata function, which implements the Catamorphism recursion scheme. It takes what we will call an algebra as parameter, and returns a transformation on a whole AST. The algebra is a function that takes an expression_r templated on Out, and outputs an Out value.   // Catamorphism algebra Out catamorphism_algebra(expression_r&lt;Out&gt; const&amp; e);   The result of cata on the algebra (curried) is a function that applies on a full expression and returns an Out value:   template&lt;typename Out, typename Algebra&gt; Out cata(Algebra f, expression const&amp; ast) {    return f(       fmap(          [f](expression const&amp; e) -&gt; Out { return cata&lt;Out&gt;(f, e); },          ast.get())); }   For instance, the following print_alg algebra transforms an expression_r templated on string into a string. Its goal is to implement a “pretty print” of the expression at one stage of the expression alone.   template&lt;typename Tag&gt; std::string print_op(op&lt;Tag, std::string&gt; const&amp; e, std::string const&amp; op_repr) {    return std::string(\"(\") + op_repr + \" \" + boost::algorithm::join(e.rands(), \" \") + \")\"; }  std::string print_alg(expression_r&lt;std::string&gt; const&amp; e) {    if (auto* o = get_as_add(e)) return print_op(*o, \"+\");    if (auto* o = get_as_mul(e)) return print_op(*o, \"*\");    if (auto* i = get_as_cst(e)) return std::to_string(*i);    if (auto* v = get_as_var(e)) return *v;    throw_missing_pattern_matching_clause(); }   Given to cata, it will become an function that transforms a complete expression into a string, basically being promoted to operate on all stages of the expression.   expression e = add({    cst(1),    cst(2),    mul({cst(0), var(\"x\"), var(\"y\")}),    mul({cst(1), var(\"y\"), add({cst(2), var(\"x\")})}),    add({cst(0), var(\"x\")})    });  std::cout &lt;&lt; para&lt;std::string&gt;(print_infix, e) &lt;&lt; std::endl;  // Outputs =&gt; 1 + 2 + 0 * x * y + 1 * y * (2 + x) + 0 + x   The use case that breaks the pattern   Every single technique we use in Software Engineering has its limits. Outside of these limits, the technique will either not apply or might not be the best tool for the job. Catamorphisms are no exception to this rule.   Because Catamorphisms are a way to factorize a particular recursion scheme, it cannot apply for recursions that do not follow the given pattern. We will now explore one use case that demonstrates these limits.   Infix notation   Let us imagine that the client of our arithmetic DSL does not like the prefix notation of our pretty print function. Instead, he would like the arithmetic expressions to be pretty printed in infix notation. For example, 1 + y + x * 3 instead of (+ 1 y (* x 3)).   Now, and contrary to the prefix notation which follows a pretty simple parenthesizing scheme, pretty printing in infix notation requires us to be careful. A wrong use of parentheses could change the meaning of the expression.   A first attempt   As a first approximation, we could use the following strategy for the placement of the parentheses in our infix notation:      Systematically surround the arguments of a multiplication with parentheses   Never surround the arguments of an addition with parentheses   Implementing the pretty printer that follows this strategy can be done using Catamorphisms. We use Boost to make the code simpler:   std::string print_infix_op_bad(op&lt;add_tag, std::string&gt; const&amp; e) {    return boost::algorithm::join(e.rands(), \" + \"); }  std::string with_parens(std::string const&amp; s) {    return std::string(\"(\") + s + \")\"; }  std::string print_infix_op_bad(op&lt;mul_tag, std::string&gt; const&amp; e) {    return boost::algorithm::join(e.rands() | transformed(with_parens), \" * \"); }  std::string print_infix_bad(expression_r&lt;std::string&gt; const&amp; e) {    if (auto* o = get_as_add(e)) return print_infix_op_bad(*o);    if (auto* o = get_as_mul(e)) return print_infix_op_bad(*o);    if (auto* i = get_as_cst(e)) return std::to_string(*i);    if (auto* v = get_as_var(e)) return *v;    throw_missing_pattern_matching_clause(); }   We can try this first implementation on our test arithmetic expression:   expression e = add({    cst(1),    cst(2),    mul({cst(0), var(\"x\"), var(\"y\")}),    mul({cst(1), var(\"y\"), add({cst(2), var(\"x\")})}),    add({cst(0), var(\"x\")})    });  std::cout &lt;&lt; cata&lt;std::string&gt;(print_infix_bad, e) &lt;&lt; std::endl;  // Outputs =&gt; 1 + 2 + (0) * (x) * (y) + (1) * (y) * (2 + x) + 0 + x   What we get is is a correct result: the pretty printed expression has indeed the right meaning. But there are so much unneeded parentheses that the expression is really hard to read. We have to do much better.   Improving parenthesizing   To get better results, we need our infix notation to avoid adding useless pairs of parentheses. We know how to fix this: a multiplication only needs to add parentheses around sub-expressions that correspond to additions.   Unfortunately, Catamorphisms are not a powerful enough recursion scheme to implement this logic. The algebra given to the Catamorphism has no access to the sub-expressions, only their resulting string.   As a consequence, there is no way to know whether the expression was previously an addition (except by parsing it, which would truly be awful). The Catamorphism has failed us here: we need to turn to a different recursion scheme.   From catamorphism to paramorphism   The previous use case demonstrated us that we need the information on whether a sub-expression is an addition when dealing with the multiplication.   We will turn to the recursion scheme known as Paramorphism, which is like a Catamorphism but with added contextual information.   Paramorphisms   Paramorphisms are pretty close to Catamorphisms. The goal is identical: it turns a local transformation on an open recursive data structure into a global transformation on the fixed point of this data structure.   The difference is the prototype of the algebra given as parameter to the recursion scheme. Instead of taking the open recursive type parameterized on the output type of the transformation, the algebra takes a an open recursive type parameterized on a pair:      The first element of the pair is the output of the sub-expression transformation   The second element of the pair is the sub-expression before the transformation   In more concrete terms, and applied to our arithmetic expression, here are the prototypes for the algebra of catamorphism and paramorphism:   // CATAMORPHISM Out catamorphism_algebra(   expression_r&lt;Out&gt; const&amp; e);  // PARAMORPHISM Out paramorphism_algebra(   expression_r&lt;std::pair&lt;Out, expression const*&gt;&gt; const&amp; e);   The second element of the pair is the contextual information. In our specific case, it will provide us with the information about the sub-expression needed to make the right parenthesizing choice.   Paramorphism implementation   We will now implement the para function, whose goal is to transform a local algebra into a global transformation on an arithmetic expression.   The implementation is very similar to the one of the Catamorphism. The only modification concerns the lambda provided to the fmap function, which needs to return a pair instead of a single value:   template&lt;typename Out, typename Algebra&gt; Out para(Algebra f, expression const&amp; ast) {    return f(       fmap(          [f](expression const&amp; e) -&gt; std::pair&lt;Out, expression const*&gt; {             return { para&lt;Out&gt;(f, e), &amp;e };          },          ast.get())); }   Example: implementing the infix notation   We now have enough contextual information to implement our infix notation properly. For each sub-expression of addition and multiplication, our algebra has access to:      The pretty printed sub-expression (first argument of the pair)   The sub-expression itself (second argument of the pair)   We can therefore implement the pretty printing of the multiplication such that it adds parentheses around addition sub-expressions only.   std::string print_op_infix(op&lt;add_tag, std::pair&lt;std::string, expression const*&gt;&gt; const&amp; e) {    auto fst = [](auto const&amp; e) { return e.first; };     return boost::algorithm::join(e.rands() | transformed(fst), \" + \"); }  std::string print_op_infix(op&lt;mul_tag, std::pair&lt;std::string, expression const*&gt;&gt; const&amp; e) {    auto wrap_addition = [](auto const&amp; sub_expr) {       if (get_as_add(sub_expr.second-&gt;get()))          return with_parens(sub_expr.first);       return sub_expr.first;    };    return boost::algorithm::join(e.rands() | transformed(wrap_addition), \" * \"); }  std::string print_infix(expression_r&lt;std::pair&lt;std::string, expression const*&gt;&gt; const&amp; e) {    if (auto* o = get_as_add(e)) return print_op_infix(*o);    if (auto* o = get_as_mul(e)) return print_op_infix(*o);    if (auto* i = get_as_cst(e)) return std::to_string(*i);    if (auto* v = get_as_var(e)) return *v;    throw_missing_pattern_matching_clause(); }   We can try this second implementation on our test arithmetic expression. This result is clearly much better. The resulting infix notation has no unnecessary parentheses left:   expression e = add({    cst(1),    cst(2),    mul({cst(0), var(\"x\"), var(\"y\")}),    mul({cst(1), var(\"y\"), add({cst(2), var(\"x\")})}),    add({cst(0), var(\"x\")})    });  std::cout &lt;&lt; para&lt;std::string&gt;(print_infix, e) &lt;&lt; std::endl;  // Outputs =&gt; 1 + 2 + 0 * x * y + 1 * y * (2 + x) + 0 + x   Conclusion   This was the second post dedicated to the implementation of the recursion schemes often used in Haskell into C++.   Through a motivating use case, we discovered the limits of the Catamorphism recursion scheme, and learned about a new strictly more powerful one: Paramorphism.   Although typically unused in C++, we managed to provide a concise implementation of it. The result is clearly not as short and beautiful than in Haskell, but has the merit to show that it is not outside of the expressiveness range of C++.   You can access the full code of the DSL, along with all its associated interpreters, in this Gist or alternatively in Ideone.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2017/03/31/paramorph-dsl-cpp.html",
        "teaser": null
      },{
        "title": "Lost in std::is_permutation complexity",
        "excerpt":"This post is dedicated to an STL algorithm I discovered only recently, and which caused me some serious performance issue at my first use of it: std::is_permutation.   The algorithm appeared in the STL with C++11 and in principle is quite a useful one. It is however deeply penalized by its inefficiency, which make this algorithm almost impractical.   In this post, we will first describe the algorithm itself and describe some of the use cases that makes it interesting in principle.   Then we will talk a bit about my misadventure with it. This misadventure could have been avoided by reading the manual and not use std::is_permutation in the first place. But I suspect other might fall into the trap as well, for reasons that we will describe as well.   We will conclude by discussing the design decision that makes this algorithm implementation inefficient by construction, and discuss some alternatives.   Motivation for std::is_permutation   From the the cppreference documentation, std::is_permutation is an algorithm that takes two ranges as input. It indicates whether there exists a rearrangement of the elements that would make both ranges be equal. The equality criteria can be parameterized.   Anagrams   The simplest use case for std::is_permutation would be to implement a function that would tell if two strings are anagrams of each others.   An anagram is “the result of rearranging the letters of a word [..] to produce a new word [..], using all the original letters exactly once” (Wikipedia). This is a perfect match for std::is_permutation:   bool is_anagram(std::string const&amp; lhs, std::string const&amp; rhs) {   return std::is_permutation(begin(lhs), end(lhs), begin(rhs), end(rhs)); }   Equality but for the ordering   A more interesting use case of std::is_permutation is to check that two collections are equal but for the ordering. In other words, that they contain the exact same elements. This is a pretty common use case inside Unit Tests.   For instance, we may want to test a function eval_accounting_entries that produces a vector of accounting entries for the current period. The contract says nothing about the order of the accounting entries produced.   In order to avoid testing more than the actual contract of eval_accounting_entries, increasing the precision and resilience of our unit test, we could use std::is_permutation instead of std::equal.   std::vector&lt;AccountingEntry&gt; expected = ...; std::vector&lt;AccountingEntry&gt; result = eval_accounting_entries(...); \t ASSERT_TRUE(   std::is_permutation(     begin(expected), end(expected),     begin(result), end(result)));   This check of equality without the ordering might be useful as well inside a GUI. We might be interested in notifying some listening processes if the user modifies some accounting entries, but not if the modification is a simple rearrangement.   Testing an unstable sort   Time to describe my little misadventure. Let us say that we just implemented a new unstable sort algorithm and want to make sure that it is correct. How can we test that our implementation is bug free?   We could do some example based tests for starter, before adding some Property Based Testing to increase our level of confidence. The plan is to:      Find a good invariant that, if it holds, proves the sort is correct   Generate a bunch of random vectors   Call our sort routine on each of these vectors   Check that the invariant hold on the outputs of the sort   Finding a good property to check   If our sort was stable, we could check the result of our sort against std::stable_sort. That would make it a perfect property. But our sort is unstable. So we cannot compare it against a reference sort to prove that it works. Sure, std::sort is unstable too, but the unstable swaps do not have to be the same.   Fortunately for us, sorting a collection is performing a permutation of the elements of a range such that the resulting order of the elements complies with the increasing order relative to some ordering relation R.   It means that we can check that our unstable sort works fine by simply checking whether the resulting collection answers true to both std::is_permutation and std::is_sorted.   Implementing the property   We can port this definition into code. The check_sort_property function returns true if the result iterable is a correct sort of the input iterable:   template&lt;typename InputIterable, typename ResultIterable, typename Less&gt; bool check_sort_property(InputIterable const&amp; input,                          ResultIterable const&amp; result,                          Less less) {   return     std::is_permutation(begin(input), end(input), begin(result), end(result))     &amp;&amp; std::is_sorted(begin(result), end(result), less); }  template&lt;typename InputIterable, typename ResultIterable&gt; bool check_sort_property(InputIterable const&amp; input,                          ResultIterable const&amp; result) {   auto less = std::less&lt;typename InputIterable::value_type&gt;();   return check_sort_property(input, result, less); }   Note: Asserting that std::is_sorted returns true would not be enough: there could be missing elements. Asserting that the number of elements is the same would not be enough either: it could be the same element repeated as many time as needed. We really need the permutation check to ensure our sort works correctly.   Generating vectors   We then need to generate random vectors to perform our tests. We define a function make_vector_gen that will return a lambda which we can call to generate random vectors for us.      The max_size allows us to parameterise how big the vector can be.   The value_generator allows us to generate the content of the vector   With this small piece of code, we are able to generate random vectors made of random elements of any chosen type:   template&lt;typename ValueGenerator&gt; auto make_vector_gen(int max_size, ValueGenerator value_generator) {   return [=](std::mt19937&amp; gen) {     std::uniform_int_distribution&lt;int&gt; distribution (0, max_size);     std::vector&lt;decltype(value_generator(gen))&gt; out(distribution(gen));     for (auto&amp; val: out) val = value_generator(gen);     return out;   }; }   Note: alternatively, we could rely on RapidCheck. This is the choice to make if it was production code. But as the generator is simple enough, we can do it by hand here.   Generating tuples   To test our our sort on our random vector, we must first be able to generate some random elements inside our vector. We will settle for tuples of integers.   Why tuples and not simple integers? The motivation is to test our sort routine with a “less” function that orders by the second value of the tuple. This will allow us to exercise the “unstable” part of our algorithm (sorting integers would show no differences between stable and unstable sorts).   We design our tuple generator generically. The following code allows to generate arbitrarily large tuples, makes of arbitrarily chosen types:   template&lt;typename... Generators&gt; auto make_tuple_gen(Generators... generators) {   return [=](std::mt19937&amp; gen)   {     return std::make_tuple(generators(gen)...);   }; }   Composing and testing our generators   We now have the ability to generate vectors of tuples of arbitrary types. We can create a last generator of random integers:   auto int_gen(int max_size) {   return [=](std::mt19937&amp; gen) -&gt; int {     std::uniform_int_distribution&lt;int&gt; distribution(0, max_size);     return distribution(gen);   }; }   We can now easily combine all of our generators to create a vector of tuples of integers. We can quickly check that it behaves correctly:   auto int_vector_gen = make_vector_gen(10, int_gen(1000)); auto int_pair_gen = make_tuple_gen(int_gen(100), int_gen(1000)); auto int_pair_vector_gen = make_vector_gen(20, int_pair_gen);  // Example code std::mt19937 gen = ...;  int_vector_gen(gen); //Outputs: [171,614,15,346,263,44]  int_pair_vector_gen(gen); //Outputs: [(1, 280),(47, 218),(42, 867),(32, 119),(48, 396),(58, 82),(41, 576),(63, 108),(16, 108),(50, 216)]   Three, two, one… test!   Everything is ready. We can now test that our custom_sort routine does its job correctly by running some random test inputs and check that our sort property always holds.   Let us start small, with one single example of a vector holding up to 50,000 tuples of integers, which we will sort by their second component:   auto int_pair_gen = make_tuple_gen(int_gen(100), int_gen(1000)); auto inputs_gen = make_vector_gen(50000, int_pair_gen); auto less_on_second = ordering_by_index&lt;1&gt;();  //Generate a vector of up to 50k elements auto input = inputs_gen(gen);  //To test our sorting routine auto sorted = input; custom_sort(begin(sorted), end(sorted), less_on_second);  //Check the property of unstable sort check_sort_property(input, sorted, less_on_second);   Now, this is where it hurts. Depending on the generating inputs:      The actual sorting lasts less than 1 milliseconds   The property check might last more than 500 milliseconds   So much for the fast feedback of unit tests… With 100 test samples (the default of most property based testing libraries), we have to wait almost a minute to get some feedback. What is happening?   Hopelessly inefficient std::is_permutation   The reason why the property check is so slow is because the implementation of std::is_permutation has worst case quadratic complexity. This behaviour is documented in both cplusplus.com and en.cppreference.com.   Note: obviously, I should have read the manual. But had I read the manual, I would have chosen not to use std::is_permutation. This is not very satisfactory.   Quadratic by design   Given the definition of the std::is_permutation algorithm, there is no other way it could be better. Having only access to an equality predicate, the algorithm cannot do much better than trying (in the worse case) all the combinations.   By asking for a little more than an equality predicate, it could do a much better job. We will explore such alternatives later in the post.   Surprisingly slow   Most algorithm design courses teach us that quadratic complexity is something we should not accept unless we have no other choice (*). The big problem here is that there are much more efficient algorithms available for us to check for std::is_permutation.   Most developers do know about these better algorithms, as they are frequently asked as interview questions. This makes the quadratic implementation of std::is_permutation counter-intuitively slow, increasing the the chance of introducing a performance issue in the software.   (*): The rationale is that quadratic algorithms do not scale. Linear algorithms scale with the hardware. Throwing a multiplicative logarithm does not change this result that much: with twice as much as resources, such algorithm can handle nearly twice as big inputs.   What about Range-V3?   Range V3 seems to follow the same algorithm as the one used for std::is_permutation. It also implements a quadratic algorithm to do the job. You can have a look at permutation.hpp and read the code by yourself.   Some possible alternatives   There are plenty of alternatives to implement std::is_permutation much more efficiently. Which alternative to select depends on the concepts available on the type inside the iterables provided to std::is_permutation.   Potential solutions   We list below some of these most obvious algorithms we could use to implement std::is_permutation, in decreasing order of preference:   For types with few inhabitants, like char, we can number each inhabitant. We can create an array, indexed by each inhabitant, and count the number of characters for both strings. We then check that the number of occurrences of each character is the same in both strings. The resulting algorithm is O(N).   For types with hash functions, we can follow the same principle, but with a hash map. We count the frequency of each term in each collection and compare the result. We then check if the keys and their associated values (the number of occurrences of the key) match in both hash maps. The resulting algorithm is slower, but still O(N).   For types with a strict total ordering, we can sort both collections and compare them for equality. If their size differ, we can early return with a negative answer. We can also sort one of the collection, and binary search each element of the other collection in it (the usual trick is to sort the smallest collection), but that would require all elements to be unique in order to work. The resulting algorithm is O(N * log N) in both cases.   Drawbacks of the alternatives   Each of these alternative solutions are much faster than the std::is_permutation current implementation. They will scale properly.   The problem with each of these algorithms is that they require extra memory to perform their work. The first two alternatives requires either an array or an hash map, and the last one will have to create a vector to avoid mutating its inputs (and also, binary search requires a random access container to be efficient, which is not a given).   One additional problem with each of these algorithms is that they ask for more than the standard Regular Type requirements on which the STL is based. On the other side, the std::is_permutation implementation is perfectly satisfied by the Regular Type requirements.   Conclusion and what’s next?   We went over a use case that show how penalising the quadratic algorithmic complexity of std::is_permutation can be. We discussed why the algorithm could not be made better with the requirements it makes on the types contained in the ranges it takes as inputs.   We went over some alternative, in which the algorithm complexity could be vastly improved by requiring just a bit more on the types manipulated inside the algorithm.   The next post will discuss a bit more these additional requirements and whether they can be justified as basic assumption on types manipulated by the STL algorithms.   ","categories": ["modern-cpp"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2017/04/04/std-permuration-complexity.html",
        "teaser": null
      },{
        "title": "How to improve std::is_permutation complexity",
        "excerpt":"In our previous post, we talked about the std::is_permutation algorithm and its algorithm complexity issue and wee went over several use cases that seems like perfect matches for this algorithm for which we cannot really use it because of its complexity issues.   Indeed, because of its quadratic complexity, we made the argument that std::is_permutation is almost impractical: its costs is not worth the trade-off of manually coding the alternative.   Finally, we discuss three alternative of more efficient implementations, that each require some extra memory and some additional requirements on the inputs.   In this post, we will discuss these implementations further, and the additional requirements they add on the inputs. The goal is to explore whether these additional requirements make sense and could be used as basis for an alternate implementation. We will end up by a proposal of evolution for std::is_permutation and some other parts of the STL as well.   Alternate implementations   Since the standard implementation of std::is_permutation is too slow to be usable in practice, we have to find some more efficient implementations for it.   Our previous post listed three such alternatives. These alternatives depend on the operations available on the type std::is_permutation iterates over:      An array based approach for small vocabulary sizes (like ASCII strings)   An hash map based approach in case std::hash is available   An sort based approach in case a strict total ordering is available   Since the array based approach is at the same time very specialized and very similar to the hash map based approach, we will only cover the approaches 2 and 3 below.   Hash based implementation   If we have a hash available on the types we iterate over, the implementation of is_permutation can leverage it to perform fast searches inside a hash map. The implementation consists in:      Counting the number of occurrences of each elements in the left iterable   Counting the number of occurrences of each elements in the right iterable   Checking that these elements and occurrence counts match up   We can be a bit more clever than this in our implementation, and use a single unordered_map instead of two. We count plus one for each element of the left iterable, and count minus one for the elements of the right iterable.   template &lt;   typename LhsForwardIterator,   typename RhsForwardIterator,   typename Equal = std::equal_to&lt;typename LhsForwardIterator::value_type&gt;,   typename Hash = std::hash&lt;typename LhsForwardIterator::value_type&gt; &gt; bool is_permutation_hash(   LhsForwardIterator lhs_first, LhsForwardIterator lhs_last,   RhsForwardIterator rhs_first, RhsForwardIterator rhs_last,   Equal equal = Equal(),   Hash hash = Hash()) {   using value_type = typename LhsForwardIterator::value_type;   std::unordered_map&lt;value_type, int, Hash, Equal&gt; frequencies;      for (; lhs_first != lhs_last; ++lhs_first) frequencies[*lhs_first] += 1;   for (; rhs_first != rhs_last; ++rhs_first) frequencies[*rhs_first] -= 1;      return std::all_of(begin(frequencies), end(frequencies),                      [](auto const&amp; p) { return p.second == 0; }); }   This listing is naive in many ways, but has the merit not to require any scrolling. We can improve the solutions in many ways:      Early returning in case the size of both iterable do not match   Reserving the space inside the unordered_map to limit resizes   Aborting the second scan in case the key to decrement is not found   These ideas are implemented in the following Gist GitHub. And there are for sure many more refinements we could do, optimizations as well as cosmetic changes (like using ranges), but this is not the point of this post.   Note: There is also a problem of packaging of the function is_permutation_hash. It takes up to six arguments, which is a first problem. The default arguments are the second problem: both the equal and the hash have to be provided or none should be. Both these problems should be dealt with in production code.   Ordering based implementation   If we have a strict total ordering available on the types we iterate over, the implementation of is_permutation can leverage it to sort both collections and compare them equal afterwards. Here is a naive implementation of such a strategy:   template &lt;   typename LhsForwardIterator,   typename RhsForwardIterator,   typename Less = std::less&lt;typename LhsForwardIterator::value_type&gt; &gt; bool is_permutation_less(   LhsForwardIterator lhs_first, LhsForwardIterator lhs_last,   RhsForwardIterator rhs_first, RhsForwardIterator rhs_last,   Less less = Less()) {   using value_type = typename LhsForwardIterator::value_type;   std::vector&lt;value_type&gt; lhs(lhs_first, lhs_last);   std::vector&lt;value_type&gt; rhs(rhs_first, rhs_last);   if (lhs.size() != rhs.size())     return false;      std::sort(begin(lhs), end(lhs));   std::sort(begin(rhs), end(rhs));   return lhs == rhs; }   Performance improvements   Due do their lower algorithmic complexity, both these alternatives perform quite faster than their std::is_permutation counterpart.   For 50,000 elements, the standard implementation lasts around 1.7 seconds in average on my laptop. Both alternatives are systematically below the 10 milliseconds mark. This is more than 2 order of magnitude faster.   These implementations are naive and could be made much faster: minimal changes to the hash based implementation leads to go down the 5 milliseconds. Further improvements could be reached by using more appropriate data structures. For instance, a hash map implementation based on linear probing would be much more efficient since we do not delete any keys in such use case.   Requirement on types   All the implementations listed above add some additional constraints on the underlying types of the iterables provided to the is_permutation algorithm. The concern is whether these constraints would make sense in the general case.   In this section, I will try to convince you that these constraints are justified in many cases. In particular, I will argue that implementing std::hash should be workable for most types, and as a consequence, that we should be able to rely on its presence in all STL algorithms manipulating value types.   Value types   We can safely assume that the two iterables provided to is_permutation will contain what is usually called value types.   There are plenty of definitions available for value types. John Lakos refers to them as matching some ethereal types. Eric Evans refers to them as objects whose characteristics are derived from their attribute values.   In any case, it would not make much sense to call std::is_permutation on iterables containing something else than value types. For instance, it makes no sense on the two other object categories distinguished by Eric Evans, Entity types and Services.   Regular types   In his quite famous paper Fundamentals of Generic Programming, Stepanov defines the concept of regular type as a type satisfying a set of constraints that makes it suitable for generic programming.   These constraints happens to match pretty closely what we expect from a value type. The following Stack Overflow thread features a great answer from Sean Parent that adds some more constraints after the release of C++11.   Among the list of constraints first listed by Stepanov stands the requirement for a total ordering. Among the additional suggested by Sean Parent stands the requirement for std::hash to be properly defined for the type.   So the constraints required by both our alternative implementations do make some sense for value types. Let us now discuss which of strict total ordering and hash function would make more sense.   Hash is easier to implement   For the simplest use cases, defining a hash function or an operator less on a type are both pretty simple.   The lexicographic comparison works great to define the operator less on std::tuple, struct or class. Hash functions can be implemented in terms of of the hashes of the attributes and the use of boost::hash_combine to combine their result (and again, we can selection the lexicographic ordering for the order of combination).   But there are cases in which defining a strict total ordering gets much harder. For instance, how would you efficiently define the operator less on an unordered_map? The order of the elements of a hash map is unspecified, making the lexicographic comparison unworkable.   Defining a hash function does not require such lexicographic ordering to exist. We can define the hash of a unordered_map by summing the hash values of each pairs stored inside the map (this is in fact what a valid Java implementation does). There are other definitions possible: any associative and commutative function could replace plus.   I have no formal proof to back it up, but I would argue that providing a std::hash function should be workable in every places in with we can define operator== (while operator less is more problematic). For instance, Clojure has no problem providing a hash function by default for all its value types.   Hash complements equal   The other reason why std::hash is easier to add as a type requirement is its absence of meaning. The hash function is only an implementation trick to improve the efficiency of our algorithms. We do not have to bother with its meaning, we only need to make sure it is consistent with operator==.   This is not true for the operator less. Let us consider an example in which this distinction is important. Here is a very naive modelization of a color in RGB encoding:   struct rgb_color {   int m_red;   int m_green;   int m_blue; };   We can easily define the operator== such that two colours are equal if all their RGB components are equal. This definition makes sense in the context of the domain.   We can as easily define std::hash, by combining the hash of the red, green and blue integers. This definition does not have to make sense in the domain, it is merely an implementation detail.   We can also define the ordering rather mechanically, using std::tie:   bool operator&lt; (rgb_color const&amp; lhs, rgb_color const&amp; rhs) {   auto as_tuple = [](rgb_color const&amp; c) {     return std::tie(c.m_red, c.m_green, c.m_blue);   };   return as_tuple(lhs) &lt; as_tuple(rhs); }   But it does not make much sense to define such ordering. Is there really a notion of order between colours? Why this one in particular?   Sean Parent advices in this same Stack Overflow answer to reserve the operator less for when there is a natural ordering. And there seems to be no natural ordering in this context.   Value composition   Composition allows decomposition. There is no point is breaking down a problem into pieces if we cannot plug back the pieces together. Compositions is therefore one of the most (if not the most) important characteristic to seek in everyday software.   This applies to value types. We get tremendous leverage if we can aggregate values into values and preserve their value-like concepts transparently (such as equality and hash) along the the way as we compose them.   For instance, if an unordered_map (or vector) of values is a value, we can transparently replace a std::string by an arbitrary collection of std::string inside an STL algorithm (or container) leveraging hash, and get the job done with the same efficiency.   Since the std::hash could be defined mechanically in most case, there is therefore a great value in supporting it for our most common ways to aggregate values (tuples, vectors and maps for instance) and to provide helpers to help us define it on our own types (via std::tie for instance).   Dear std::hash needs some love   The STL does not seem to love std::hash that much. For reasons that I am unaware of, this lack of affection seems to be all over the Standard Template Library.   Proofs of un-affection   For instance, std::tuple, std::vector and std::map define both equality and equivalence relations automatically. But none of them define std::hash, while they could rather easily.   The same goes for std::unordered_map: it defines equality (but not operator less, probably for the reasons we listed above) but does not provide the associated specialization for std::hash.   Standard Tuple   This lack of definition for std::hash is especially troubling in the context of std::tuple: defining std::hash on std::tuple would automatically offer a helper function to define it on our user defined types.   Using std::tie could get us an implementation for our custom data types very succinctly. For our rgb_color, it could look like this:   size_t operator()(rgb_color const&amp; c) const {   auto as_tuple = std::tie(c.m_red, c.m_green, c.m_blue);   return std::hash&lt;decltype(as_tuple)&gt;()(as_tuple); }   Why not fix it?   For all the reasons listed above and in the previous section (composition), I strongly believe that std::hash should be defined for the following types:      std::tuple: this is the most important one for it is an enabler   Sequential containers: for consistency with std::string (also a container)   Associative containers: very useful since less is hard to define on hash maps   Adding these would make for a good addition to the features of C++ (*) and would probably greatly help a lot of C++ developers in their daily job.   (*) I did not go through all the standard to check if this was already proposed for C++20 (or already integrated in C++17). Maybe it already is.   Back to std::is_permutation   Let us assume for this section that the arguments above convinced you, and you are ready to believe that std::hash should be a given for value types. Let us discuss what it would imply for std::is_permutation.   Use hash in std::is_permutation   If std::hash becomes available for most of our types, we could improve std::is_permutation such that:      It makes it use std::hash if available, making it O(N) W.H.P.   It falls back to its current implementation otherwise   What about memory usage?   The algorithms based on std::hash or operator less do need additional memory. Although we are most likely to suffer more from the quadratic complexity than from this O(N) space requirement, this drawback cannot just be ignored.   It could very well be a problem in some use cases in which memory is rare. The STL could provide a specific quadratic implementation for such cases, that could be named std::inplace_is_permutation to be explicit.   Combining alternatives   The last CppChat asked whether we should try to always automatically select the best implementation, or whether the user should have a way to select. We could make so that both approaches can be combined.   For instance, std::is_permutation could be selecting its implementation based on some concepts or constexpr if. This selection process could take the form of a simple redirection to algorithms (with distinct names) that would implement the different policies (such as std::inplace_is_permutation).   The rationale is that the default selection policy (with priorities inside the selection in case several branches are available) might not be the best choice for everyone. Providing different functions allows the user to make a conscious choice if he desires to do so.   Conclusion and wishes for the STL   We discussed two different implementations that offers much better algorithmic complexity than the standard implement of std::is_permutation.   We choose the hash based implementation, based on the argument that it would make sense for most for all value types to support std::hash. Based on this assumption, we saw how we could improve std::is_permutation to take advantage of this.   To summarise, here is a list of changes in the STL, that I think would make a lot of sense and improve the life of C++ developers in the process:      Add a std::hash specialization for std::tuple   Add a std::hash specialization for all sequential containers   Add a std::hash specialization for all associative containers   Fix std::is_permutation to take advantage of std::hash if available   Provide a std::inplace_is_permutation as alternative implementation   In particular, I think that the first proposal, the specialization of std::hash for std::tuple, would be both feasible and really useful. It would help developers define their own std::hash for custom data types.  ","categories": ["modern-cpp"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2017/04/10/std-permuration-complexity-2.html",
        "teaser": null
      },{
        "title": "Lost in std::is_permutation complexity (reddit answer)",
        "excerpt":"In this short post, I would like to answer an interesting comment that was added in the Reddit thread asssociated to my lost in permutation complexity previous post. Answering this comment on Reddit directly would make for a big wall of text, hence this post, which aims at providing a comprehensive answe   Context   The original post described a necessary and sufficient property to test that an unstable sort was doing its job correctly.   This property is based on the fact that an unstable sort is a permutation of a collection such that the resulting collection is sorted after the permutation. We named this property check_sort_property and translated it into code:   template&lt;typename InputIterable, typename ResultIterable, typename Less&gt; bool check_sort_property(InputIterable const&amp; input,                          ResultIterable const&amp; result,                          Less less) {   return     std::is_permutation(begin(input), end(input), begin(result), end(result))     &amp;&amp; std::is_sorted(begin(result), end(result), less); }  template&lt;typename InputIterable, typename ResultIterable&gt; bool check_sort_property(InputIterable const&amp; input,                          ResultIterable const&amp; result) {   auto less = std::less&lt;typename InputIterable::value_type&gt;();   return check_sort_property(input, result, less); }   We used this property inside a Property Based Test which consist in four distinct phases:      Generating random inputs (random vectors of pair of ints in our case)   Call our unstable sort routine on each of these vectors   Check that the property holds on the output of the unstable sort   Shrinking the failing random input to find a simpler counter example   To summarize, the goal of the check_sort_property property is to describe succinctly and precisely a condition that makes such a test pass or fail, knowing that the test is performed on random inputs.   The Reddit comment   The check_sort_property property got some attention. One such comment mentioned that the usage of std::is_permutation was not justified here, and that there were another ways to unit test the unstable sort:      […] the given problem is unit testing an unstable sorting algorithm. Compare the output with your expected result, and check that corresponding items in output and expected are equal (or neither less than the other). Using is_permutation to compare two sorted ranges is misguided.    The comment (as I understand it) arguments that it would be much easier to test the unstable sort by comparing the output of the unstable sort against an expected result, for instance, using GTEST:   std::vector&lt;std::tuple&lt;int, int&gt;&gt; inputs = ...; std::vector&lt;std::tuple&lt;int, int&gt;&gt; expected = ...;  custom_sort(begin(inputs), end(inputs)); ASSERT_EQ(expected, inputs);   We will now go through some rationales that justify the usage of properties (such as check_sort_property) and property based testing to verify the correctness of an algorithm, instead of comparing the result of a function call with an expected output as we would do with GTEST. I believe these arguments do apply for both property based tests and example based tests.   Missing in action: Expected   There are cases in which we cannot test an algorithm against a fixed expected result. This happens when the expected result is not easy to craft.   Random inputs   In most cases, it is very difficult to check our input against expected results when the inputs are random. Generating random inputs is precisely what we do in the context of property based testing as this allow us to test much more and potentially find edges cases we would not have thought about.   In some cases, despite random inputs, it is however still possible to get the exact expected result. For instance, if we were implementing a stable sort, we have a reference algorithm to test against.   In our case however, there is no algorithm that would match exactly what we want to test.   Big inputs   One second use case for properties in when the inputs are huge. In such cases, the “expected” result is not easily accessible or downright impactical. For instance, we could try to test our unstable sort on a vector of thousands or more elements.   An hand-crafted expected result (matching a hand-crafted input) will be very awkward to create and expensive to maintain. Similarly, understanding the output of a failed test in such cases is hard and it is much easier to understand the output of a property (if this property correspond to a nice abstraction such as “not a valid permutation”).   Tradional unit tests on big inputs becomes so tedious that most developers will just copy-paste the result of their algorithm and set it as “expected” output. This somehow defeats the purpose of testing in the first place.   And when code evolves, these “unit tests” on big inputs often transform into “regression tests”. These tests do not ensure correctness as much as they ensure that nothing changes. When software changes (as it invariably does), these tests will become red in non-meaninful ways (and either be commented, ignored, or corrected by copy pasting the new results as expected results).   Non deterministic algorithms   One last reason, and not the least, for avoiding hardcoded expected results to our unit tests is that we sometimes have to deal with non deterministic algorithms.   We could for instance envision a distributed sorted algorithm, which, for efficiency reason, would be unstable and non-deterministic. Based on how fast each of the workers process their respective tasks, the output would be correctly sorted but elements in the same equivalence class could change their respective orders.   The dangers of over-testing   Property based testing allows to test predicates, while hardcoded expected results typically test much more than those properties. They tend to test all the implementations details of the algorithm (in the case of our stable sort, they would test the “exact unstable way” in which the sorting algorithm is unstable)   As a rule of thumb, we should avoid testing too much of a function, and in particular, we should avoid to expand the tests past the contract of the function. Why?   Freedom to improve   The purpose of implementing an unstable sort instead of a stable sort is to get a degree of freedom on the output of the algorithm. This degree of freedom can be leveraged to implement a faster algorithm.   This freedom extends in the time axis too: it should be fine to get different results for our stable sort across releases. If we discover a faster implementation in the future, we want to be in position to implement it. This might change the relative ordering of equivalent elements: this is fine.   Improving developers productivity   If instead of relying on a property to check the correctness of our unstable sort, our unit tests matched against whole expected output, improvement to our implementation would be made more difficult.   Improving the algorithm could make such tests fail. This fail status could be because we broke the algorithm. But it could also be because the test relied on the implementation details of the algorithm (the specific instability).   The developer will have to check the result to make sure the failed status represents a real issue or if the test should be adapted. This manual work could be avoided by making sure our unit tests test the interface, not the implementation details.   For that reason, testing the output of an algorithm using a property might have a big positive impact on a software flexibility and developers productivity. Tests that only test the contract of a function will only fail if the function gets broken.   Note: This argument for testing the contract and not the implementation is in contradiction with some mechanical applications of Test-driven development. The inflexibility of locking everything in place by testing implementation details will likely hurt productivity.   Conclusion   I hope this post answers the valid concerns that were raised inside the Reddit post and did clarify why we went for the implementation of a property making use of std::is_permutation and std::is_sorted to verify the correctness of our unstable sort.   In this process, I hope I did good justice to property based testing and why it is useful and sometimes preferable to example based testing (testing against fixed inputs with fixed expected outputs), in particular to test the contract of a function and avoid testing too much of its implementation details.  ","categories": ["modern-cpp"],
        "tags": ["Functional-Programming","C++"],
        "url": "/blog/2017/04/14/std-permuration-complexity-3.html",
        "teaser": null
      },{
        "title": "10 things Idris improved over Haskell",
        "excerpt":"The 1.0.0 of Idris has been released just a few months back, just enough to start trying out the language and some of the possibilities dependent typing offers.   But this post is not about dependent typing. There is already a really good book that came out this year, named Type Driven Development with Idris, exploring the benefits (and trade-offs) of dependent typing. I highly recommend you to read it.   Instead, this post describes some of the pleasant surprises you get trying out Idris, coming from the Haskell world. These pleasant surprises have nothing to do with the dependent typing features. They are simple yet impacting modifications, which improve the developer experience substantially.   I listed my top 10 in the hope they will convince you to give a try at Idris.   1) Idris strings are not lists   It does not seem like much, but Haskell Strings are such a pain to deal with, that this improvement got the first place.   Haskell String are lists of characters. This big mistake in terms of efficiency is corrected by two very good packages: Data.Text and Data.ByteString. Nevertheless, this is still a source of pain and accidental complexity:      Newcomers to Haskell almost always face the inefficiency of Strings   Strings are not first class, and forces use the Overloaded Strings extension   The code gets obscured by successive by pack and unpack calls   Idris learned from the mistakes of Haskell and made Strings first class. You can call pack and unpack strings to go back an forth to a List Char representation. This is illustrated by this simplistic implementation of the caesar cipher algorithm:   caesar_cipher : Int -&gt; String -&gt; String caesar_cipher shift input =   let cipher = chr . (+ shift) . ord   in pack $ map cipher (unpack input)  caesar_cipher 1 \"abc\" =&gt; \"bcd\"  caesar_cipher 0 \"abc\" =&gt; \"abc\"   2) Overloading without Type Classes   Overloading of function has also been a subject of numerous complains in the Haskell community. Of course, we can workaround the issue by using Type Classes, but this has some drawbacks as well.   Idris learned from these complains as well, and offers a kind of overloading. You can import the same name from different modules and Idris will not care, as long as it can deduce which one to use.   Even better, Idris introduce the notion of namespace, that we can use inside a module to introduce overloads. For instance, we can create a plus operator that works for both scalars and lists in the same module.   infixr 5 +.  namespace Scalar   (+.) : Int -&gt; Int -&gt; Int   x +. y = x + y  namespace Vector   (+.) : List Int -&gt; List Int -&gt; List Int   xs +. ys = zipWith (+) xs ys   As long as Idris can deduce which overload to use, the developer does not have to prefix the symbol with the namespace:   3 +. 5 =&gt; 8 : Int  [1, 2, 3] +. [4, 5] =&gt; [5, 7] : List Int   This is a very nice improvement over Haskell rules that forbid any kind of overloading, and has nice benefits on the code:      It improves composability of software (by limiting conflicts of names)   It avoids using awkward operators to avoid ones used by other libraries   It remains safe and clear, by supporting explicit namespace prefix   3) Record fields are namespaced   The notion of namespace of Idris really shines when it comes to records. The fields of a record live in the namespace of their respective record. The net effect is that they do not collide with the names of the other records as they do in Haskell.   So we can have several records with the same field name. For instance, we define below an Account and Customer record, each having an address field:   record Account where   constructor MkAccount   accound_id : String   address : String  record Customer where   constructor MkCustomer   name : String   address : String   account : Account   As for the overloading rules and namespace, Idris will try to infer which function is being referred to when using the name address. Most often, the developer does not have to provide any hint.   Here is an example of function that uses both the customer address and account address to check if they both match:   custom_billing_account : Customer -&gt; Bool custom_billing_account customer =   address customer /= address (account customer)   This type-checks correctly. In case of ambiguous calls, you can always add the namespace as prefix to help Idris figuring your intent:   custom_billing_account : Customer -&gt; Bool custom_billing_account customer =   Customer.address customer /= Account.address (account customer)   4) Record update and access syntax   Updating values in nested record does come at the cost of verbosity in Haskell. There are packages that help navigating data structure, such as lenses, but a lot of Haskell users recognise it as a pretty big dependency.   Idris offers a lighter update syntax for the fields of nested records. We can update the address of the account of a customer that way:   update_billing_address : Customer -&gt; String -&gt; Customer update_billing_address customer address =   record { account-&gt;address = address } customer   Idris also offers the possibility to apply a function over a field in a nested records. For instance, we can complete (by concatenation) the address of the account of the customer with $=:   concat_billing_address : Customer -&gt; String -&gt; Customer concat_billing_address customer complement =   record { account-&gt;address $= (++ complement) } customer   We can try both our previous function in the REPL to convince ourselves that they work properly (and they do):   john : Customer john = MkCustomer \"John\" \"NYC\" (MkAccount \"123\" \"NYC\")  update_billing_address john \" LND\" =&gt; MkCustomer \"John\" \"NYC\" (MkAccount \"123\" \"LND\") : Customer  concat_billing_address john \" LND\" =&gt; MkCustomer \"John\" \"NYC\" (MkAccount \"123\" \"NYC LND\") : Customer   This does not replace the need for lenses (which are much more general). But it is nice to count of some basic support in core Idris when we do not need that much power.   5) Monad and Functor got fixed   The Haskell Monad return is absent of Idris, and so is the fail method, which most Haskell developers recognise as being a design mistake.   In Idris, Monad extends the Applicative (as it does now in Haskell, but did not for quite a long time) and so pure makes sure that return is not needed. Since the naming was conflicting with the return statement of many programming languages, this is one less distinction to explain to newcomers to Idris when compared to Haskell.   You can also notice the presence of join in the interface of the Monad, allowing to define whichever of bind or join is more intuitive depending on the Monad instance:   Idris&gt; :doc Monad Interface Monad  Parameters:     m  Constraints:     Applicative m  Methods:     (&gt;&gt;=) : Monad m =&gt; m a -&gt; (a -&gt; m b) -&gt; m b     join : Monad m =&gt; m (m a) -&gt; m a   Looking at the Functor type class, fmap is renamed map in Idris. This also improves over Haskell, by avoiding the awkward explanation to newcomers to Haskell of why map is in fact named fmap for legacy reasons:   Idris&gt; :t map map : Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b   6) Laziness is opt-in, not opt-out   There are plenty of good reasons for laziness, there is no denying it. Reading the amazing Why Functional Programming matters shows how much it helps modularising and decoupling our software, by allowing the separation of processes producing data from the one consuming it.   But there are plenty of drawbacks to laziness as well. Some are technical (space leaks) and some are psychological (non strict evaluation is not intuitive when coming from other languages).   A bit like Clojure and other FP languages did before, Idris embraces opt-in laziness, with a strict evaluation by default. Streams are the lazy equivalent of Lists and the language features both. You can notice the different pretty easily, when playing with infinite and finite ranges:   Idris&gt; :t [1 .. 10] enumFromTo 1 10 : List Integer  Idris&gt; :t [1 ..] enumFrom 1 : Stream Integer   7) A smaller Num class   For all of those who likes to play with DSL in Haskell, the fact that the Haskell Num class is split into smaller bits in Idris is a small but nevertheless enjoyable improvement:   Idris&gt; :doc Num Interface Num     The Num interface defines basic numerical arithmetic.  Parameters:     ty  Methods:     (+) : Num ty =&gt; ty -&gt; ty -&gt; ty     (*) : Num ty =&gt; ty -&gt; ty -&gt; ty     fromInteger : Num ty =&gt; Integer -&gt; ty  Child interfaces:     Integral ty     Fractional ty     Neg ty   The Haskell version often leads to dummy implementations of the negate, abs or signum methods. This should not occur anymore in the Idris version of the Num class.   8) The Cast type class   Idris removed the Read type class and replaces it with the more general Cast type class. The Read type class allowed to parse a String into a type a, effectively a transformation from a String to any other type. The Cast class is parameterized on the input type as well, allowing to transform between any two types implementing the type class.   Idris&gt; :doc Cast Interface Cast     Interface for transforming an instance of a data type to another type.  Parameters:     from, to  Methods:     cast : Cast from to =&gt; (orig : from) -&gt; to   We can read a string into an integer like follows (you can note that reading an invalid string returns a default value instead of throwing an exception):   the Int (cast \"abc\") =&gt; 0 : Int  the Int (cast \"123\") =&gt; 123 : Int   The generalisation allows to avoid the multiplication of functions to convert between the numeric types. For instance, we can use it to convert (with losses) a double into an integer value:   the Int (cast 1.1) =&gt; 1.0 : Int   9) Clear separation of evaluation and execution   Let us write a simple function that reads the input from the command line, interprets it as a number, double this number, before printing it on the screen:   double_it : IO () double_it = do   input &lt;- getLine   let n = the Int (cast input)   printLn (n * 2)   If you evaluate a call to this function in the Idris REPL, you will get the following big pile of Abstract Syntax Tree, which correspond to the recipe to execute the IO expression described by double_it:   [*src/InOut&gt; double_it io_bind (io_bind prim_read                  (\\x =&gt;                     io_pure (prim__strRev (with block in Prelude.Interactive.getLine', trimNL (MkFFI C_Types String String)                                                                                               (prim__strRev x)                                                                                               (with block in Prelude.Strings.strM (prim__strRev x)                                                                                                                                   (Decidable.Equality.Bool implementation of Decidable.Equality.DecEq, method decEq (not (intToBool (prim__eqString (prim__strRev x)                                                                                                                                                                                                                                                     \"\")))                                                                                                                                                                                                                     True))))))         (\\input =&gt;            io_bind (prim_write (prim__concat (prim__toStrInt (prim__mulInt (prim__fromStrInt input) 2)) \"\\n\"))                    (\\__bindx =&gt; io_pure ())) : IO ()   To execute the function and not just evaluate it, you need to say so explicitly, by using :exec as prefix to the expression to execute:   [*src/InOut&gt; :exec double_it 123 -- My input 246 -- Output   Why considering this an improvement over Haskell. If you are a Lisp adept, you can but appreciate the reification of the IO actions into a proper AST. It may just be personal taste, but I just love it.   10) The Do-notation without Monads   I kept the best part of Idris for the last. Before of its support for overloading, Idris allows the developer to define a bind operator out of the Monad class, and the do notation is based on the sole presence of this operator.   This is truly an awesome idea. It allows the developer to profit from the nice syntax of the do notation, without having to comply to the interface of the Monad bind operator.      It avoids forcing awkward design just to fit the Monad type class requirements   It opens up the notation for numerous types that could not be made proper instance of Functor, Applicative or Monad, because they are not parameterised   It allows to keep the do notation for dependent types, which much rarely conform to the interface of Monad   It also allows us to abuse even more the do notation. More power means more changes to do horrors as well. Here is an example of abuse that shows that we do not even need a parameterized type for the do notation anymore:      It describes a not very useful StringBuilder DSL   Evaluating an expression of this DSL with eval_string yields a String   Defining the bind operator allows us to describe our DSL expression with do   data StringBuilder   = Pure String   | (&gt;&gt;=) StringBuilder (String -&gt; StringBuilder)  eval_string : StringBuilder -&gt; String eval_string (Pure s) = s eval_string (x &gt;&gt;= f) = eval_string (f (eval_string x))   Here is an example of usage of this DSL, in which we create an StringBuilder expression named john, using our beloved and dreaded do notation:   build_john : StringBuilder build_john = do   john &lt;- Pure \"John\"   let john_doe = john ++ \" Doe\" ++ concat (replicate 10 \"!\")   Pure john_doe   Evaluating our StringBuilder expression shows us the AST, and calling eval_string on it interprets it as a String:   [*src/DoNotation&gt; build_john Bind (Pure \"John\") (\\john =&gt; Pure (prim__concat john \" Doe!!!!!!!!!!\")) : StringBuilder  [*src/DoNotation&gt; eval_string build_john \"John Doe!!!!!!!!!!\" : String   Conclusion   Idris offers some pleasant surprises for the Haskell programmers, even without considering the dependent typing support. There are many other pleasant surprises I got, such as the distinction between print and printLn, which is now aligned with putStr and putStrLn, and many others.   These changes mostly show how helpful it is to be able to start all over again from scratch and fixing these pesky mistakes we did at the beginning.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/06/14/idris-improvements.html",
        "teaser": null
      },{
        "title": "Idris dependent typing challenge: Bowling Kata",
        "excerpt":"The 1.0.0 of Idris has been released just a few months back, just enough to start trying out the language and some of the possibilities dependent typing offers.   In this post, we will look at implementing a type safe version of the Bowling Kata in Idris, to see how far we can go with the Idris type system.   The rules   The goal of the original Bowling Kata is to implement a function that allows to compute the rules of the Ten-Pin Bowling game. Reading the problem description, we see it does not include any validity checks:      “We will not check for valid rolls”   “We will not check for correct number of rolls and frames”   “We will not provide scores for intermediate frames”   We will extend this kata by adding the validity checks, and try to implement them at the type level. Our goal will be to make invalid bowling game not representable.   Here are the constraints we will implement, all at the type level:      A roll cannot knock down more than 10 pins.   A frame cannot knock down more than 10 pins.   A valid game contains exactly 10 frames.   There are exactly 2 bonus rolls for a strike, 1 for a spare, and 0 otherwise   Rolling a strike in the first bonus roll gives another 10 pins to roll against   Outside of a strike, a roll cannot knock down more than 9 pins   Let’s do this as a challenge, to see where it leads us. We will discuss at the end whether or not going that far was a good idea.   Describing a valid frame   A game of Ten-Pin Bowling rules consists of 10 frames. At each frame, a player attempt to knock down the 10 pins.      Should he succeeds in 1 roll, he gets a strike.   Should he succeeds in 2 rolls, he gets a spare.   In this section, we will try to capture the nature of a frame in terms of types. Our goal will be to make an invalid frame not representable   One roll or two rolls   The first distinction we have is that a frame consists either of 1 roll (for a strike) or 2 rolls in any other case. We will represent this using a sum type.   data Frame : Type where   TwoRolls : (x, y : Nat) -&gt; Frame   Strike : Frame    roll : (x, y: Nat) -&gt; Frame roll x y = TwoRolls x y  strike : Frame strike = Strike      We use Nat to make sure the pins knocked down are positive   We added smart constructors to decoupled the instantiation (potentially exporting the smart constructors and not the data constructors)   We add the notion of a spare though a predicate on our frame:   PinCount : Nat PinCount = 10  isSpare : Frame -&gt; Bool isSpare (TwoRolls x y) = x + y == PinCount isSpare _ = False   This implementation is however not type safe: any positive number will do. We might create a frame in which a player knocked 25 pins in one single roll.   Important properties involve multiple fields   To make sure we can only construct valid TwoRolls frames, we need a pre-condition that relates both numbers given to the data constructor.   Constraining each number individually is not enough. The best we could do is making sure that both numbers do not exceed 9 (included) individually. But it would not prevent the creation of frame with two rolls knocking 9 pins each.   In general, the most interesting properties involve several arguments (or fields). Focusing on single value type-safety only checks the most trivial properties, for sometimes only a deceiving illusion of safety (yet this is the focus of most type systems).   Proving a frame is valid   To make sure we can only create valid Bowling frame, we will need to express a property on both the rolls of the TwoRolls type constructor:   data Frame : Type where   TwoRolls : (x, y : Nat) -&gt; { auto prf : ValidFrame x y } -&gt; Frame   Strike : Frame   This syntax is asking Idris to find an implicit proof (the auto prf syntax where prf is the variable name of the proof), that both our numbers x and y obey the property ValidFrame (described below).   A ValidFrame is such that both rolls are below 10 (excluded, or else it would be a strike) pins knocked down, and that the sum of pins knocked down is below 10 (included, to take into account the possibility for spares).   Propositions as types   Prooving something in the sense of Idris, is being able to create an instance of a given type (if you are unclear why being able to instantiate a type is proving the proposition defined by the type, you should watch “Propositions as Types” by Philip Wadler).   In Idris, the type that represents “lower than” is LT and the type that represents “lower than or equal” is LTE. So a TwoRolls x y is valid if we can instantiate the following types:      LT x 10: the first roll is strictly lower than 10   LT y 10: the second roll is strictly lower than 10   LTE (x + y) 10: the sum of both rolls is lower or equal than 10   We need to express the conjunction of all these propositions. To do so, we need to prove that we can construct all the types that represent these propositions.   A tuple represents a conjunction: to instantiate a tuple, we need to instantiate all the types it contains. We can therefore express our proof that a frame is valid as follows:   PinCount : Nat PinCount = 10  ValidFrame : (x, y: Nat) -&gt; Type ValidFrame x y = (x + y `LTE` PinCount, x `LT` PinCount, y `LT` PinCount)   Now, any attempt at constructing an invalid Bowling frame should be rejected by the type system. Here are some example in the REPL:   roll 10 0 -- COMPILE ERROR: \"Can't find a value of type (LTE 10 10, LTE 11 10, LTE 1 10)\"  roll 9 9 -- COMPILE ERROR: \"Can't find a value of type (LTE 18 10, LTE 10 10, LTE 10 10)\"  roll 0 0 -- Fine =&gt; TwoRolls 0 0 : Frame  roll 5 5 -- Fine =&gt; TwoRolls 5 5 : Frame   Describing a valid game   A game of Ten-Pin Bowling rules consists of 10 frames, with the last frame being somewhat special. In case the last frame of the game is a spare, the player gets one additional roll, if it is a strike, the layer gets two additional rolls.   Subtelties of the strike bonus   In the case of a strike, there is some additional complexity. In case the first bonus roll is a strike, we get another 10 pins to roll against. In case your first bonus roll is not a strike, the second roll only has the remaining available pins to knock down.   Some examples of valid and invalid bonus rolls following a strike at the last frame:   Valid: [9, 1] Invalid: [9, 2]  Valid: [2, 8] Invalid: [2, 9]  Valid: [10, 8] Invalid: [8, 10]   This shows that encoding the bonus rolls as a vector of positive integer bounded by 10 (the type Fin 11 in Idris) will not cut it. We need to do a better than that.   Specifying the bonus   We will start by writing a function that returns the number of bonus rolls given the last frame. It returns 2 for a strike, 1 for a spare and 0 otherwise:   bonusRolls : Frame -&gt; Nat bonusRolls Strike = 2 bonusRolls rolls = if isSpare rolls then 1 else 0   We can use this function to compute type of the vector of bonus rolls. BonusRollType returns the type of the bonus roll vector with the appropriate size:   BonusRollType : Frame -&gt; Type BonusRollType f = Vect (bonusRolls f) (Fin (S PinCount))      The Vect is a list parametized by its length: Vect 2 Int contains exactly 2 integers   Fin (S PinCount) represent positive integers bounded by PinCount (10) included   Used on the last frame of a bowling game, this function will compute the type of the vector of bonus rolls. This will make sure the number of bonus rolls will match the rules of the bowling game.   But this is not be enough. We need to forbid sequences such as 9 followed by 2. We will therefore need to add some preconditions.   Properties on the bonus   The bonus rolls of a strike are valid if either the sum of the rolls is lesser or equal than 10, or if the first roll is a 10. We can express this property in types:   ValidBonuses : Vect n (Fin (S PinCount)) -&gt; Type ValidBonuses {n = Z}      bonuses = LTE 0 0     -- 1) No bonuses, no constraints ValidBonuses {n = (S _)}  bonuses =             -- 2) In case of bonuses:   Either                                        -- Either:     (finToNat (head bonuses) = PinCount)        -- * The first roll is 10     (sum (map finToNat bonuses) `LTE` PinCount) -- * Or the sum is less than 10      Either express a disjunction of proposition: you can construct a Either a b instance if you can instantiate either a a or a b   finToNat allows to convert from a bounded positive integer Fin Bound to a non bounded positive integer Nat (LTE only works on Nat)   The conversions between Fin (bounded natural numbers) and Nat (unbounded natural numbers) make this this quite dense. Another interesting design would have been to get rid of Fin and encode the bounds inside ValidBonuses.   Specifying the game   It is now time to wrap up our specification for a valid bowling game.      A game is made of 10 exactly frames. We can enforce this using a Vect 10 Frame   We use BonusRollType to compute the bonus roll vector type from the last frame   The ValidBonuses precondition makes sure the strike bonus rolls are valid   FrameCount : Nat FrameCount = 10  data BowlingGame : Type where   MkBowlingGame :                              -- Create a bowling game from:     (frames: Vect FrameCount Frame)            -- A vector of 10 frames     -&gt; (bonuses : BonusRollType (last frames)) -- The bonus rolls of the last frame     -&gt; {auto prf: ValidBonuses bonuses}        -- The bonus rolls precondition     -&gt; BowlingGame   We used dependent types extensively here. We see that the BowlingGame type depends heavily on its content.   Checking our type checking   Time to make sure we did a fine work. We will fire up a REPL and try to instantiate some valid and invalid games:   MkBowlingGame (replicate 10 strike) [10, 10] -- OK: The perfect game MkBowlingGame (replicate 10 strike) [10, 1] -- OK: Almost perfect game MkBowlingGame (replicate 10 strike) [9, 1] -- OK: Too bad for the last rolls  MkBowlingGame (replicate 10 strike) [10] -- FAIL: Missing a last bonus roll (there should be 2)  MkBowlingGame (replicate 10 strike) [9, 2] -- FAIL: Can't find a value of type Either (9 = 10) (LTE 11 10)  MkBowlingGame (replicate 10 (roll 5 5)) [10] -- OK: only spares MkBowlingGame (replicate 10 (roll 5 5)) [9] -- OK: only spares  MkBowlingGame (replicate 10 (roll 5 5)) [10, 10] -- FAIL: Only spares but two bonus rolls instead of 1   Note that testing that invalid instances are rejected is interesting, but it is even more important to test that valid instances pass the type checking. We would not want to forbid valid use cases.   Implementating the scoring   Pretty interestingly, the code to implement the scoring of a Bowling game (which is the focus of the original Bowling Kata) ends up being shorter than the code needed to implement the rigorous type safety.   View: a series of rolls   To solve the puzzle elegantly, we need two views on our data: one as a sequence of frames and one as a sequence of rolls. The latter will be used when dealing with strikes and spares.   We therefore need a function gameRolls to transform our game to a list of rolls:   knockedPins : Frame -&gt; List Nat knockedPins (TwoRolls x y) = [x, y] knockedPins Strike = [PinCount]  gameRolls : BowlingGame -&gt; List Nat gameRolls (MkBowlingGame frames bonuses) =   concatMap knockedPins frames ++ toList (map finToNat bonuses)   Aside from being helpful for the computation of the score, this function is useful in a more general context. We illustrate how it behaves below:   gameRolls $ MkBowlingGame (replicate 10 (roll 5 5)) [9] [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 9] : List Nat   Scoring a game   Implementing the score function makes use of both our frames-based view and our rolls-based view. We recur on both these view at the same time, dropping one frame and one or two rolls at each iteration.   score' : Nat -&gt; Vect n Frame -&gt; List Nat -&gt; Nat score' current [] _ = current score' current (f :: fs) rolls =   let frameRollNb = length (knockedPins f)      -- Nb of rolls in the frame       scoreRollNb = frameRollNb + bonusRolls f  -- Nb of rolls to sum       frameScore = sum (take scoreRollNb rolls) -- Sum of the rolls to sum   in score'                       -- Recur:        (current + frameScore)     -- Add the frame score to the current score        fs                         -- Advance the the next frame        (drop frameRollNb rolls)   -- Advance to the next rolls  score : BowlingGame -&gt; Nat score game@(MkBowlingGame frames bonus) = score' 0 frames (gameRolls game)   We can check that our code works correctly by implementing a series of unit tests. I only listed two of them below:   should_be_300_for_perfect_game : IO () should_be_300_for_perfect_game =   assertEq 300 $ score $ MkBowlingGame (replicate 10 strike) [10, 10]  should_be_150_for_5_pins_only_game : IO () should_be_150_for_5_pins_only_game =   assertEq 150 $ score $ MkBowlingGame (replicate 10 (roll 5 5)) [5]   Note that we did not have to perform any defensive checks in our scoring function. Our type-safety has already got rid of any kind of badly formed inputs. The code instead focuses on the nominal case.   Conclusion   Using Idris, we managed to build a type-safe variant of the Bowling Kata, making sure than invalid Bowling games are not representable. The full code is available in this GitHub repo, in the file Bowling.idr.   Now let’s take a step back.   The good parts   Idris allows to check quite complex properties at the type level. These properties can capture quite a lot of our domain invariants.   Where most type systems are limited to single argument or field validity, Idris is not. We can use this ability to ensure lots of invariants, and not only the most trivial ones (as type systems such as the one of Java do).   Also, since Idris blurs the limit between the type system and run-time values, our work at the type level can often be reused in our run-time code. For instance, bonusRolls is used to both compute the score and the type of the vector holding the bonus rolls.   The price to pay   First, we have to pay long compilation times. The simple module here takes several seconds to compile on my laptop. And I could observe things getter slower as I added more properties on the bowling game types.   The second issue is the cost of dependent typing in terms of flexibility. The scoring is so coupled to the notion of valid game that we cannot use it to compute the intermediary scores anymore (the bowling kata does not deal with intermediary score either).   Finally, and for all cases in which the inputs are coming from the real world (like a bowling game inputs), making invalid states not representables does not dispense us to implement the run-time checks of validity of our inputs (*). Dependent types however make sure that these checks take place.   (*) These run-times checks will differ from the usual run-time checks in that they will have to provide a proof. A simple boolean will not do.   Strong typing is not for everything   Due to the additional efforts needed and the potential inflexibility implied by that much type safety, a valid question is whether or not dependent typing is worth it.   Richard Eisenberg arguments about reserving them to the core business logic in this Haskell Cast. It looks like a real good advice: dependent types are not for everything, abusing them certainly can lead to code that is unnecessarily rigid and more complex.   The good news is that Idris does not forces us to dependently type everything. Ultimately, this is our responsibility to decide on the appropriate use of those features.   Consider alternatives   Last but not least, we should also note that there are other ways than dependent typing to get very strong type safety, some of these being less expensive. For instance, we could use phantom types to force a workflow in which we would validate our Bowling Game before scoring it.   Overall, data-flow typed-enforced designs seem more appropriate for cases like the bowling game: we know that the inputs will come from the real world, we know they will require validation, so having a design that matches the real world acquisition process seems much more robust.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/07/01/idris-bowling-kata.html",
        "teaser": null
      },{
        "title": "Hexagonal Architecture and Free Monad: Two related design patterns?",
        "excerpt":"You do not need to understand Monads to follow this post. This is not a Monad tutorial either, but it might help you getting some intuition on what is a Monad. Some knowledge of Haskell and C++ might help but are not pre-requisite.   There is a lot of talk about Domain Driven Design lately. This approach of design advocates that most of the software complexity we face today is due to our software not being aligned with the domain it attempts to model.   If the software does not properly decompose the problem it was built to solve, or solves another problem, or simply does not speak the language of the problem, chances are high that the customer will not be happy with it.   Domain Driven Design also comes with some design patterns (often referred as tactical pattern in DDD). One of those patterns that is often associated to Domain Driven Design is the Hexagonal Architecture.   In today’s post, we will explore this architecture through an example, describe it, and relate it to Free Monads, a well-known and pretty popular pattern in typed functional programming languages to build Domain Specific Languages.   Introduction &amp; motivation   Paris developers got lucky lately. The capital of France hosted a bunch of high quality presentations featuring the Hexagonal Architecture:      The Alistair in the Hexagon meetup with Alistair Cockburn   A full Afternoon dedicated to DDD and refactoring toward DDD.   These presentation were great. Technically, they largely focused on delivering design patterns for OOP languages. Some attendees got the feeling that paradigms such as FP could not really offer the same domain modeling as OOP.   This is obviously not true. On the contrary, most Functional Programming languages are great at modelling domain specific problems by supporting the definition of embedded Domain Specific Languages (DSL) quite naturally.   But it is true is that different paradigms lead to different solutions. Languages such as Haskell are not that good at applying patterns from the OOP world. Instead, they have patterns of their own: such as the Free Monad in place of the Hexagonal Architecture.   In today’s post, we will explore the relations and differences between the Free Monad and the Hexagonal Architecture.   Motivating example   Any proper discussion about design needs a good example as illustration. We will use the same example as the Domain Driven Design afternoon presentation and build the domain logic of a train reservation application.   Business rules   The goal is to implement the domain of train reservation. We should offer an API to reserve a given number of seats at a given date.   The rules of the reservation of a train are the following:      We cannot reserve seats in a train if it bumps up the occupancy over 70%   All the reserved seats should be in the same coach (we cannot separate families)   Preferably, we should avoid bumping the occupancy of a coach over 80%   External services   Our application is only responsible for providing this business logic. Some other services already implement the booking and browsing of the trains:      One service offers the capability to search for trains by date, and access the typology of the train (available seats, by coaches)   One service offers the capability to book a bunch of seats in a coach in a given train. This service might deny the request (due to race conditions)   Our application will have to integrate to an monitoring infrastructure. We will simulate this by adding an external logging service.   Architecture constraints   We want our application to separate the domain logic from the technicalities of the communication with the external services and the infrastructure:      The business logic cannot depend on the real services   A wrapping layer should take care of the plumbing to the real services   These rules are deliberately built to be in line with the tenets of Domain Driven Design and the Hexagonal Architecture, the topic of the next section.   Hexagonal Architecture   In this section, we will introduce the basics of the Hexagonal Architecture. We will keep it minimal and the curious reader is encouraged to look at the original article and additional resources.   Dual goals   The Hexagonal Architecture has two connected goals.   From a DDD perspective, it aims at structuring the code such that it offers a shell in which the code speaks the language of the domain and is not immediately bothered by technicalities. These technical aspects are kept separated.   From a evolution perspective, it aims at structuring the code such that it makes it safe and easy to switch technology stacks by minimising the amount of rework of the code that implements the business logic.   Principles   The core business domain code is kept isolated from the implementation of the service on a particular technology stack.   The domain code communicates with the real world by using ports (interfaces in OOP). All the services on which the core business domain depends are abstracted by these ports, named after the capabilities they offer from the domain point of view.   There are no layers below or above the Hexagon. Instead, there is a layer around the hexagon consisting in adapters and code plugging these adapters to the ports the hexagon defines (dependency injection).   Applying the Hexagonal Architecture   We will now illustrate how the Hexagonal Architecture translates in terms of code to implement our service. To keep things short, we will only focus on the architecture of the application. The full code will be provided at the end.   Service providers   As described in the previous section, the core domain depends on service providers. We abstract each of them behind dedicated interfaces, named after the capability they offer from the point of view of the core domain.   We name these interfaces using the naming scheme advocated by Thomas Pierrain: we will use the I of the interface name to form a sentence that explains the capability offered by the service.      IReserveTrains allows to reserve a set of seats in a coach of a given train.   ISearchTrains allows to:            Retrieve all the trains departing around a provided date-time       Get the typology of a given train (coaches and seats available)           Here is how it would translate in OOP (using C++):   struct ISearchTrains : Interface&lt;ISearchTrains&gt; {     virtual std::vector&lt;TrainId&gt; trains_around(DateTime const&amp;) = 0;     virtual TrainTypology get_typology(TrainId const&amp;) = 0; };  struct IReserveTrains : Interface&lt;IReserveTrains&gt; {     virtual std::optional&lt;ConfirmedReservation&gt; reserve(ReservationAttempt const&amp;) = 0; };   We can abstract the logging service the exact same way, by providing an interface that models this capability:   struct ILog : Interface&lt;ILog&gt; {     virtual void log(std::string const&amp;) = 0; };   Service provided (API)   As described in the previous section, our hexagon also offers a port for the service the core domain offers (basically, what our application does). We will modeled this service with an interface IFindTheBestPlaces:   struct IFindTheBestPlaces : Interface&lt;IFindTheBestPlaces&gt; {     virtual std::optional&lt;ConfirmedReservation&gt; reserve(ReservationRequest const&amp;) = 0; };   Clients of our applications will only depend on this interface. The implementation of the service will stay hidden in the Hexagon, behind the adapter layer.   Instantiating this implementation require implementations for all the service providers it depends on (ISearchTrains, IReserveTrains, ILog). These implementations are taken as argument of the constructor:   class FindTheBestPlaces : public IFindTheBestPlaces { public:     FindTheBestPlaces(IReserveTrains&amp;, ISearchTrains&amp;, ILog&amp;);     std::optional&lt;ConfirmedReservation&gt; reserve(ReservationRequest const&amp;) override;      private:     IReserveTrains&amp; _iReserveTrains;     ISearchTrains&amp; _iSearchTrains;     ILog&amp; _iLog; };   Plumbing   The plumbing is done inside the factory function that creates the IFindTheBestPlaces service. It injects the real implementation of the service providers (ISearchTrains, IReserveTrains, ILog) inside the FindTheBestPlaces concrete API implementation.   All the details of this plumbing are therefore hidden from the user:   std::unique_ptr&lt;IFindTheBestPlaces&gt; find_best_places_service() {     ISearchTrains&amp; iSearchTrains = ...;     IReserveTrains&amp; iReserveTrains = ...;     ILog&amp; iLog = ...;     return std::make_unique&lt;FindTheBestPlaces&gt;(iReserveTrains, iSearchTrains, iLog); }   A similar plumbing goes into the unit tests of the core business logic. Each time a port is used inside a code under test, a mock, fake, stub must be provided.   A similar plumbing also happens in the code living inside the Hexagon. ISearchTrains, IReserveTrains and ILog must be carried to all classes and functions that need them (outside of the context of using a dependency injection framework).   Drawbacks of the Hexagonal Architecture   Applying the Hexagonal Architecture to our train reservation application allowed us to decouple the implementation of the service providers from the core business logic.   The code in the Hexagon is less likely (there are limits to everything) to need rework upon changing the technology stack or communication protocols used to exchange with the service providers. It solves our initial problem.   But there are obviously drawbacks in using this architectural pattern. These drawbacks should not be understood as advice against the Hexagonal Architecture. But we have to be aware of the costs of techniques we use before applying them.   Somestimes heavy   The Hexagonal Architecture is essentially a pattern of dependency injection, a pretty heavy technique, which leads to mocks in tests and the multiplication of interfaces.   The overhead of having to inject the interfaces is there. It can sometimes represent a good chunk of the code or the unit tests. Each class that needs to access the services will need to be injected the implementation of these services.   Not declarative   The hexagonal shell is not visible in the code. There is no clear indication in the code that some code is inside the hexagon. It is only a matter of convention between developers.   As a result of having only conventions, there is no strong insurance against a developer using the dependencies directly, instead of going through the ports, or adding a new dependencies without the associated port (it happens, we all have seen it).   Other caveats   Abstracting the services providers in the business logic does not abstract away the knowledge of know how many of these services there are.   Having IReserveTrains, IGetTypologies and ILog as ports shows part of the infrastructure inside the business logic code (the Hexagon). This is not much but it represents a source of coupling still. It can be solved by reworking the interfaces.   Embedded DSL: a more declarative approach   We have seen how the Hexagonal Architecture allowed us to separate the code that implements the domain core logic, from the code that deals with the infrastructure or the technicalities of the communication with other services.   We will now describe another approach, more adapted to typed functional programming languages, that aims at tacking the same problem, with different trade-offs.   Being declarative by selecting our primitives   The Structure and Interpretation of Computer Programs describes the basic building blocks of a programming language in the first sentences of the first chapter:      Primitives: the simplest elements a language is built upon   Means of combination: used to build compound elements from simpler ones   Means of abstraction: used to abstract compound elements as single unit   Most often, the primitives of the language of our business domain are not the primitives our general purpose programming language. This is why we write well-named functions, classes or interfaces: the build the right abstractions.   But sometimes, it is not enough.   Creating an Embedded Domain Specific Language (EDSL) in a language such as Haskell will allow us to keep much of the powerful means of combination and abstraction of our language, but will allow us to pick our own primitives.   Picking our own primitives will allow us to build our domain language at a much deeper level than function and classes. We will get a more declarative and safer equivalent of the Hexagonal Architecture, to decouple our business logic from the “real world”.   Selecting our primitives, but how?   It depends. In some host language (the language in which we build our embedded DSL), some approaches are more idiomatic and appropriate than others. Data and macros are the way to go in Clojure, while Monads will be prefered in Haskell.   Because we choose Haskell in this post, we will select an approach based on the concept of Monad (and Free Monad in particular). It is especially effective in languages having a very expressive type system such as Haskell, Idris or Scala.   A high level definition of Monads   We will not go into the conceptual definition of a Monad. It is an abstraction for a recurring pattern in Category theory, much like an interface or a design pattern in a programming language, but we will not this here.   Instead, we can consider a Monad as a way to define a small language inside our programming language. Inside this language, we can choose to modify the rules of composition, evaluation and the available primitives.   In short, it is like a customized environment of execution. Inside a Monad, the rules of the host language can be changed as we see fit. This allows us to speak a different tongue, closer to the language of the domain we are trying to model, and decoupled from the technicalities of the implementation.   Using Monads to select our primitives   In this section, we will explain how Monads can be used to offer a more declarative alternative to the Hexagonal Architecture. The next section will then show how to implement such a Monad.   Functions without side effects   Let us start with pure functions, which are function that lives outside of any Monad. You can find below the prototype of a function computing the length of a string:   -- Compute the length of a `String` and returns it as an `Int` length :: String -&gt; Int   This Haskell function, by the very declaration of its type, is limited to pure computations, with no side-effects allowed such as:      Sending a request to the Search Train service   Calling a function that would itself call the Search Train service   In other words, the primitives the length function has access to, are limited to those that do not perform side-effects. This seems to align particularly well with our need to create a functional core in the Hexagonal Architecture, but as we will see, this is too restrictive.   Functions with IO side effects   In Haskell, we can tag a function as living in the IO Monad, by prefixing its return type by IO. Inside this Monad, a function is allowed to do any side effect it wants (printing something, accessing a file, sending a HTTP request, etc):   -- Cannot do anything but pure computations reserve :: ReservationRequest -&gt; ConfirmedReservation  -- Can do anything it wants, such as sending a HTTP request reverseWithIO :: ReservationRequest -&gt; IO ConfirmedReservation   In other words, the primitives the reserveWithIO function has access to, contain all those that perform arbitrary side-effects.   Tagging a function with a Monad allows to select or discard the primitives available inside a piece of code, declaratively.   Defining our own language (Monad)   Inside the IO Monad, we can do anything. This is too permissive. We would like to forbid direct access to the implementation of the service providers in the Hexagon.   Outside of any Monad, we cannot do any side effects, directly or indirectly. This is too restrictive. Our business logic needs to access the service providers.   The solution is to define our own Monad, our own environment of execution with our own rules, which we will name ReservationExpr:   -- The `ReservationExpr` is a Monad with the appropriate restrictions: reserve :: ReservationRequest -&gt; ReservationExpr ConfirmedReservation   Inside this Monad, we will offer only the side effects needed to connect to the external services we want, by defining our own primitives to do it. By construction, these primitives will be the only way to access the service provider, the real world.   This effectively defines a DSL that is declarative (the Monad is clearly visible) and safe (we cannot bypass the primitives). We will now see how it also allows to solve our dependency injection concerns.   Free your Monad   As in the Hexagonal Architecture, we want to decouple the intent to use a service from its actual implementation inside our DSL. In other words, the primitives of our new language will only express what we want to do, and not how.   By varying the how behind the what, we can make our primitives do different things, much like an interface allows to vary the implementations. Our primitives will for instance connect to external services in production settings, but not during tests.   To do this, we will build our ReservationExpr Monad such that the code that lives inside it will emit abstract instructions upon evaluation, describing the connection to these external services instead of directly connecting to them.   For instance, the code inside our Monad will emit instructions such as:   SearchTrains at 11/06/2017-11:00 =&gt; Bind result to variable `trainId`  RetrieveTypology of Train with ID `trainId` =&gt; Bind result to variable `trainTypology`  Call pure function `belowOccupancyThreshold` on `trainTypology` =&gt; Bind result to `isValid`   We call this kind of Monad a Free Monad, as it only describes a sequence of operations, free of any hardcoded interpretations.   Interpreters   Functions tagged with our ReservationExpr Monad will just emit abstract instructions (an Abstract Syntax Tree to be exact) upon evaluation, instead of executing the code they contain. This effectively buys us one level of indirection.   These instructions can then be interpreted differently in different contexts. Inside a production context, we can make them trigger connections to the real world. Inside a test context, we can make them use an in-memory test database.   We do this by defining several functions that each transforms these abstract instructions into different real instructions of our host language (yes, much like compilers do for assembler). We call these functions interpreters.   We can build as many interpreters as we wish. We just pick the one we want depending on the context. For instance, for the same abstract instruction “SearchTrain at datetime D” and depending on the interpreter, we could:      Send an HTTP request (on a production environment)   Lookup inside an in-memory DB (for integration tests)   Return a fixed value (for a specific unit test)   Log the call to the function (for simulations)   You know the basics   If you understood this section, you understand how Free Monads help defining EDSLs, which are declarative and controlled environment to express domain specific logic.   Inside the EDSL, the business logic is decoupled from a lot of technical concerns such as external dependencies, or even the evaluation strategy. This is done by relying on primitives of a language that we developer have control on.   The rest of the post will demonstrate how simple and concise it is to define our own EDSL, by using Free Monads in Haskell.   Free Monad: Example implementation   This section explains how to create our ReservationExpr Monad easily and concisely. It is described in such a way that only a small amount of Haskell knowledge is needed.   If you are not interested in Haskell or never touched it, you should skip this section.   Step 1: Identify the abstract instructions   The first step to define our EDSL is to identify its primitives, the low level abstractions needed to express our business logic. We identify six of them:      SeachTrain T: searching for trains around the datetime T   GetTypology T: retrieving the typology for the train with reference T   Reserve T C S: reserving the seats S in the coach C of the train T   Log M: logging the message M (represented as a string)   Pure C: running a pure computation C (to implement our business logic)   Bind I C: binding the result of instruction I to the next computation C (*)   The last two instructions Pure and Bind are the two instructions needed in every Free Monad. They basically allow you to use the pure part of Haskell inside the EDSL.   (*): For non Haskell, do not worry if you do not understand Bind. Just think of it as a kind of glorified C++ / Java / C# semicolon and you will be fine.   Step 2: Define the type of the instructions   The abstract instructions have a semantic that could be encoded by functions. Searching for the trains at date-time T could be implemented by a searchTrain function living in the ReservationExpr Monad:   -- Search for a train: -- * At a given DateTime (example: 2017-07-01 14h38) -- * Returning a list of TrainId searchTrain :: DateTime -&gt; ReservationExpr [TrainId]   Similarly, every single of our primitives could be encoded as functions:   searchTrain :: DateTime -&gt; ReservationExpr [TrainId] getTypology :: TrainId -&gt; ReservationExpr (Maybe TrainTypology) reserve :: Reservation -&gt; ReservationExpr (Maybe Reservation) log :: String -&gt; ReservationExpr ()   Now, these functions cannot contain direct calls to external services. Instead, they should emit abstract instructions (for an interpreter to translate them later).   This is easy enough: we just take the functions above, capitalise them (first letter to upper case) to get type constructors, and group these constructors into a type named after our Monad: ReservationExpr.   data ReservationExpr a where   SearchTrain :: DateTime -&gt; ReservationExpr [TrainId]   GetTypology :: TrainId -&gt; ReservationExpr (Maybe TrainTypology)   Reserve :: Reservation -&gt; ReservationExpr (Maybe Reservation)   Log :: String -&gt; ReservationExpr ()   Pure :: ta -&gt; ReservationExpr ta   Bind :: ReservationExpr ta -&gt; (ta -&gt; ReservationExpr tb) -&gt; ReservationExpr tb   ReservationExpr a is the abstract type for an instruction which, upon evaluation, will return a value of type a. It consists of primitive instructions such as SearchTrain, which will return a list of train ids upon evaluation.   Thanks to Pure and Bind, the primitive instructions can be composed into bigger computations. So ReservationExpr a is also the abstract type of computations inside the ReservationExpr Free Monad, which return a value of type a.   Step 3: Make it a Monad   Haskell will need a bit of boilerplate code to be satisfied and make our ReservationExpr a recognized Monad.   instance Functor ReservationExpr where   fmap fn expr = expr &gt;&gt;= Pure . fn  instance Applicative ReservationExpr where   pure = Pure   fExpr &lt;*&gt; aExpr = fExpr &gt;&gt;= \\f -&gt; fmap f aExpr  instance Monad ReservationExpr where   (&gt;&gt;=) = Bind   If you do not understand these lines, it is fine. It is enough to copy-paste them and search and replace in them to define your own Free Monad.   Step 4: Write your business logic   We now are all set. We can define our business logic in our EDSL based on the abstract instructions we defined above. Here is an example of such a code:   reserve :: ReservationRequest -&gt; ReservationExpr ReservationResult reserve request = do   trains &lt;- SearchTrain (_dateTime request) -- Search for trains at date-time   forM trains $ \\train -&gt;                   -- Loop on all the trains     typology &lt;- GetTypology train           -- Get the typology of a train     ...                                     -- Implement the reservation rules     Log (\"Confirming reservation\")          -- Logging stuff     confirmed &lt;- Request reservation        -- Trying to reserve the train     ...                                     -- More stuff   Upon evaluation, this code will translate into a tree of instructions, ready to be read by an interpreter. Therefore, all the code that lives inside the ReservationExpr Monad is itself free of side effects. It only builds an AST.   Step 5: Write your interpreters   A ReservationExpr a is an Abstract Syntax Tree that upon evaluation will produce a value of type a. Any interpreter we define on this AST, whatever its implementation, will have to do exactly that.   This means that our ReservationExpr Monad, through its types, forces the interpreters to comply with the rules expressed inside the DSL. The type system will make sure that SearchTrain must return a list of train ids or else will reject the code.   This has two important consequences:      You get tons of help by the type system to write the interpreters   You can encode very powerful invariant in the DSL, using the type system   We can therefore write our production settings interpreter by (almost) just pattern matching on the AST and following the type hints of the Haskell compiler.   evalReservation :: ReservationExpr ty -&gt; IO ty evalReservation = evalCmd   where     evalCmd :: ReservationExpr ty -&gt; IO ty     evalCmd (Log msg) = putStrLn msg     evalCmd (Pure val) = pure val     evalCmd (Bind val next) = evalCmd val &gt;&gt;= evalCmd . next     evalCmd (SearchTrain time) = searchTrainAt time     evalCmd (GetTypology trainId) = getTypologyOf trainId     evalCmd (Reserve command) = confirmCommand command   This evalReservation transforms abstract instructions into real world IO calls. It effectively fills the role of dependency injection in the Hexagonal Architecture.   But we are not limited to this interpreter. We can build an interpreter to run our instructions into a in-memory database model (the State monad):   -- Run the computation using a InMemoryDb of trains and typologies -- * Simulates real world behaviors with fake data -- * Can simulate the behavior of successive interacting requests evalWithFakeDB :: ReservationExpr ty -&gt; State InMemoryDb ty   And we can do more. We can write interpreters to log the function calls, return constant values, and more… There is no limits but your imagination.   Step 6: Wrap up in a nice API   As in the case of the Hexagonal Architecture, we can provide a wrapper around our API to hide the details of the implementation of the service.   In the case of the Free Monad, that would be hiding the construction of the AST (done in reserveImpl) and the interpreter we use, all behind a single function call:   -- Wrapper around the reserveImpl function, living in ReservationExpr reserve :: ReservationRequest -&gt; IO ReservationResult reserve = evalReservation . reserveImpl   Similarly, we can provide wrapper for the in-memory DB interpreter, to help the writing of our integration tests:   reserveWithFakeDb :: ReservationRequest -&gt; State InMemoryDb ReservationResult reserveWithFakeDb = evalWithFakeDB . reserveImpl   Step 7: Enjoy &amp; Celebrate   There is nothing much to do. Following this pattern, we provided a safe and decoupled EDSL for our business logic code.   Code expressed in this EDSL is truly decoupled from the external world by the Free Monad, hidden from the external world by the wrapping layer around the API, and incapable of directly communicate with the external world.   Free Monad vs OOP Hexagonal Architecture   Having gone through this post, the similarities between the Hexagonal Architecture and the Free Monad pattern should be quite clear.   Both approaches rely on creating a “context bubble”, decoupled from the real world by an abstraction, and plugged back to the real world by an adaptation layer. But there are some important differences too.   Complexity   I think there is little argument that the Free Monad is a more complex pattern than the Hexagonal Architecture. Interfaces are a much easier concept to grasp than Monads for the vast majority of developers, which makes it easier to build the initial architecture.   But on the other hand, the Free Monad provides a better guidance to the developers: it is much more explicit and declarative. Developers do not have to rely on documentation (if any) to find their way in the architecture, making their life easier.   It ultimately boils down to what is more idiomatic. Interfaces are pretty common in OOP, while Monads and Free Monads are a pretty classic pattern in Haskell.   Declarative-ness   The Free Monad is by its very nature much more declarative than the Hexagonal Architecture. I think this is a no-contest.   Any code written inside a Free Monad is only providing a recipe (the what). How the recipe will be translated in terms of real world instruction is completely decoupled from the recipe and left for the interpreter to decide.   The interpreter can choose to evaluate the code differently than how it looks. It might bulk the request to external services, cache them, parallelise some evaluation safely (knowing it is pure) and more (see Haxl for a great example of this by Facebook).   Technical aspects are therefore more decoupled in the Free Monad than in the Hexagonal Architecture. The Hexagonal Architecture is still bound by the standard rules of evaluation of the language and can only abstracts the real world calls.   Rigidity vs Safety   Both pattern aim at creating an environment where code is more constraint than usual code, allowed to perform any kind of side effects (such as code living in the IO Monad).   The difference lies in how each pattern enforce this. The Hexagonal Architecture does not enforce any guaranty, while the Free Monad does. In truth, both approaches have their benefits.   Being more constraint makes the Free Monad able to offer stronger guaranties (the code must comply with the architecture, and the interpreter can therefore leverage this) but also makes the architecture more rigid.   As a result, jumping right on the Free Monad from the start of a project, while still exploring the problem, is likely not a good idea. But jumping too soon on the Hexagonal Architecture is also a risk (I learned it some years ago).   Both patterns erect walls between the real world and the domain logic. This is what they do. And it should be quite obvious that this is not a very good idea to try to erect walls too soon, before even knowing what we want to protect.   Domain modelling   The Free Monad offers a different kind of domain modelling than the Hexagonal Architecture, by separating the following aspects of the domain:      The recipe describing the business logic   The rules the recipe must follow, encoded with types in the DSL   The transcription of the recipe to the real world   This separation allows us to profit more from domain modelling. We can for instance enforce some invariants of the domain directly inside the type system of the DSL.   We can also abstract some technical aspects some more. For instance, error handling can be done inside the interpreter, stopping the evaluation of an expression without having to rely on exception going through the business logic code.   Final words   The Free Monad is a kind of Hexagonal Architecture on steroid. More declarative and stronger at enforcing the separation of concern, the Free Monad is also more rigid and a potentially riskier choice at the start of project.   The Free Monad shines by providing a stronger decoupling between the recipe describing the business logic and the actual evaluation of the recipe, allowing different evaluation of the code and domain specific optimizations.   Ultimately though, both Hexagonal Architecture and Free Monad are patterns whose complexity is tied to the idioms of the languages they are used in.      The Hexagonal Architecture is a better fit in OOP   The Free Monad is likely a better fit for Haskell   For languages such as Scala, both approaches are available   If anything, I hope this post showed how Functional Programming languages such as Haskell have their own pattern, which make them great at modelling a problem.   You can find the code in Haskell in the following Git Hub repository.     Acknowledgments to the speakers of the Afternoon dedicated to DDD: Thomas Pierrain, Jérémie Grodziski and Bruno Boucard whose Kata was a great inspiration for this post.   Acknowledgments to the speakers of the Alistair in the Hexagon meetup: Thomas Pierrain and of course Alistair Cockburn for their great and illustrated explanation of the Hexagonal Architecture.  ","categories": ["software-design"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/07/06/hexagonal-architecture-free-monad.html",
        "teaser": null
      },{
        "title": "Implementing Clojure-like Transducers in Idris: definitions & concepts",
        "excerpt":"The 1.0.0 of Idris has been released just a few months back. We will continue our series on post on Idris, by implementing a small transducer library (the Idris package is available in this GitHub repo).   Our goal in this post will be to provide Idris with a library efficient composable algorithmic transformations. This is something we quickly feel the need to when playing with Idris, due to the strict (non-lazy) nature of the language.   Motivation   Let us first start by discussing why transducers are an interesting library to introduce in Idris.   Lazy vs Strict   As mentioned in the post listing 10 differences between Haskell and Idris, Idris is strict by default, while Haskell is lazy by default. Whether or not laziness is a good default is a common subject of discussion in the Haskell community.   On the bad side, laziness is often complained about for its tendency to introduce non obvious memory leaks or other performance defects in Haskell code. On the good side, laziness allows to separate processes that produce data, from the one transforming or consuming it (*).   (*) John Hughes writes in lot more details about the benefits of laziness in terms of software modularity in its great paper Why functional programming matters.   Composing algorighms   Thanks to laziness, we can easily compose map, filter and folds together in Haskell and not worry to much about intermediary list creation. But this is not the case in Idris.   The following two lines of Idris code will not execute at the same speed: map (+1) will need to first realize the whole intermediary list before take extracts only the 10 first elements:   take 10 $ map (+1) [1..20]   -- Faster take 10 $ map (+1) [1..1000] -- Slower   In Idris, we need to implement ways to emulate laziness in order to get back the efficient composition of algorithm which is native in Haskell.   Why transducers?   Transducers are one way to implement efficient composition of algorithms. Transducers comes from the Clojure world and have been built with efficiency and reuse in mind:      They eliminate intermediary sequence or containers when composing algorithms   They decouple the transformation from the data source and destination   This makes transducers a great tool to build generic pipe-lines of algorithmic transformation, reusable in quite different contexts, and which can be composed very efficiently.   Step functions &amp; Reducing functions   We will start with some definitions and define their associated types. The vocabulary is directly inspired from Clojure, with some minor twists. Defining this vocabulary will guide us through the main concepts of pipelines of data transformation.   Step functions   A stateless step function is a function whose purpose is to be used in a left fold (also known as reduce in Clojure or std::accumulate in C++).   It combines an element coming from a data source (a container for instance) with some intermediary result, to compute the next intermediary result. Put differently, a step function represents a task to be performed in one iteration of a pure loop (without states and side-effects).      We call accumulator (or acc) the result being computed   We call element (or elem) an element of the data source to read   We can define a type alias that will help us formalise this concept in the code:   StatelessStep : (acc, elem: Type) -&gt; Type     -- List of type parameters for the alias StatelessStep acc elem = acc -&gt; elem -&gt; acc   -- Define the alias to the step function   For instance, the type alias StatelessStep Int String represents a step function that consumes strings to produce a result of type integer. It could be a function that sums the length of strings (in a fold):   sumLength : StatelessStep Int String sumLength res str = res + fromNat (length str)  foldl sumLength 0 [\"abc\", \"de\", \"\", \"fghij\"] &gt; 10   Adding state   A stateful step function is a step function that needs some additional state to do its job properly. For instance, splitting a collection into chunks of equal size requires some kind of state: elements have to be kept in store until the completion of a chunk.   Because we are in a pure language, we will avoid relying on side-effects to track the state of our step function. Instead, we will rely on the State Monad:   Step : (state, acc, elem: Type) -&gt; Type Step state acc elem = acc -&gt; elem -&gt; State state acc   For instance, the type alias Step Bool Int String represents a step function that consumes strings to produce a result of type integer, and maintains a state of type boolean. It could be a function that sums the length of strings, ignoring one of every two strings it encounters:   sumLengthOfEveryOddStrings : Step Bool Int String sumLengthOfEveryOddStrings totalLength str = do   doSum &lt;- get                        -- Get the state (should we sum the length?)   modify not                          -- Modify the state (alternate True and False)   pure $ if doSum     then sumLength totalLength str    -- Sum the length in case of True     else totalLength                  -- Otherwise return the length unchanged   Adding early termination   We will also want to express early termination for algorithms such as take that do not need to consume the whole data source. To do so, we will enhance our stateful step function to return a result decorated by a status:   data Status a = Done a | Continue a  Step : (state, acc, elem: Type) -&gt; Type Step state acc elem = acc -&gt; elem -&gt; State state (Status acc)      The step can return Done to indicate early termination of the loop   The step can otherwise return Continue to proceed with the rest of the loop   For instance, the type alias Step () Int String represents a step function that consumes strings to produce a result of type integer, and maintains no state. It could be a function that sums the length of strings, stopping when the sum exceeds a given value:   sumLengthUntil : Int -&gt; Step () Int String sumLengthUntil maxValue totalLength str =   pure $ if totalLength &lt;= maxValue     then Continue (sumLength totalLength str)     else Done totalLength   Note: this ability to return early combines especially well with state (for instance to build functions such as take or drop). But we just saw that it also makes sense without state.   Reducer (or reducing function)   A reducer (or reducing function) is what we get when we bundle a stateful step function with its state. The following Idris code creates a type Reducer that contains a field state and two functions runStep and complete:   record Reducer st acc elem where  -- Defines a reducer in terms of   constructor MkReducer              state : st                      -- * A piece of state   runStep : Step st acc elem      -- * A (stateful) step function   complete : st -&gt; acc -&gt; acc     -- * A completion function   The runStep function is doing the heavy lifting. It takes as input the current state, the current value of the accumulator, and an element. It returns the a new accumulator and the state to use for the next iteration. It represents the content of a loop.   The complete function is there to deal with the remaining piece of state. It represent the termination of the loop, the last thing to perform once the source of data is consumed. It allows to discharge remaining pieces of state at termination.   Example of reducer   Going back to our previous example, we can package our sumLengthOfEveryOddStrings step function (which sums the length of strings, ignoring one of every two strings it receives as input) with its state (a boolean).   Having packaged the stateful step with its state, we get a reducer that is self sufficient. It can be plugged into reduce to execute it on an input collection:   let reducer = MkReducer True sumLengthOfEveryOddStrings (const id)  reduce reducer 0 [\"abc\", \"de\", \"\", \"fg\", \"hij\"] &gt; 6   We have not introduced the reduce function yet, but you can see it as a generalised fold which manage both state and early termination.   Transducer   A transducer is a transformation of reducers. It takes as input a reducer, and returns another reducer. The new reducer includes additional functionality. In the process of adding new functionality, a transducer can both:      Change the type of the state (s1 to s2), usually to track some more state   Change the type of the element (elem1 to elem2) being accumulated   The type of the accumulator, on the other hand, cannot be modified (the result we expect from a loop is fixed). This leads to the following type alias for transducers:   Transducer : (acc, s1, s2, elem2, elem1: Type) -&gt; Type Transducer acc s1 s2 elem2 elem1 =   Reducer s1 acc elem1      -- Input reducing function   -&gt; Reducer s2 acc elem2   -- Output reducing function   For instance, the type alias Transducer Int () Bool String Char represents a transducer that transforms:      A stateless reducer accumulating strings into a result of type integer   To a reducer accumulating characters into result of type an integer   And adding a boolean state in the output reducer   Transducer composition   Because transducers are just functions from one reducer to another reducer, they can be composed together just like normal function can. Composing transducers lets us:      Gradually add features to pipe-line of data transformation   Avoid realizing intermediary containers: we only compose recipes   For instance, we can compose a transducer than adds a filtering behaviour on a reducer to a transducer that maps each element to its square:   filtering odd   -- Added behavior: keep only odd numbers mapping square  -- Added behavior: square each element  -- When composed: keep only odd numbers and square them afterwards filtering odd . mapping square   Because of this, we can see transducers as pipe-lines, each each step is responsible for its own transformation, and forwards resulting elements to the next transducer in the line.   Note: You may have noticed that the type alias for transducer had elem1 and elem2 reversed. This is because transducers compose from right to left (the direction of composition), but the data flows from left to right (the direction of pipeline).   Running the loop   Reducing functions provides us with recipes to consume a stream of value and summarize it as a single result. Transducers allows us to build such recipes out of smaller recipes. But to make these recipes useful, we need to way to execute them.   In this section, we will dive into the implementation of reduce and transduce, two function that will allow us to execute the recipe on some data. You can skip this section if you are not interested in the implementation, and jump to the next one for example of transducers.   Reduce   Our library provides a function named reduce that we used already in this post. It executes a provided reducing function (a recipe), given:      An initial value for the accumulator   A data source we can fold over to retrieve a stream of values   It will consume elements of the data source, executing the recipe at each iteration, until the stream is totally consumed or until the recipe asks for early termination. Then it will call the completion function on the result before returning it.   reduce : (Foldable t) =&gt; Reducer st acc elem -&gt; acc -&gt; t elem -&gt; acc reduce step acc =   uncurry (complete step)                 -- 4) Call the completion on the result     . (\\(acc, s) =&gt; (s, unStatus acc))    -- 3) Remove the wrapping status     . (flip runState (state step))        -- 2) Remove the state monad     . runSteps (runStep step) acc         -- 1) Consume as many value as needed   This implementation relies on runSteps to run the loops until either the stream of values is totally consumed, or the reducing function asks for early termination (returning Done).   Running the steps   The implementation of runSteps relies on Continuation Passing Style to support the early termination.   runSteps : (Foldable t) =&gt; Step st acc elem -&gt; acc -&gt; t elem -&gt; State st (Status acc) runSteps step acc elems =   foldr stepImpl (pure . id) elems (Continue acc) -- Using continuation passing style   where     stepImpl _ nextIteration (Done acc) = pure (Done acc)     stepImpl e nextIteration (Continue acc) = step acc e &gt;&gt;= nextIteration      foldr builds a chain of functions, one for each element of the source   Each of these functions represents one iteration of the loop   Each iteration and is provided with the next one: nextIteration   If nextIteration is not called, the next iteration is not run and so the loop stops   Transduce   The second key function named transduce is only a thin but useful layer above reduce. It reduces (pun intended) verbosity for the most common use cases.   Indeed, a lot of pipe-lines of data transformation ends up with a stateless step function (like a sum, a concatenation, etc.). In such cases, using transduce instead of reduce removes a bit of noise. Here is an example in which we sum the square of odd numbers:   -- with transduce transduce (filtering odd . mapping square) (+) 0 [1..10] &gt; 165  -- with reduce reduce (filtering odd . mapping square $ terminal (+)) 0 [1..10] &gt; 165   One other great advantage is that it allows to use the word transduce in our code, making your Idris code almost as cool as Clojure code.   Building our own transducer   It is time to build our very own transducers. We will keep it simple in this post, and focus on stateless transducers. We will also use a helper function statelessTransducer (available in the library) to abstract away some of the details of the construction of a transducer.   The goal is to build an intuition for those who are foreign to the concept. The next post will deal with stateful transducer and unveil the details behind the helper functions.   Mapping   Mapping consists in using a function from a to b to transform an input reducer operating on element of type b to a reducer operating on elements of type a (we see the continuation passing style formulation here).   It takes elements of type a and sends elements of type b to the next element of the pipe-line. In the code below, next represents the step function of the next transducers in the pipe-line, while fn represents the mapping function from a to b.      By applying the function fn on an element of type a, we get an element of type b   We can give this element to next, which consumes elements of type b   ||| Given a mapper of type (a -&gt; b), it transforms: ||| - a step function taking values of type `b` ||| - into one taking values of type `a` mapping : (a -&gt; b) -&gt; Transducer acc s s a b mapping fn = statelessTransducer $   \\next, acc, a =&gt; next acc (fn a)   Here is an example in which we sum the length of a bunch of strings, multiplying each length by 2 along the way:   transduce (mapping length . mapping (*2)) (+) 0 [\"abc\", \"\", \"de\"] &gt; 10   Thanks to transducers and ability to compose in terms of recipe, we get the following equivalence by construction: mapping f . mapping g = mapping (g . f). Note that f and g are inverted compared to the usual Functor law because of the left to right flow of data.   Filtering   Filtering consists in transforming an input reducer operating on element of type a to a reducer operating on only those elements a that satisfy the a given predicate.   In the code below, next represents the step function of the next transducers in the pipe-line, while pf represents the predicate function from a to Bool.   By calling next on only these elements that satisfy the predicate, we effectively filter these elements from the input source data: the rest of the pipeline will not see them.   ||| Given a predicate of type (a -&gt; Bool), it transforms: ||| - a step function taking values of type `a` ||| - into one taking the values of type `a` that fulfills the predicate filtering : (a -&gt; Bool) -&gt; Transducer acc s s a a filtering pf = statelessTransducer $   \\next, acc, a =&gt;     if pf a       then next acc a       else pure (Continue acc)   Here is an example in which we sum the length of strings that do not start with the letter ‘a’:   transduce (filtering (\\s =&gt; not (startsWith 'a' s)) . mapping length) (+) 0 [\"abc\", \"de\", \"fgh\"] &gt; 5   Concat Mapping   Concat mapping is just like mapping, to the exception that the function provided to the catMapping function may return several b for one a.   In the code below, next represents the step function of the next transducers in the pipe-line, while fn represents the mapping function from a to a collection of b.   By calling next on all the the elements output by fn, catMapping takes elements of type a from and the left, and transmits elements of type b to pipe-line on the right. The main difference with mapping is that the number of bs is not necessarily the same as the number of as.   ||| Given a mapper of type (a -&gt; Foldable b), it transforms: ||| - a step function taking values of type `b` ||| - into one taking values of type `a` catMapping : (Foldable t) =&gt; (a -&gt; t b) -&gt; Transducer acc s s a b catMapping fn = statelessTransducer $   \\next, acc, a =&gt; runSteps next acc (fn a)   Here is an example in which we sum the length of strings, counting each of them twice:   transduce (catMapping (replicate 2) . mapping length) (+) 0 [\"abc\", \"\", \"de\"] &gt; 10   Conclusion, and what’s next   In this post, we went over basics to define transducers in Idris. We defined the concepts and our main types, detailed the main function reduce and transduce, and built very simple transducers.   In the next post, we will see how to define more interesting transducers, such as take, takeWhile, interspersing or groupingBy. We will also look at some helper functions that helps building these transducers more easily.   The library is available in this GitHub repository. Any suggestions for improvements is obviously welcomed.   ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Idris"],
        "url": "/blog/2017/07/28/idris-transducers.html",
        "teaser": null
      },{
        "title": "Implementing Clojure-like Transducers in Idris: advanced transducers",
        "excerpt":"In the previous post, we started the implementation of a small transducer library for Idris. We went over the main concepts, defined types for each of them, and implemented reduce and transduce. We ended the post by building basic transducers such as mapping or filtering.   In today’s post, we will continue where we left off. We will first look at a helper function we used in our last post to build stateless transducers. We will then build some more complex transducers, ones with states and featuring completion steps. We will also build some more helper to define transducers more concisely and correctly.   Disclaimer: This post builds on our previous post on transducers. You should read it if you want to be able to follow this one.   Quick summary of the last episode   Before going further in this post, let us review together the main concepts behind transducers. If any of these concepts is not clear to you, you can read my previous post on the subject.   Vocabulary for reduction recipes   Let us start with the basic vocabulary:      A reduction is a process that consumes a series of values to build a final result   An accumulator is the name we give to this result under construction   A step function represent the content of an iteration of such a reduction   A reducer is a recipe for a reduction, with a step function, some state and a completion step   A transducer is a transformation on a reducer, used to add functionality to a recipe   Composing recipes   Reducers are recipes for algorithms operating on source of values (such as but not limited to Foldable), and transducers are the means to transform smaller recipes into bigger ones.   To build a complete recipe, we can compose transducers together the same way we compose function. Each transducers adds a new ingredient to the recipe:   filtering odd   -- Added behavior: keep only odd numbers mapping square  -- Added behavior: square each element  -- When composed: keep only odd numbers and square them afterwards filtering odd . mapping square   In the example above, we compose two transducers together to build a more complex recipe out of simpler ones.   Executing a recipe   Having defined how to build recipes, we now need to show how to run them. The functions reduce and transduce allow us to execute a recipe on a collection of values (any Foldable).   For instance, we can compute the sum of the squares of odd numbers on a list, by first defining a transducer pipe-line, and then running it on a list of numbers:   -- with transduce transduce (filtering odd . mapping square) (+) 0 [1..10] &gt; 165  -- with reduce reduce (filtering odd . mapping square $ terminal (+)) 0 [1..10] &gt; 165   Now that we are done with the reminder, let us move on!   Back to stateless transducers   So we gave some example by implementing some stateless transducers. To do so, we used an helper function named statelessTransducer.   In this section, we will explore how this helper function is implemented. The goal is to explain how to easily create your own transducers, by showing how this helper function works behind the curtain.   Back to the mapping transducer   The first transducer we defined was named mapping. It takes a function from a to b and applies it to each element that goes through the transducer:      It receives elements of type a from the previous transducer in the pipe-line   It forwards elements of type b to the next transducer in the pipe-line   In the implementation of mapping, next represent the next step function of the pipe-line, acc represents the accumulator, and a represent the input flowing through the pipe-line.   mapping : (a -&gt; b) -&gt; Transducer acc s s a b mapping fn = statelessTransducer $   \\next, acc, a =&gt; next acc (fn a)   Now, if we go back to the definition of a transducer, it is a transformation of a reducer into another reducer. So a transducer can act upon the three components that together forms the reducer it transforms: a state, a step function and a completion function.   The statelessTransducer helper function allows to only deal with the transformation of the step function, when states and completion functions do not need any transformation. This is why the implementation of our mapping function is so tiny.   We will now look behind the curtain and see how statelessTransducer works.   Defining of statelessTransducer   By definition, a stateless transducer does not need to modify the state of the pipe-line it transforms, since it does not track any additional state.   We can further reason that the only operation that makes sense for a stateless transducer is to transform the step function. Indeed, the completion function is mainly there to deal with the remaining piece of state upon termination of the data source. If there is no state to flush, there is no completion step needed either.   This leads us to define statelessTransducer as a factory function that creates a transducer from the specification of a transformation of a step function:   statelessTransducer : (Step s acc b -&gt; Step s acc a) -&gt; Transducer acc s s a b statelessTransducer onStep next =   MkReducer     (state next)              -- Do not add to state of next transducer     (onStep (runStep next))   -- Modify the step of the next transducer     (complete next)           -- Keep the completion of the next transducer   This function creates a transducer that takes elements of type a and outputs elements of type b from:      The definition of Step receiving elements of type a (*)   Built from of Step receiving elements of type b   (*) Keep in mind that transducers compose to the left, while data flows to the right. A transducer that maps elements from a to b therefore transforms a step function on b‘s to a step function on a‘s   Using statelessTransducer   The statelessTransducer function takes as argument a function from a step function to a new step function. Yet, our mapping function is defined in terms of a function taking three arguments:   mapping : (a -&gt; b) -&gt; Transducer acc s s a b mapping fn = statelessTransducer $   \\next, acc, a =&gt; next acc (fn a)   To understand this, we need just need to substitute the second occurrence of the type alias Step inside the prototype of the function onStep given to statelessTransducer:   -- Type of the `onStep` argument provided to `statelessTransducer` onStep : Step s acc b -&gt; Step s acc a  -- Type of `Step` (quick reminder) Step state acc x = acc -&gt; x -&gt; State state (Status acc)  -- Type of `onStep` (substituded) onStep : Step s acc b -&gt; acc -&gt; a -&gt; State s (Status acc)   Put differently, the type of onStep correspond to a step function that takes an additional parameter as first argument: the next step function in the pipe-line. Hence the three arguments to mapping.   Note: pragmatically, there is not much a stateless transducer can do with this next function except calling it once (mapping), several time (concat mapping) or not calling it (filtering). It still allows to build interesting transformations as the next section will show.   More examples   Using this helper function, we can define stateless transducers in a very few lines of code.   For instance, we can define takingWhile, which consumes a source of data as long as its element satisfy a given predicate. The definition is short and quite close to the specification of what the transformation does:   takingWhile : (a -&gt; Bool) -&gt; Transducer acc s s a a takingWhile p = statelessTransducer $   \\next, acc, a =&gt; do     if p a                  -- If the element a satisfies the predicate       then next acc a       -- * Then forwards it to the rest of the pipe-line       else pure (Done acc)  -- * Else trigger an early termination   Here is a quick example of how it can be used to consume a stream of values lazily:   transduce (takingWhile (&lt;= 10)) (+) 0 [1..100] &gt; 55  foldl (+) 0 [1..10] &gt; 55   Note: interestingly, while we can define takingWhile as a stateless transducer, you cannot define droppingWhile (which ignores elements until one that satisfies the predicate is encountered) without tracking some state.   Toward stateful transducers   We defined transducers as arbitrary transformation on reducers, taking as input a reducer and returning as output a potentially completely different reducer.   In practice, the transformation is not as arbitrary as this may sound: a lot of transformation do not make sense. We can therefore offer some helper functions that will help us define more easily a reduced set of transducer that we will call sound transducers.   In this section, we will define these helpers function to use them in the next section. If you need examples to make sense of these functions, try to switch back and forth between this section and the next one.   Sound &amp; unsound transducers   A sound transducer is one that performs only additive changes to the reducer it acts upon. It might add some state but will not remove or modify any existing one. It might add a completion step but will not remove or impact existing ones. In addition to this, a sound transducer will not mess with other’s state.   We will therefore define a sound transducer as a transducer that:      Only adds to the state of the pipe-line   Only impacts its own state in its step function   Does not remove or mess around with other’s completion step   Our next step is to define a factory function makeTransducer, which will enforce these constraints, and by restraining the problem will also offer a cleaner API.   Sound state transducers   A sound transducer is only able to add to the state of the pipe-line. We can therefore create a transducer by only asking for the initial value of this additional piece of state. We can then combine the additional piece of state (added by the transducer) to the pipe-line state, by grouping them under a pair.   Practically, our factory for transducer will ask for a state s’ and will return a transducer with a state (s’, s). This lets us define the first pieces of our makeTransducer prototype:   makeTransducer :   s' -- Additional initial piece of state   -&gt; ??? -- Step transformation   -&gt; ??? -- Completion transformation   -&gt; Transducer acc s (s', s) a b -- Output: a transducer adding state s'   There is no loss of generality there, it is simply a matter of convention.   Sound step function transformations   A sound transducer will not mess with the completion functions of the pipe-line it transforms, nor to the state of this pipe-line. So a step function transformation only needs to have access to the state its operates on, and to the next step function in the pipe-line:   makeTransducer :   s' -- Additional initial piece of state   -&gt; (Step s acc b -&gt; Step s (s', acc) a) -- Step transformation   -&gt; ??? -- Completion transformation   -&gt; Transducer acc s (s', s) a b -- Output: a transducer adding state s'   To better understand the step transformation prototype, we will play the same game we played before and substitute the definition of Step in it:   -- Type of step transformation stepTf : Step s acc b -&gt; Step s (s', acc) a  -- Type of `Step` (quick reminder) Step state acc x = acc -&gt; x -&gt; State state (Status acc)  -- Type of step transformation (after substitution) stepTf : Step s acc b -&gt; (s', acc) -&gt; a -&gt; State s (Status (s', acc))   So basically, we specify a step function in terms of the previous state of the current state of the transducer, and return a new version of this state. The whole computation happens in the State s monad to be able to call the next step function.   Sound completion transformation   A sound transducer will not mess with the completion functions of the pipe-line it transforms. It can only add a new completion function, whose goal is to handle any remaining state upon termination of the pipe-line.   The new completion function will need to have access to the next step function in the pipe-line. This allows to send some leftover elements to be processed before terminating (quite useful for transducers such as chunksOf). Because of this, this computation also has to happens in the State s monad:   makeTransducer :   s' -- Additional initial piece of state   -&gt; (Step s acc b -&gt; Step s (s', acc) a) -- Step transformation   -&gt; (Step s acc b -&gt; s' -&gt; acc -&gt; State s acc) -- Completion transformation   -&gt; Transducer acc s (s', s) a b -- Output: a transducer adding state s'   The prototype of the function makeTransducer is now complete. The full definition of the function is available at this Gist GitHub. Most of it consists in plumbing to transform a State s computation into a State (s’, s) computation, and to handle the systematic call of the next completion function in the pipe-line.   Now with the completion step   A large number of stateful transducers do not need to define a completion step. Their state does not need to be flushed upon the termination of the pipe-line.   We can therefore improve the API again by providing an additional statefulTransducer helper function, that looks like makeTransducer except that it does not require a completion function:   statefulTransducer : s' -&gt; (Step s acc b -&gt; Step s (s', acc) a) -&gt; Transducer acc s (s', s) a b statefulTransducer initState stepTf = makeTransducer initState stepTf onComplete   where     onComplete next _ acc = pure acc   The implementation consists in a wrapper around makeTransducer that specifies a completion step that does nothing. It is not much, but it does clean the definition of some transducers as we will see.   Example of stateful transducers   We built some helper function to make the construction of stateful transducers easier and safer. It is time to go through some example to show how to use them to build interesting transducers.   Indexing elements   We will start by defining a simple but useful transducer, that associates to each element that goes through the pipe-line an associated index (a position) in the stream. We will call it indexingFrom.   Inputs: ['a', 'b', 'c']  Outputs of (indexFrom 1): [(1, 'a'), (2, 'b'), (3, 'c')]   This transducer requires some piece of state, and integer, to track the next index to associate to an element. At each new element going through, it bumps this index by one.   The prototype of this transducer is therefore:   indexingFrom : Int -&gt; Transducer acc s (Int, s) a (Int, a) indexingFrom startIndex = ???      It adds an integer to the state s of the pipe-line   It associates each a that goes through it with an integer   Implementing IndexFrom   We can reason that indexingFrom does not need any completion step: the state does not need to be flushed at pipe-line termination. The implementation will therefore use our statefulTransducer function, which takes the initial state as first argument, and the step transformation as second argument.   The initial step is simply the index from which we want to start counting. The step function just sends a pair (index, element) to the next step function and increments the index value:   indexingFrom : Int -&gt; Transducer acc s (Int, s) a (Int, a) indexingFrom startIndex = statefulTransducer startIndex stepImpl   where     stepImpl next (n, acc) a = withState (succ n) &lt;$&gt; next acc (n, a)   This function makes use of the withState helper function, provided in the library, to add the next piece of state to the accumulator returned by the function.   withState : s -&gt; Status acc -&gt; Status (s, acc) withState s = map (\\acc =&gt; (s, acc))   We can play along with our new transducer to associate indexes to element at different stages of a filtering pipe-line.   reverse $ into [] (filtering even . indexingFrom 0) [1..10] &gt; [(0, 2), (1, 4), (2, 6), (3, 8), (4, 10)] : List (Int, Integer)  reverse $ into [] (indexingFrom 0 . filtering (even . snd)) [1..10] &gt; [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)] : List (Int, Integer)   As we can see, the result is not the same depending on whether we add the indices before the filtering or after the filtering: before the filtering, some indices will get jumped over.   Taking a fixed amount a values   We can combine state with the ability to early terminate from a computation. We will demonstrate it by defining the function taking that only consumes a fixed number of elements of an input stream (much like the function take would do).   This transducer needs to maintain a count down of elements to consume, and will stop the pipe-line when this counter reaches zero:   taking : Nat -&gt; Transducer acc s (Nat, s) a a taking n = statefulTransducer n takeImpl   where     takeImpl next (Z, acc) a = pure (Done (Z, acc))     takeImpl next (n, acc) a = withState (pred n) &lt;$&gt; next acc a   Again, we can play with this transducer and see how it interacts with the rest of a filtering pipe-line:   transduce (taking 10) (+) 0 [1..100] &gt; 55 : Integer  transduce (filtering even . taking 10) (+) 0 [1..100] &gt; 110 : Integer  transduce (taking 10 . filtering even) (+) 0 [1..100] &gt; 30 : Integer   And plenty more…   We can define plenty more transducers, all inspired from the their equivalent list-based algorithm. Here are some that you can find in the transducer library:      interspersing   dropping   droppingWhile   deduplicating   If you are interested in having a look at their implementation, all these transducers are available in the Idris Transducers.Algorithms module.   Conclusion, and what’s next?   In this post, we went over the creation of stateful transducers in Idris. We defined some helper functions that helped us defined sound transducers and illustrated how they could be used by building our first stateful transducers.   In the next post, we will see how to define stateful transducers that have completion step, such as chunksOf or groupBy. We will also look at some additional helper functions such as into and conj to deal with reductions assembling collections.   The library is available in this GitHub repository. Any suggestions for improvements is obviously welcomed.   ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Idris"],
        "url": "/blog/2017/08/04/idris-transducers-2.html",
        "teaser": null
      },{
        "title": "A study of 4 Money class designs, featuring Martin Fowler, Kent Beck and Ward Cunningham designs.",
        "excerpt":"I started to read the Test Driven Development: by example book (by Kent Beck). It offers a perspective on TDD that is far from being the dogmatic perspective that is taught by some trainers. It is a really good back and I highly encourage you to read it.   But this post is not about TDD. There are plenty of blog posts already available online for this. This post is about the main example used by Kent Beck in this book, the Money class.   In this post, we will look at this Money class implementation and compare it with the other approaches available in the literature, such as the one of Martin Fowler. Through this study, we will:      Discuss the approach provided in PEAA and some related implementation   Unveil the hidden defect behind the implementation of TDD: by example   Provide a different implementation of the same idea which fixes this defect   Show how dependent typing and Idris provide new ways to design the Money class   Our goal is to explore the trade-offs behind each of these 4 approaches. This journey will lead us to discuss about the hole in our mainstream type systems and how dependent typing solves it.   This post features C++, Haskell and Idris. The post is written such that the knowledge of these languages is not a prerequisite, but you will likely learn a bit about these languages. Similarly, the discussion is not exclusive to these languages and is easily generalisable.   Motivation   The Money class is one of these popular class that appears almost everywhere you look. Martin Fowler talks about it in PEAA, it is the main example of Test Driven Development: by example and is often taken as example in a lot of Domain Driven Design talks.   The goal is to design a type that encapsulate an amount together with its currency. We want to provide a safe way to do arithmetic on amounts, and avoid the kind of bug that arise when summing double values with different units (such as EUR and USD) and get angry customers.   Unlike units in the metric system though, the conversion rates are constantly changing and depend on external sources (such as rate curves on the stock exchange). Converting EUR in USD is therefore not as easy as converting kilometres in meters.   Given these constraints, how can we implement a class that represents an amount of money with its currency? Interestingly, the literature provides different solutions on it.   Martin’s Fowler money class   Our first candidate for a Money class is the one proposed by Martin Fowler in his book, Patterns of Enterprise Application Architecture. To keep things short, we will focus on the safe arithmetic part and ignore the allocate part of his design.   How it works   We group a currency and an amount inside the same class / structure. We create methods to add moneys together, multiply them by a constant, and compare them for equality.      Equality is easy: two Money instances are equal if both their amount and currency are equal   Multiplying by a constant is easy: we multiply the amount by the provided constant   Adding Money instances is tricky: we have to deal with the possibility of different currencies   The solution proposed in PEAA by Martin Fowler is to assert that the two currencies are equal inside the implementation of the addition. The literature also contains variations on the same scheme (*).   In short, adding currencies of different currencies is forbidden by the API. It becomes a precondition of calling the add method, and so the client is responsible:      To check that the currencies are equal before calling add   To convert the amounts to the same currency if needed   In this design, the type system will not help the client. Performing these checks in on the client, and forgetting about them will result in a runtime error, hopefully caught at testing time.   (*) For instance, the book Patterns, Principles and Practices of Domain-Driven Design encourages to throw an exception if the currencies are different (instead of an assertion).   Sample implementation   Here is a possible implementation of this Money class design in Haskell.   We start by defining of the data structure Money. It contains two fields, currency and amount, and a default implementation of the == operator:   data Money = Money {    -- Declares a Money class with:   amount   :: Amount,   -- * an amount field   currency :: Currency  -- * a currency field } deriving (Show, Eq)   -- * and equality on all fields   We then write a function to add two Money instances together. If you are not familiar with Haskell, the prototype of the function below says “take two instances of Money and return a Money instance”:   add :: Money -&gt; Money -&gt; Money   We can then complete the definition of the function. The implementation throws an exception when the currencies of the two Money instances m1 and m2 are different:   add :: Money -&gt; Money -&gt; Money add m1 m2 =    if currency m1 != currency m2                   -- If the two currencies are different     then error \"Currencies should be equal\"       -- * Throws an exception     else Money { amount = amount m1 + amount m2   -- * Else return a new Money instance                , currency = currency m1 }         --   which is the sum of the two inputs   For reference, and if you are unfamiliar with Haskell and more accustomed to OOP, the following C++ implementation is the equivalent implementation:   class Money {   Amount m_amount;   Currency m_currency; \t public:   Money(Amount const&amp; amount, Currency const&amp; currency)     : m_amount(amount)     , m_currency(currency)   {} \t\t   friend bool operator==(Money const&amp; lhs, Money const&amp; rhs) = default;   friend bool operator!=(Money const&amp; lhs, Money const&amp; rhs) = default;    Amount amount() const { return m_amount; }   Currency currency() const { return m_currency; } };  Money add(Money const&amp; lhs, Money const&amp; rhs) {   if (lhs.currency() != rhs.currency())     throw std::logic_error(\"Currency should be equal\");   return Money(lhs.amount() + rhs.amount(), lhs.currency()); }   Critical analysis   The pattern is quite simple and allows to group together a value and its currency (its unit). The complete pattern also uses a dedicated Amount type (like a big Decimal, instead of doubles, for better precision). As it stands, this pattern is already quite an improvement over using doubles (without unit) as money amounts (*).   Quite an improvement already, but it is not perfect.   The main critic on this design is the poor declarative nature of the error handling. The type signature of add does not indicate it can fail. The polymorphic nature of the operation is hidden too. As a result, the client of the API is left the burden of the checking the precondition manually, with no help from the type system.   The exception-based implementation can also be criticized for using exceptions to deal with a non-exceptional situation: adding currencies of different currencies is the most common case. It might lead to the client code catching the exceptions to implement its control flow: basically, as glorified gotos.   Overall, this implementation of Money encapsulates some of the concerns associated to the representation of amounts, but lets one concern leaks away: the safety of operations such as add.   (*) Using doubles to represent amounts of money is still unfortunately found pretty much in the wild, especially in legacy applications, in which it becomes really hard to refactor.   Improvements using optionals   We can make the error handling more explicit by making it appear in the type signature of add. We can even force the client code to do a check of validity of the operation.   Nowadays, most languages define an optional type that encodes the presence of absence of something. In C++, this type is called std::optional. In Scala, it is called Option. In Haskell, it is called Maybe.   We can use it to return an optional Money from add:   add :: Money -&gt; Money -&gt; Maybe Money add m1 m2 =    if currency m1 != currency m2             -- If the two currencies are different     then Nothing                            -- * Return an empty result     else Just $ Money {                     -- * Else return a new Money instance           amount = amount m1 + amount m2,   --   which is the sum of the two inputs           currency = currency m1 }   Now, the type signature correctly indicates that add may fail to return a new Money instance. Better yet, the client has to verify the return value and check whether the operation went gracefully or not.   Finally, we now avoid to use exceptions to deal with what is a non-exceptional situation, making it an explicit part of our domain logic.   Still room left for improvement   Despite the improvements we did, the Money class as it stands still has some annoying defects. Our add operation is now asymmetric. It returns an optional Money instance. In some languages such as Haskell, it means we cannot use the operator +.   Another annoying issue is that the checks of validity of the add operations occur after add has been called. It would be more intuitive to force the verification of the precondition before calling the function.   We will see how to address these issues in the last section of this post.   Kent Beck’s money class   We will now look at the different design of the Money class, which comes directly from Test Driven Development: by example (written by Kent Beck). This design takes a rather different stance than the previous design: instead of forbidding cross-currency addition, it embraces it.   How it works   The simple yet powerful idea (*) that lies behind the design exposed by Kent Beck is to separate the specification of the addition from its evaluation. Adding money instance with different currencies does not sum them immediately: it builds an expression that represents the sum.   Building something that represents the sum is in fact the only reasonable way to proceed. Indeed, adding the two amounts eagerly by forcing a currency conversion would be terrible:      We would have to arbitrarily choose a currency to convert into   We would have to arbitrarily choose a rate curve (on which a market?) to get the rates   We would introduce a side-effect is what looks to be a pure computation   It would destroy information: 3 EUR + 5 USD is a different information than 9.15 USD (**)   Instead, in the design of Kent Beck, adding two amounts results in building an expression that represents the sum of the two amounts. For instance, adding 3 EUR and 5 USD results in the following abstract syntax tree (AST):        (+)     /   \\ 3 EUR   5 USD   To evaluate the AST in any destination currency we want, we build an evaluator that needs to have access to a source of data that provides the conversion rates between the different currencies involved. The evaluation is decoupled from the specification. So much decoupled in fact, that it can be performed later, or never, or even several times, with different rate curves, etc.   (*) Often, truly powerful ideas are simple in their very essence as they touch to the core of the concepts we try to model.   (**) Summing the amounts early has for effect to collapse the information at a given point in time. Delaying the addition keeps the information independent of time, allowing several evaluations at different points in time.   Implementation (AST)   Our Haskell implementation will distinguish between two notions:      Money expression: an un-realized abstract syntax tree (MoneyExpr in the code)   Money: a known amount with a known currency, the result of the evaluation of a MoneyExpr   We will keep our Money data structure from the previous implementation:   data Money = Money {    -- Declares a Money class with:   amount   :: Amount,   -- * an amount field   currency :: Currency  -- * a currency field } deriving (Show, Eq)   -- * and equality on all fields   We then create a MoneyExpr type for a money expression, which defines our AST. For those unfamiliar with Haskell, the pipe operator | represents a disjunction (OR). The code below says that a MoneyExpr is either an known amount KnownAmount, or an addition of several sub-expression MoneyAdd or a multiplication of a sub-expression MoneyMult.   data MoneyExpr                  -- An Money expression made of EITHER:   = KnownAmount Money           -- * A known amount and currency (base case)   | MoneyAdd [MoneyExpr]        -- * A sum of several money expression   | MoneyMul MoneyExpr Double   -- * A money expression multiplied by a factor   deriving (Show, Eq)   We then implement our function such that they build the AST instead of directly computing sums and products:      Adding will create a new MoneyAdd node.   Multiplying by a constant will create a MoneyMult node.   -- Given these expressions let a = money 30 \"USD\" let b = money 25 \"EUR\" let c = money 1000 \"JPY\"  -- Add the different currencies add (add a (multiply b 2)) c  -- It returns the following AST: MoneyAdd   [ MoneyAdd     [ KnownAmount (Money {amount = 30.0, currency = \"USD\"})     , MoneyMul (KnownAmount (Money {amount = 25.0, currency = \"EUR\"})) 2.0]   , KnownAmount (Money {amount = 1000.0, currency = \"JPY\"})]   Graphically, the resulting AST of the code above would look like this:            (+)         /   \\       (+)   1000 JPY      /   \\ 30 USD   (*2)           |         25 EUR   The only missing piece now is the evaluator.   Evaluator implementation   The MoneyExpr represents a sum of money amounts expressed in different currencies. At some point though, the client code will be interested in converting all the amounts in a target currency (for instance to compare it with another amount in this currency). This is the job of the evaluator.   The evaluator will need a way to access conversion rates from a source of data (such as a rate curve on a given market). We can abstract this behind a function that returns a rates from a currency conversion:   -- Abstracts the access to a source of data which provides -- the rate associated to a conversion between 2 currencies Conversion -&gt; Maybe Rate   The evaluator will also need as input the money expression to evaluate and the target currency to convert into. This gives us the following prototype for our evaluator, which we name of evalMoneyIn:   evalMoneyIn ::                -- Evaluate an Money expression   (Conversion -&gt; Maybe Rate)  -- * Given a way to retrieve a rate   -&gt; MoneyExpr                -- * A money expression to evaluate   -&gt; Currency                 -- * And a destination currency   -&gt; Maybe Money              -- Returns a known amount (or fails)   Here is how the function can be used, where findRate represents the function that gives access to the rates, and moneyExpr is a money expression:   -- Successful evaluation evalMoneyIn findRate moneyExpr \"USD\" &gt; Just (Money {amount = 100.0, currency = \"USD\"})  -- Failing evaluation evalMoneyIn findRate moneyExpr \"USD\" &gt; Nothing   The implementation details of the evaluator would require going into some Haskell core abstractions, and is outside the scope of this post, but is provided as reference in this GitHub Gist.   Critics   It is important to notice that this design encapsulates more concerns than the previous design did. It handles cross currency addition and also handles the conversions between currencies in a declarative way.   As a functional programming enthusiast and a Lisp lover, this design has a lot of appeal for me. If you ever implemented a small Lisp interpreter, I bet you like this design as much as I do.   Unfortunately, this design is flawed. The equality operator is broken. Depending on the way you assemble the expressions, two equivalent expressions may have very different AST:   let x = add (add a (multiply b 2)) c  -- (a + b * 2) + c  let y = add a (add (multiply b 2) c)  -- a + (b * 2 + c)  x == y                                -- Testing equality &gt; False                               -- Not what we expect   Graphically, these two equivalent expression will have the following AST:            (+)                     (+)         /   \\                   /   \\       (+)   1000 JPY       30 USD   (+)      /   \\                         /   \\ 30 USD   (*2)                    (*2)  1000 JPY           |                       |         25 EUR                  25 EUR   The problem with this implementation is that it keeps too much information about the initial expression. So much that it becomes sensible to factors such as operator precedence. We will fix this in the next section.   Fixing the Money expression   Separating the specification from the evaluation of an addition of Money allowed us to support cross-currency addition, quite an interesting feature. But our previous implementation is broken with regards to equality. In this section, we will fix this defect, and go back to the old idea of Money Bag from Ward Cunningham.   How it works   This implementation keeps the Kent Beck’s design we presented in the previous section. We keep the decoupling between the specification of an addition and its evaluation. We keep the evaluator.   The only difference is the data representation of a money expression. We drop the AST (which captured too much information as we have seen) and use an associative container (a map) instead. This map associates each currency to its corresponding amount.   Now, adding money expressions is a simple matter of merging their associated map. And multiplying a money expression consists in multiplying the amount of each currency.   Use associative contains correctly fixes our previous defect with equality: two money expressions are equal if their keys are the same and if each keys is associated to the same value.   Implementation   The API remains mostly unchanged. The implementation details are quite different though. We will look at the main changes.   First, we drop the AST in favor of a map. We also rename the Money expression into MoneyBag, in honor of Ward Cunningham, but also because it is closer to what it now is:   newtype MoneyBag                    -- A Money Bag is a wrapper around   = MoneyBag (Map Currency Amount)  -- * A map from currency to amount   deriving (Show, Eq)               -- Equality is automatically generated   Adding two money bags is implemented as the union of two maps:   add :: MoneyBag -&gt; MoneyBag -&gt; MoneyBag add (MoneyBag m1) (MoneyBag m2) = MoneyBag (unionWith (+) m1 m2)   Multiplying a money bag with a constant consists in mapping over each amount:   multiply :: MoneyBag -&gt; Double -&gt; MoneyBag multiply (MoneyBag m) f = MoneyBag (fmap (* f) m)   The evaluator is quite simple too (3 lines of code). It consists in collapsing the map into a one that only contains a single currency key, the one we want to convert too. Again, this is outside the scope of this post, but the implementation is nevertheless provided as reference in this GitHub Gist.   Critics   This design has basically the same advantages than the Kent Beck’s design. It also handles cross currency addition and handles the conversions between currencies in a declarative way.   But now it works with equality. It also offers a more compact data representation in most cases (same currencies are collapsed). The only drawback is that multiplication has to scan over all the currencies (*).   Compared to the Martin Fowler’s design, it remains heavier. It consumes more memory and more CPU, at the price of managing addition in a truly encapsulated way. This is a trade-off.   (*) This could be fixed by adding the factor as a separate field, delaying its application until the very moment it is needed (evaluation time and merging of money bags)   Improving on Martin Fowler’s Money class with Idris   In the original Money class design of Martin Fowler, the client code is expected to check that both amounts have the same currency before calling add on them.   The main problem in this design is that the type system does not offer any help. It does not enforce this constraint and failing to check the precondition is not caught at compile time. The probability of error is high and the client is left without support.   Let us see how Idris and its dependent typing feature might help us provide a type safe version of the Martin Fowler’s Money class, such that failing to check the precondition will not compile.   The hole in our type systems   The type system of most mainstream languages is unable to express relations and constraints between several arguments of a function. Even in Haskell, it is hard to express a precondition that involves several arguments with a type, such that the compiler might verify it for us.   Idris is not bound to the same limitation. Its type system allows to build types that express relations between several values, or several arguments of the same function. For instance, we can write a type that represents the fact that two money instances have the same currency.   Put differently, we can express preconditions on our functions as types, allowing the compiler to verify for us that these preconditions are satisfied before calling the function.   Translating Haskell to Idris   Let us go back to our initial implementation of add in Haskell and translate it into Idris. Idris being pretty close to Haskell syntax, this is a rather simple task:   record Money where      -- Definition of Money   constructor MkMoney   -- * With a constructor named MkMoney   currency : Currency   -- * Containing a currency   amount : Amount       -- * And an amount of money  -- Definition of `add` which takes 2 Money instances and returns a new one add : (m1, m2 : Money) -&gt; Money add m1 m2 = MkMoney (currency m1) (amount m1 + amount m2)   For now, this implementation is incorrect if the two money instances we try to sum together, m1 and m2, have different currencies. Indeed, the new Money instance is constructed from the currency of m1 and we have no assert to ensure both money arguments have the same currency.   Preconditions as types   To fix this, we can enrich the prototype of the function add to ask for a proof (the argument prf below) that the money arguments have the same currency:   add :   (m1, m2 : Money)                    -- Arguments of the function: 2 Money instances   -&gt; {auto prf : SameCurrency m1 m2}  -- Proof that m1 and m2 have the same currency   -&gt; Money                            -- Return type: a new Money instance   In this function prototype, SameCurrency m1 m2 is a type which represents a constraint between the arguments m1 and m2 of the function. And in Idris, we can effectively build this type such that being able to instantiate this type is equivalent to proving that the constraint is satisfied (*).   The auto keyword tells Idris to look for implicit proofs in the neighborhood of the function. Thanks to this, the following code will compile just fine, and does not require us to provide a proof of its correctness:   -- Compile just fine: same currencies add (MkMoney \"EUR\" 1) (MkMoney \"EUR\" 2)   The following code will correctly be rejected at compile time, Idris being unable to find a proof that the two currencies “EUR” and “USD” are equal:   -- Does not compile: different currencies add (MkMoney \"EUR\" 1) (MkMoney \"USD\" 2)   It is important to observe the distinguishing characteristic of Idris there: a type can refer to the other arguments that appear in the prototype of a function.   (*) Note: you can refer to my previous article on building a type safe Bowling Kata for more detailed information on how to write proofs in Idris.   Runtime checks   In our previous examples, Idris is able to find an implicit proof that two currencies are either equal or not equal by looking at their values at compile time. For values that are only known at runtime though, Idris cannot do miracles.   We have to provide in our API a function to construct a proof that two money instances known at runtime satisfy the precondition on their currency:   sameCurrency :                  -- Predicate function   (m1, m2 : Money)              -- * Taking two instances of Money   -&gt; Dec (SameCurrency m1 m2)   -- Returning a proof or a contradiction   We will not go in details into what Dec means here, but you can think of it as something that either returns “Yes and here is the proof” or “No, and here is a contradiction”. The implementation of this function is outside the scope of this post, but is provided as reference in this GitHub Gist.   What matters is that the client code is now forced to call sameCurrency before being able to call add on runtime values. In fact, the it will only be able to call add if sameCurrency returns YES. Indeed, add requires a SameCurrency m1 m2 instance to be available in its environment of evaluation. This is only possible if either:      Idris can find an implicit proof that it holds (for values known at compile time)   The proof is constructed successfully by sameCurrency (upon returning YES)   This sounds like magic, but this is no fairy tale. Type systems such as the one of Idris allow to ensure that our if statements are correct at compile time.   Critics   This last design shares some important characteristics with the one proposed by Martin Fowler in PEAA. It is lightweight, and does not support adding amounts with different currencies. It basically shares the same pros and cons as the one from Martin Fowler.   The main difference is type-safety: the client code is now ensured to do the appropriate precondition checks before adding amounts. Failing to do the appropriate checks will result in a compilation error.   Conclusion   The design space of a common class such as Money is surprisingly large. There does not seem to be a single best answer for all situations.   Depending on the required capabilities, such as being able to sum amounts of different currencies, an the performance constraints, it might be more advantageous to chose either the Money or the MoneyBag implementation.   As an opening, we also saw how new type systems with a support for dependent typing, such as the one of Idris, can offer yet more design choices and more compile time guarantees.   EDIT: I published a new blog post to explain why lifting currencies as type parameters of the Money class would not bring the same benefits as the Idris solution here.  ","categories": ["software-design"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/08/17/money-class-design.html",
        "teaser": null
      },{
        "title": "Money class design: why not having currencies as type parameters?",
        "excerpt":"In the previous post, we went through a comparative study of 4 different designs for a Money class that represents an amount of money in a given currency. This article received a quite positive review, and also a lot of comments and remarks.   One of the most recurring remark was: why not encode the currencies as types parameters of the Money class? If we do so, the currencies will be visible in the type system and should allow us to implement safe arithmetic.   This is a fair and interesting remark, especially since it appears to be such a good design solution at first sight.   In this post, we will first present the solution in details, before explaining why it is not really a viable option for the Money class. We will conclude this post with some words of advice regarding using strong types, and not using them.   Summary of the last episode   We first start with a quick recap on the 4 different designs we evaluated so far.   Two broad category of designs   In the previous post, we went trough two broad categories of design for the Money class.      Martin Fowler’s design was about forbidding cross-currency addition with an assertion   Kent Beck and Ward Cunningham designs implemented a sound cross currency addition   In short, we could either choose to support the addition of money amounts in different currencies, or to forbid it.   Martin Fowler’s approach   The design of Martin Fowler relies on adding a runtime check (an assertion) to forbid cross-currency money addition. In this design, it is invalid to call add on two amounts with different currencies, and the client of the API is responsible for ensuring these preconditions are fulfilled.   The only problem with this solution is that the client of the API might forget to do those checks. If so, the assertion will catch the violation at runtime and not at compile time, hopefully before production.   Type safe preconditions with Idris   Using Idris, we then improved the design proposed by Martin Fowler to make it more type-safe. We made sure at compile time that the add function could only be called in the conditional branches for which the runtime checks of the precondition were done and returned a positive answer.   case sameCurrency m1 m2 of  -- Forced to call the predicate   Yes _ =&gt; add m1 m1        -- Can only call `add` in this branch   No _  =&gt; ...              -- Cannot call `add` in this branch   It is important to understand that this last solution is not about ensuring that the structure of the code is correct. It is about ensuring that the runtime checks are always called correctly before calling add. It is not about ensuring that the two currencies are the same at compile time (it cannot be done if values are created dynamically).   Currencies as type parameters   Now, let us have a look at the proposal that consists in lifting the currencies as type parameters of the Money class. We will first implement it in this section. The next section will then explain why it does not make for a great design.   Motivation   The motivation behind this design is to answer the same concern than the Idris design. The goal is to improve on Martin Fowler’s design to make it more type-safe. The goal is to forbid cross-currency addition and to catch violation of that rule at compile time.   To achieve that, the proposed solution is to parametize the Money class with a currency. The currency becomes a type parameter of the Money class, such that we can play with it in the type system.   This solution was proposed by different persons (and in different languages) such as @MinskAD, u/bstempi or u/zokier. The implementation showed below is greatly inspired from these comments, and especially the one of u/zokier in this reddit post (and the Gist associated to it).   How it works   The solution consists in encoding the currency as a type parameter of the Money class, invisible in the runtime representation of the class, a technique reminiscent of Phantom types in Haskell.   Here is a (simplistic) implementation that illustrates this design, where Currency is a type, and Money is templated on a value of that type:   template&lt;Currency MoneyCurrency&gt; class Money { public:    Money() : m_amount(Amount{}) {}    explicit Money(Amount amount) : m_amount(amount) {}    Amount amount() const { return m_amount; }  private:    Amount m_amount; };   Now that the currency appears as a type parameter, we can exploit it in the C++ type system and write an add function that it only works for two Moneys templated on the same currency:   template&lt;Currency SameCurrency&gt; Money&lt;SameCurrency&gt; operator+ (Money&lt;SameCurrency&gt; const&amp; lhs, Money&lt;SameCurrency&gt; const&amp; rhs) {    return Money&lt;SameCurrency&gt;{lhs.amount() + rhs.amount()}; }   This solves the problem for add. Money instances with the same currencies can be added normally, while trying to add Money instance with different currencies will fail to compile:   auto eur = Money&lt;Currency::EUR&gt;{3}; auto usd = Money&lt;Currency::USD&gt;{5}; \t // Compiles files auto sum_eur = eur + eur;  // Does not compile auto invalid = eur + usd;   It looks like the problem is solved. But by doing so, this solution creates tons of other problems, as we will see in the next section.   Down the rabbit hole   To notice the problems that arise with the above design, we need to look at how this class would integrate with the rest of the software. Looking at it in isolation is not enough: we will need to gradually add some more code around this class.   Support for equality   Let us first add the support for equality. The original implementation provided by u/zokier in his proposal is limited to equality checks between amounts with the same currency.   We can remove this limitation by playing with pattern matching on the currency type parameter of the Money class. We can make sure that comparing Money instances with different currencies always returns false, and otherwise correctly compares the amounts:   template&lt;Currency SameCurrency&gt; bool operator==(Money&lt;SameCurrency&gt; lhs, Money&lt;SameCurrency&gt; rhs) {   return lhs.amount() == rhs.amount(); }  template&lt;Currency LeftCurrency, Currency RightCurrency&gt; bool operator==(Money&lt;LeftCurrency&gt; lhs, Money&lt;RightCurrency&gt; rhs) {   return false; }   It works because the most specialized overload will be preferred to the most general one. Now, our equality operator works across moneys amounts in different currencies:   // Returns false: different currencies Money&lt;Currency::EUR&gt;{3} == Money&lt;Currency::USD&gt;{3};  // Returns true: same currency and same amount Money&lt;Currency::EUR&gt;{3} == Money&lt;Currency::EUR&gt;{3};  // Returns false: same currency but different amount Money&lt;Currency::EUR&gt;{3} == Money&lt;Currency::EUR&gt;{5};   So with a bit of pattern matching on types, we managed to implement equality on Money amount in any currency. It was not hard, but it shows a first sign of why this design is not that great.   What just happened   By lifting currencies from values to type parameters, we split the concept of Money into several types, one for each currency. When implementing equality, we discovered that some operations do operate on Money amounts with different currencies. This should be a warning sign.   If it so happens that most operations on Money do not require different types for different currencies (like equality), our new design would substantially increase accidental complexity: the special case of add and made it every other money operation’s concern.   For now, this is not that bad. We managed to circumvent this split in different types using a simple form of template meta-programming to implement our business logic. This came at the cost of just a bit of verbosity and additional complexity. But we might not be that lucky for other use cases.   Storage becomes an issue   Containers such as std::vector cannot store values of different types. This means that an std::vector will not be able to contain Money amounts expressed in different currencies.   std::vector&lt;Money&lt;Currency::USD&gt;&gt; usds;  // Compiles fine usds.push_back(Money&lt;Currency::USD&gt;{5});  // Does not compile usds.push_back(Money&lt;Currency::EUR&gt;{3});   This is a real big damn huge problem. Storing moneys with different currencies in a single container is a real need. We might for instance be interested in representing positions in a portfolio, or just represent a wallet.   This time, solving this problem is not that easy. Simple meta-programming tricks will not do. We could turn to boost::hana and its heterogenous containers. It is a great library, but is arguably a bit too complex for such a simple use case.   The other solution would be to do some type erasure, but this would defeat the purpose of lifting the currencies as type parameters. We would lose both information and type-safety.   Algorithms are out of reach   Because we cannot easily store Money instances with different currencies together in the same container, we cannot easily run algorithms on them either.   With currencies as type parameters, and as many Money types as there are currencies, answering the following needs is getting much more difficult:      Counting how many currencies appear in a collection of Money.   Summing the amounts of a collection of Money, by currencies.   Again, we could turn to boost::hana which has a nice collection of algorithms on heterogenous sequences. But again, this looks a bit overkill.   Types are contagious!   The problem is that this design choice is contagious. It affects any part of the program which uses the Money class. There is no such thing as encapsulation of types (*). Any client code will see the currency as type parameter. Any client code is coupled to this design decision.   For instance, let us say we want a type to represent a Foreign Exchange Spot, an exchange between two currencies at a given spot date. We are forced to parameterise our class on the two currencies:   template&lt;Currency BuyCurrency, Currency SellCurrency&gt; class foreign_exchange_spot {    Date m_spot;    Money&lt;BuyCurrency&gt; m_buy;    Money&lt;SellCurrency&gt; m_sell; \t    // ... construtor, operations ... };   The design of this new class is terrible on many aspects.   From a technical standpoint, instead of having one currency type parameter, we have two. The number of types the compiler will need to instantiate will grow as the square of the number of currencies. More complex financial products will require even more.   From a business logic standpoint, this is problematic as well. This kind of deal is fungible: we expect to store it in numbers and compress multiple instances of it into positions. Satisfying these needs is only made harder by the strong typing.   (*) Actually there is. Sub-typing would buy us type erasure, but it would defeat the purpose of this design altogether. If we feel constraint to use type erasure, why not just drop this design entirely instead?   Conclusion   Types are great tool at ensuring invariants in a program. But they are not the tools for all kinds of invariants. For instance, lifting the currencies as type parameters of the Money class gives us a design much too rigid and far to cumbersome to deal with.   It might not look as interesting as first sight, but encountering a scenario in which a technique failed can actually teach us more than all the success stories on the same technique. Let us review some of the things we saw.   Types have drawbacks   We have seen a pretty extreme example of the kind of problem that static typing can cause if used excessively. Although in general it does not lead to that much horror, it is often a good idea to assess to the cost and benefits of introducing a type (as with any other technique, it is almost never free).   Types represents a pretty strong form of coupling, whereby we force a client to comply with strict rules to interact with our code. This might be the desired effect. This might be justified. But it is not always a winning trade-off.   Be sure to verify that the cost of adding type safety does not exceed the benefits.   Type safety VS flexibility   Other technics exist which offer different kinds of trade-offs, such as reduced type-safety. These technics have their pros and cons too, but should not be sacrificed at the altar of type-safety.   Technical limitations of the language might left us with a choice between practical software versus type-safety. Dropping type-safety might be the reasonable choice in some instance.   In our specific case, the design of Martin Fowler, although it is not as type safe, is a much better alternative compared to lifting currencies as type parameters of the Money class. The class is much less cumbersome to deal with, and the resulting software is much more flexible.   It all boils down to where we put the cursor of type safety. Too much of it, at the wrong spot, and the software turns rigid. Too little of it, and flexibility increases marginally at the cost of safety.   The best of both worlds with dependent typing?   The alternative to compile time checks are runtime checks. In mainstream type systems, these runtimes checks comes at the cost of type-safety. This is due to value and types living in two separate universes.   Languages with support for dependent typing (like Idris) are able to breach the gap between values and types and provide increased type-safety while avoiding a lot of the coupling costs associated to strong typing.   We will explore more this topic in future posts.  ","categories": ["software-design"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/08/22/money-class-design-2.html",
        "teaser": null
      },{
        "title": "List Monad connection with Non-deterministic Polynomial time complexity",
        "excerpt":"A problem is in NP (Non-deterministic Polynomial time complexity) if it can be solved by an algorithm that runs in polynomial time on a non-deterministic Turing Machine, a computer that can “guess” which path to take toward the right answer when given a choice.   I never quite built a good intuition on what it means. What does it mean to guess? If such a powerful computer could guess, why could it not guess the right answer to the problem right from the start? Why would it have to go through a polynomial number of steps?   This short post will show connect the List Monad with non-deterministic Turing machines, to build some intuition on NP, how a non-deterministic Turing machine behaves, and it would feel to program one such computer, thanks to Haskell.   Motivation   I recently found this great video from Erik Demaine, a short but quite entertaining overview of P, NP and NP-completeness complexity classes.   At 8 minutes 50 seconds in the video, he explains why the Boolean Satisfiability Problem (SAT) is in NP. Here is the content for his board after the explanation:   guess: x1 = True or False guess: x2 = True or False ... guess: xN = True or False check if formula on (x1, x2 ... xN) is True or False   Now, if you know about the List Monad, you should see it right there, in front of you. This insight might give you an idea of what “a non-deterministic computer guess” could be. If not, this post might be of interest to you.   Non-deterministic computation = List Monad   A lot of Monad tutorials start with the Maybe and List monads. Most good tutorials will also mention that the List Monad models non-deterministic computations. It sounds like it must somehow be connected to the NP non-deterministic Turing machine. Let us see how.   I see a Monad in your SAT proof   To understand the similarities between the board of Erik Demaine and the List Monad, let us translate the SAT NP proof from Erik Demaine into Haskell code. Thanks to the List monad, the translation is pretty simple.   Here is the original board he wrote:   guess: x1 = True or False guess: x2 = True or False ... guess: xN = True or False check if formula on (x1, x2 ... xN) is True or False   Below is our Haskell version. We added a function name, introduced an or to stop at the first result, but mostly, our task was to replace occurrences of “guess” by the bind &lt;- operator:   satExample :: Bool satExample = or $ do   x1 &lt;- [True, False] -- \"guess\" is replaced by bind (&lt;-)   x2 &lt;- [True, False]   {- ... -}   xN &lt;- [True, False]   pure (formula x1 x2 {- ... -} xN)   So our List Monad bind operator is analog to the “guess” of a non-deterministic Turing Machine.   Back to List Monad tutorial   Now that we have seen the similarities, let us look for an online Monad tutorial and check the definition it provides for non-deterministic computation. If we pick this one from FP complete, we can read:    [..] non-deterministic computation. It’s the kind of computation that, instead of producing a single result, might produce many.  The connection with the definition of NP is not direct, but pretty close. A non-deterministic computation returns several results.   A non-deterministic Turing Machine is able to magically pick a “good” result among theses results, by guessing which one will lead to one “yes” outcome (there might be many).   From exponential to non-deterministic polynomial complexity   Let us go back to our translation of the SAT NP proof in Haskell:   satExample :: Bool satExample = or $ do   x1 &lt;- [True, False] -- \"guess\" is replaced by bind (&lt;-)   x2 &lt;- [True, False]   {- ... -}   xN &lt;- [True, False]   pure (formula x1 x2 {- ... -} xN)   Executed on a conventional computer, this function will explore the search space of all potential variable assignments for x1, x2 up to xN, and stop at the first one for which the formula returns a positive answer. This code has therefore an exponential time complexity.   But on a non-deterministic computer, each guess can be performed in constant time. And these guesses correspond to the bind operator of the List Monad. So, provided formula runs in linear time, the non-deterministic complexity of our satExample algorithm is linear.   Estimating the non-determistic complexity of an algorithm   Generalising to all decision problems (problems whose answer is either True or False) and to non deterministic computations, we can reason that:   Given a non-deterministic computation f occurring inside the decision problem D, and returning a set of result R, a non-deterministic Turing machine is able to pick a value from R which leads to a “yes” answer for D (if it exists) in constant time.   In the List Monad, the non-deterministic algorithmic complexity of the statement y &lt;- f x is therefore equal to the non-deterministic algorithmic complexity of f, however many results f may return.   This gives us a way to estimate the non-deterministic complexity of an algorithm: we refactor the algorithm in Haskell in such as way that the List Monad bind operators becomes visible. Then we derive its complexity, by counting each bind operator as constant time assignments: O(1).   We can do this for SAT, as well as any other algorithm. Take your favorite search-like algorithm, write it using the List Monad, then you can visually estimate its complexity on an fantasized non-deterministic Turing machine of the future. I am not sure it is terribly useful, but hey, it is still fun.   Example of SAT   Let us look at the code of a complete (and completely naive!) SAT solver (*). Our solver takes as input an instance of a SAT problem pb, and returns if there exists an assignment of the variables that makes the formula True.   Our implementation has been refactored to make each bind operator of the List Monad visible:   sat :: SAT -&gt; Bool sat pb = or $ do   assignment &lt;- forM (allVars pb) $ \\var -&gt; do     val &lt;- [True, False]     pure (var, val)   pure (evalSat assignment pb)      allVars extract all the variables from the SAT instance (normalised as a conjunction of disjunction)   evalSat checks if the SAT instance is verified for a given assignment of the variables   Assuming the algorithmic complexity of allVars and evalSat are linear, and counting each bind operation as O(1) assignments, we can clearly see that the non-deterministic complexity of the sat algorithm is linear as well (there is a linear number of calls to bind).   The full code for this naive SAT evaluator is available at the end of the post.   (*): A real SAT solver would explore the search space by cutting branches early. It would use a clever ordering for the variable assignment, would use constant propagation to identify dead-end as soon as possible, as well as other clever tricks such as unit propagation.   The goal of all these tricks is to reduce the exponential exploration space. Interestingly, if we could ever have a non-deterministic Turing machine, we would not need such tricks. In fact, they would only slow down the algorithm.   Conclusion   The expressivity of Haskell and it’s do-notation gives us the ability to express different types of computations. Thanks to this, we can use Haskell to experience how programming would look like in a different world, in which we had a different kind of hardware to run our software.   Thanks to this, we can better understand how computation would work on a non-deterministic Turing machine from our home, and therefore understand NP complexity better.   Full code of SAT evaluator   module SAT where  import Control.Monad import qualified Data.Map as Map import qualified Data.Set as Set   type Var = String type Assignment = [(Var, Bool)]  data Term   = Pos { getVar :: String }   | Neg { getVar :: String }  newtype SAT = SAT { conjunctions ::  [[Term]]}  sat :: SAT -&gt; Maybe Assignment sat pb = headSafe $ do   assignment &lt;- forM (allVars pb) $ \\var -&gt; do     val &lt;- [True, False]     pure (var, val)   guard (evalSat assignment pb)   pure assignment  allVars :: SAT -&gt; [Var] allVars = Set.toList . Set.fromList . map getVar . concat . conjunctions  evalSat :: Assignment -&gt; SAT -&gt; Bool evalSat assignment =   let env = Map.fromList assignment   in and . map (any (evalTerm env)) . conjunctions  evalTerm :: Map.Map Var Bool -&gt; Term -&gt; Bool evalTerm env (Pos var) = env Map.! var evalTerm env (Neg var) = not (env Map.! var)  ------------------------------------------------------------  headSafe :: [a] -&gt; Maybe a headSafe [] = Nothing headSafe xs = Just (head xs)  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/09/04/list-monad-np-complexity.html",
        "teaser": null
      },{
        "title": "Monoids: what they are, why they are useful, and what they teach us about software",
        "excerpt":"Monoids are a pretty interesting concept in software development. Monoids are everywhere. Monoids are simple yet powerful. And Monoids have a lot to teach us about software, in particular about composition and building powerful abstraction.   This post will take you through a small tour of what Monoids are and are for.   We will first define what Monoids are and show some first examples. We will then discuss the benefits they can bring to your code, and illustrate it through a more involved example. As closing thoughts, we will step back and think about what Monoids can teach us about programming in general.   Disclaimer: Starting from the second part, we will use Haskell and C++ for our examples, but this post is written such that the knowledge of these languages is not strictly required to follow it.   What is a Monoid?   We here review the basics of Monoids, by going through the formal definition and some classic examples. You are encouraged to skip this section if you are already familiar with Monoids.   Definition (formal)   A Monoid can be defined as a tuple $(M, op, e)$ where:      $M$ is a set of element   $op$ is an associative binary operation on two elements of M, returning a new element of M   $e$ is an element of $M$, neutral for op on both left and right side   Depending on the field of Math considered, Monoids have several definitions. This one is not the most general one, but will do for the rest of this post.   Definition (statically typed languages)   In a statically typed language, we can translate the notion of set into the notion of type. A Monoid consists of a type T and a function f obeying the following rules:      f takes two instances of T and returns a new instance of T   f is associative: $\\forall a, b, c$ we have $f(f(a, b), c) = f(a, f(b, c))$   f has a neutral element e: $\\forall a, f(e, a) = a = f(a, e)$   Some language like Haskell have an explicit interface for Monoids which a type can implement. Beware though that in general the same type T can participate in several Monoids.   Classical examples   I listed below some of the very classic and general examples. Almost all of them are pretty easy to identify and are documented in many online resources:      Integers form a Monoid under addition with the neutral element zero   Integers form a Monoid under multiplication with the neutral element one   Sequential containers form a Monoid under concatenation (strings, vectors…)   Associative containers form a Monoid under union (maps, sets…)   You can find a bunch more listed in this Wikipedia page dedicated to Monoids.   Monoids are everywhere   Here are some less classic examples, which I listed below to show that Monoids can be found in many different domains, and in many successful libraries:      C++ range-v3 form a Monoid under view::concat with the empty range as neutral element (*)   Money amounts define a Monoid under summation with the null amount as neutral element   Relative paths in a file system form a Monoid under appending   Access rights to files form a Monoid under intersection or union of rights   All of these examples are pretty close to the classic ones. Access rights are related to sets, ranges are related to sequential containers, money amounts are related to numbers (or to associative containers).   So an easy way to identify and recognise Monoids in your own code is simply to look at how the concept of your domain relate to the usual suspects.   (*) ERRATUM: range-v3 view::concat does not strictly speaking defines a Monoid: although we can view them as Monoids from a conceptual standpoint, the types do not align. Thank you Eric Niebler for pointing out that error.   Why Monoids are useful   Monoids are a great way to build complex behaviour out of simple elements, without having to introduce new concepts in your software. This section will explain why. The next section will illustrate it with code.   The closure gives composition free of intellectual charge   Because the binary operation of a Monoid takes two values of a given type and returns a new value of the same type (closure property), this operation can be chained indefinitely.      We can compose simple elements into composite elements   These composite elements can be composed further, just as simple elements can   Since we stay in the same world, this process can continue for ever   In addition to this, and because we are only dealing with one type, we get composition for free: we do not have to introduce new types, and therefore new concepts in our code.   A Monoid gives us a way to build complexity out of simplicity, with no conceptual cost added.   Associativity gives abstraction over construction details   Let us imagine for a moment that the binary operation was not associative:      The outcome of combining several elements together would depend on the order in which we combine them (the more elements we have, the larger the number of outcomes)   So to get a desired outcome, we would have to care about this composition order, all the way down to the simplest elements we combine together   We would therefore have to distinguish primitive elements (not built by combination) from composite ones, and care about how many combination took place   In short, we would have to know all about the details of construction of a value. Instead, associativity abstracts away the details of construction. Given a value, we do not have to care how it was built, and whether it is a composite or not. We might not be even able to tell (*).   This abstraction has additional benefits as well: we can split work of constructing a value to different parts of the software, or to different threads even.   (*) In fact, we must not be able to tell or the abstraction is broken. Associativity requires this kind of information to be erased. This is the point of an abstraction: getting rid of unimportant details.   A more involved example of Monoid   We will now illustrate how Monoids abstract away the details of creation of a value, to help us build powerful abstractions. To do so, we will create a small library to represent shapes in any number of dimensions.   We will give the examples in Haskell first, and translate them in C++ at the end of each section.   Abstract definition of a shape   In the context of this example, we will define a shape as being a region of space, with an arbitrary number of dimension. For instance, a disk is a region of a 2D space. It contains all the points at a distance from the centre of the disk lower or equal than the radius.   Our goal is to write a small library to define and combine such shapes together into arbitrarily complex shapes. To do so, and in order to be agnostic to sampling issues, we will use an idea I first read about from Conal Elliott. We will represent shapes as functions from coordinates to a boolean, whose value indicates whether the point is part of the shape. A simple and beautiful idea.   Shapes and coordinates   To define a shape in code, we will define a Shape type which wraps a function from a coordinate (any kind of coordinate, so we use a template parameter) to a boolean:   newtype Shape coord = Shape {  -- A shape templated on any type of coordinate   isInShape :: coord -&gt; Bool   -- Contains a function from a coordinate to a boolean }   To define a shape in 2D, we define a type alias for coordinates in two dimensions. We then define a 2-dimentional shape as a type alias on a shape templated on a 2D coordinate:   type Coord2D = (Double, Double) type Shape2D = Shape Coord2D   Viewing shapes as function is a pretty interesting model. Thanks to it, we can for instance pretty easily define the complement of a shape. This new shape is such that it contains all the points that were not in the previous shape (and does not include any of the points of the previous shape).   We call the function which computes this complement outside. It simply negates the predicate of the input shape (note that this works in any number of dimensions, with any coordinate system):   outside :: Shape coord -&gt; Shape coord outside s = Shape (not . isInShape s)   Here is the equivalent code (up to the strong typing) in C++:   template&lt;class Coordinate&gt; using Shape = std::function&lt;bool (Coordinate const&amp;)&gt;;  using Coord2D = std::pair&lt;double, double&gt;; using Shape2D = Shape&lt;Coord2D&gt;;  template&lt;class Coordinate&gt; Shape&lt;Coordinate&gt; outside(Shape&lt;Coordinate&gt; const&amp; s) {   return [=](Coordinate const&amp; coord) {     return not s(coord);   }; }   Example of shapes   To define a shape, we only need to define a function which returns whether a coordinate is inside the shape or not. Here is how we would define a disk:   disk :: Coord2D -&gt; Radius -&gt; Shape2D disk center radius =   Shape $ \\coord -&gt; euclidianDistance center coord &lt;= radius      The disk function returns a shape that wraps a lambda function   The lambda takes a coordinates and returns whether it is in the disk   To do so, it computes the euclidian distance of the coordinate to the centre   A point is in the disk if its distance to the center is inferior to the radius   We can test our disk in the REPL, by asking whether a point is inside it:   &gt; let c = disk (1, 1) 1  &gt; isInShape c (2, 0) False  &gt; isInShape c (2, 1) True   Here is the equivalent code (up to the strong typing) in C++:   Shape2D disk(Coord2D center, double radius) {   return [=](Coord2D const&amp; c) {     return distance(center, c) &lt;= radius;   }; }   Now that we have the basics for a shape, let us see what kind of Monoid we can find here.   Intersecting shapes is a Monoid   A shape forms a Monoid under the intersection of shapes. The intersection of two shapes is defined as another shape which contains only the coordinates that are in both input shapes:   intersect :: Shape coord -&gt; Shape coord -&gt; Shape coord intersect s1 s2 =   Shape $ \\coord -&gt; isInShape s1 coord &amp;&amp; isInShape s2 coord   We can even generalize this to define the intersection of an arbitrarily large number of shapes (the resulting code is available in this GitHub Gist).   We also need a neutral element. In the case of the intersection, it would be the shape that covers the whole space. We can define it as a shape which always returns that a coordinate is inside it:   allSpace :: Shape coord allSpace = Shape (const True) -- `const True` is a function which always returns True   Here is the equivalent code (up to the strong typing) in C++:   template&lt;typename Coordinate&gt; Shape&lt;Coordinate&gt; allSpace() {   return [](Coordinate const&amp;) {     return true;   }; }  template&lt;typename Coordinate&gt; Shape&lt;Coordinate&gt; intersect(Shape&lt;Coordinate&gt; const&amp; lhs, Shape&lt;Coordinate&gt; const&amp; rhs) {   return [=](Coordinate const&amp; coord) {     return lhs(coord) &amp;&amp; rhs(coord);   }; }   Finally, because the and operator is associative, our intersect function is associative as well. So we have a Monoid. Let us play with it.   Note: We can define another Monoid as well for the superposition of shapes: the full code is provided here. This intersection / union process can be generalised to any predicate (with the AND and the OR operators).   Complex shapes out of simple shapes   Using our intersection operation, we can build more complex shapes. We can for instance intersect a disk with a rectangle, giving us a shape like this:       *******************   ***********************  *************************  *************************   ***********************     *******************   To build a ring-like shape, we can intersect the outside of a small disk with the interior of a big disk, both centered at the same point:   ring :: Coord2D -&gt; Radius -&gt; Radius -&gt; Shape2D ring center smallRadius bigRadius =   intersect     (disk center bigRadius)     (outside (disk center smallRadius))   Using a small helper function, we can draw one in the console:        ****        ********      ********     ***    ***    ***    ***    ***    ***    ***    ***     ********      ********        ****    Here is the equivalent code (up to the strong typing) in C++:   Shape2D ring(Coord2D center, double smallRadius, double bigRadius) {   return intersect(     disk(center, bigRadius),     outside(disk(center, smallRadius))   ); }   Nothing forbids us to compose these shapes even further, as the intersection gives us back a shape like any other, we can intersect a ring with a rectangle for instance. There is no limit to our crazy imagination.   Building a vocabulary of shapes   Since the output of a Monoid operator is also a shape, we can define complex shapes out of very simple shapes and keep on composing them. The details of construction of these new shapes are abstracted.   We are also unable to distinguish a composite shape from a primitive shape. Composite shapes behave, look and smell exactly like primitive shapes, enriching our vocabulary of primitive shapes at a low cost.   Finally, and thanks to the associative nature of the Monoid operator, we never have to care about the order in which these intersections take place. We can first intersect a rectangle with a disk and then a ring, or do it the other way around. It does not matter: given a shape, we never have to care how it was constructed.   EDIT: as u/carrutstick noted, the use of the “order” word in the sentence above might be misleading. It refers to the order of application of the associative binary operation, not the commutativity, that is to say intersect(intersect(rectangle, disk), ring) is the same as intersect(rectangle, intersect(disk, ring)).   More advanced examples of Monoids   There are plenty more examples of Monoid we could talk about.   I have been lucky enough to participate to a training given by Cyrille Martraire, in which he gave us some more example on how to apply this notion to represent financial cashflows. French speakers might be interested in looking at his Monoid talk at the Devoxx 2015.   If you happen to attend the CppCon 2017, you might be interested in coming our presentation on How to apply Functional Programming ideas to build a HTTP router API. At this occasion, Jeremy Demeule and myself will be showing two more examples of Monoids.   Closing thoughts: what Monoids teach us about software   We saw that Monoids have very good characteristics in terms of composition and abstraction, two very valuable characteristics to get in our code. By looking at how they achieve this, we can make some parallel with other good ways to achieve composition.   Associativity and ordering   As we just saw, the associativity is a pretty important property of the Monoid operation. Had the binary operation not been associative, the whole abstraction would have collapsed.      Without associativity, we have to care about the order in which we combine the elements   This ordering provokes an combinatorial explosion of the possible outcomes   In fact, associativity is not as important as being ordering independent (it just so happens that associativity is sufficient to get this property for Monoids). In general, code whose outcome does not depend on its order of execution favours greater composition.   Side effect and ordering   Let us think about the obvious kind of things that would instantaneously make us lose associativity (or alternatively, make the result of our program sensitive to ordering).   The obvious suspect is side effects. Any side effect (an action performed by a process, visible from the rest of the program) inside the binary operation of a Monoid would instantaneously break the associative property. For instance, a adding a print statement would result in different traces being emitted depending on the order of evaluation.   In general, any assignment to a variable aliased externally, or any IO effect, will introduce a dependency to ordering and time in our programs. It will make the program vulnerable to issues such as race conditions, but also greatly limit its composability.   Side effect and composition   In general, there is a pretty strong correlation between our ability to compose program and the amount of side-effects this program relies on to perform its job.   If we see Monoids are a small laboratory to experiment with the consequences of side-effects on a whole program, we understand that limiting side effects to a limited scope in our software is key to build composable and leak-free abstractions.  ","categories": ["software-design"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/09/13/monoids.html",
        "teaser": null
      },{
        "title": "Transforming data structures into types: an introduction to dependent typing and its benefits",
        "excerpt":"The 1.0.0 of Idris has been released just a few months back, just enough to start trying out the language and some of the possibilities dependent typing offers.   Back in July, we implemented a type safe bowling kata in which we could not create a bowling game that would not satisfy the rules of the game. This was a show-off of the strong typing capabilities of dependent types.   Today’s post is not a extensive show-off of the capabilities of Idris. Instead, it is inspired from a real and recent use case, in which I wish I had a dependently typed language to support me. Through a practical use case, we will discover that dependent typing:      Is not really more complex to use despite its sophistication   Avoids some of the nasty headaches with less advanced type systems   Limits the risk of rewrites when going the strong typing road   Disclaimer: The post features Idris. This is an introduction post. As such, it is written so that the knowledge of this language is not a prerequisite, but it helps if you know a bit about Haskell-like syntax.   The (adapted) test case   Let us say that we have a list of event to celebrate, and we want to build a small program to automatically publish some message when one of these events occurs.   What’s an event?   Each event has a title such as “Birthday”. This title is a short name for the event, which allows to categorize it and identify it more easily. It is represented as a simple string.   Each event also has an associated message specification. This is the template of the announcement of the event. It can be viewed as a string with placeholders for missing values. For instance, the message specification “Happy Birthday: {int} years old, {string}” contains two placeholders.   The placeholders each have an associated type such as integer or string. Only a value of the corresponding type should be interpolated at this position. This avoids emitting strange messages such as “Happy Birthday: John years old, 37” instead of “Happy Birthday: 37 years old, John”.   Requirements   Our goal is to support the following needs:      Pretty printing an event (for documentation) with its title and message specification   Storing our events in a list to scan and automate tasks such as pretty printing   Parsing the message specification as a string, such as “Happy {int} birthday {string}”   Interpolating values inside the message specification to produce a valid announcement message   We would also like to support these needs in a type-safe way: it should not be possible to interpolate values of the wrong types inside a message specification. And if possible, we would like this to fail at compile time.   Note: Without going into much details, the original use case is about constraining the schema of a JSON-like data structure, based on an identifier associated to this particular structure.   First, catching errors at runtime   Let us start simple. We will focus on having a simple API which will catch the interpolation type errors inside the message specification at runtime. The next sections will deal with moving these checks at compile time.   Message specification   We start by defining some types that will allow us to describe a message specification. We will call this type Schema. It consists in a list of schema elements which each represents part of the message.   Each schema element is either some known text, or a placeholder for an integer or string value. For instance, here is how we could decompose the message specification “{int} years old, {string}”:   Placeholder        Placeholder      |                  |      v                  v   \"{int} years old, {string}\"         ^^^^^^^^^^^^          Known text   Translated in Idris, a Schema is an alias for a list of SchemaElem which can be either:      IntVar: a placeholder for an integer value   StrVar: a placeholder for a string value   StrCst: a wrapper around a known string   data SchemaElem   = IntVar   | StrVar   | StrCst String  Schema : Type Schema = List SchemaElem   To create a message specification, we just build a list of schema elements. Here is the code that corresponds to the message specification ”{int} years old, {string}”:   -- Equivalent of: \"{int} years old, {string}\" [IntVar, StrCst \" years old, \", StrVar]   Since it is much more convenient to describe the message specification as text, we also provide a function parseMessageSpec to parse the textual description into Schema value:   &gt; parseMessageSpec \"{int} years old, {string}\" [IntVar, StrCst \" years old, \", StrVar]   We now have a way to define a message specification quite succinctly.   Event definition   An event contains both a title and a message specification. This is easily translated into an Idris record, which is analog to a data structure with automatically defined accessors on it:   record Event where   constructor MkEvent   title : String   messageSpec : Schema   Instantiating an event is pretty simple. We just use the constructor MkEvent followed by a string that describe the title, and a message specification. Here are two examples of such events:      The birthDay message specification is described by writing the Schema manually   The newYearEve message specification is parsed from a string   birthDay : Event                                                            -- Declaration birthDay = MkEvent \"Happy BirthDay\" [IntVar, StrCst \" years old, \", StrVar] -- Definition  newYearEve : Event newYearEve = MkEvent \"New Year's Eve:\" (parseSchema \"Happy new year {int}\")   Finally, accessing the members of an event instance is done by calling the accessors functions on it:   &gt; title birthDay \"Happy BirthDay\"  &gt; messageSpec birthDay [IntVar, StrCst \" years old, \", StrVar]   Pretty printing an event   Our requirements include the need to pretty print the definition of an event. This means printing the title, followed by pretty printing the message specification.   We will use the Show interface of Idris (an interface to specify show the equivalent of Java’s toString) and provide two implementations for both a schema element and an event:   implementation Show SchemaElem where   show IntVar = \"{int}\"   show StrVar = \"{string}\"   show (StrCst s) = s  implementation Show Event where   show e = title e ++ \": \" ++ concatMap show (messageSpec e)      We make use of pattern matching on SchemaElem to distinguish placeholder from know text   We use concatMap to transform each schema element into a string and concatenate them   Going back to our birthDay event definition, we can now call show on it to pretty print it:   birthDay : Event birthDay = MkEvent \"Happy BirthDay\" [IntVar, StrCst \" years old, \", StrVar]  -- In the REPL: &gt; show birthDay \"Happy BirthDay: {int} years old, {string}\" -- Output   Interpolation of values   A message specification contains placeholder for integer and string values. To emit an announcement message, we first need to interpolate integer and string values in place of the placeholders.   We will start by defining a type to represent values that can be used to fill a placeholder, which we will name PlaceholderValue. It contains either an integer or a string:   data PlaceholderValue   = IntVal Int   | StrVal String   To interpolate these placeholder values inside the message specification, the logEvent event function will take as input an event (containing a message specification) as well as a list of placeholder values.   It will try to match the placeholders in the order in which they appear in the message specification, with the placeholders values in the order in which they appear in the list.   \"Happy birthday: {int} years old, {string}\"                    ^                 ^                    |                 |                    v                 v               [IntVal 32, StrVal \"Quentin\"]   Since this process might fail (due to arguments of the wrong type, or missing arguments), logEvent will return an optional value (Maybe in Idris) to signal it.   -- Takes an Event + a List of PlaceholderValue as argument -- Returns an optional String as a result logEvent : Event -&gt; List PlaceholderValue -&gt; Maybe String logEvent = ?missingImplementation   The implementation of this function is not that important (it is mainly pattern matching the placeholder expected type against the placeholder value) but provided here as reference.   Examples of interpolation   Below are some examples of using our logEvent function:   birthDay : Event birthDay = MkEvent \"Happy BirthDay\" [IntVar, StrCst \" years old, \", StrVar]  -- In the REPL:  &gt; logEvent birthDay [IntVal 32, StrVal \"Quentin\"]    -- Values match the placeholder expected types Just \"Happy BirthDay: 32 years old, Quentin\"  &gt; logEvent birthDay [StrVal \"Quentin\", IntVal 32]    -- Wrong placeholder types (inverted) Nothing  &gt; logEvent birthDay [IntVal 32]                      -- Missing placeholder value Nothing   It is safe because wrong types for placeholder will lead to Nothing being returned as an answer (to indicate a failure) at runtime. So we cannot construct and therefore emit bad messages.   But we could argue that these type and missing values errors are programming errors, not user input errors, and could therefore be moved at compile time. We will see how to do this in the next section.   Evaluating the costs   Before we proceed into making our API type-safe in such as way that interpolation errors are caught at compile time, it is worth to consider the cost of doing so.   The cost of implementation   Our needs are pretty simple. A non-technical person would expect it to be done quite quickly. Yet, and depending in the language we use, making our API type-safe might be quite expensive.   There is indeed a hidden challenge here. Ensuring type safety, while still allowing message specifications to be parsed from a string, is no easy programming task.   Take C++ for instance. Type-safety would go through hoisting our message specification to the type level. Parsing the message specification will therefore have to be done at compile-time too. This would require using either template meta programming or constexpr functions.   This can be done. Ben Deane and Jason Turner showed how to parse JSON at compile time in their “constexpr ALL the things!” talk. But it is not for the feint of heart, and certainly not without a cost.   The question then becomes whether it is worth it. It is not if the cost of developing a fully type-safe implementation is higher than the cost of dealing with or correcting the errors.   The cost of change   We also need to evaluate the cost of migrating our previously developed API into this new compile-time type safe API. Think about the refactoring needed to accommodate a single new requirement, type safety. Think about the potential cost of migrating potential existing users.   Can we even keep a single function from the previous API?   Now, it turns out that in Idris, we do not need to change anything of our previous API. To make it fully type safe, we only have to add two new functions. And the use of the word add instead of change is important here: we do not need to break anything.   Now, with compile time checks   In our current design, interpolation errors can only be caught at runtime. Let us see how we catch them at compile time instead, without breaking our previous code.   Overall Design   We want a way to interpolate placeholder values inside a message specification such that any missing or invalid placeholder values is caught at compile time.   To get an idea of where we want to go, let us write some client code of the API first. Here is one possible such client code, where logEvent is a function which:      Takes as first argument the event to be announced   Takes as subsequent arguments its placeholder values   birthDay : Event birthDay = MkEvent \"Happy BirthDay\" [IntVar, StrCst \" years old, \", StrVar]  -- In the REPL: &gt; logEvent birthDay 32 \"Quentin\" \"Happy BirthDay: 32 years old, Quentin\"   Now, it is important to notice that the number and the types of the arguments of this logEvent function depend on the value (not the type) of the first argument. A perfect match for dependent types.   How we will proceed   Thanks to currying, we know that a function that takes N arguments can be seen as a function that takes one argument, and returns a function which expects N-1 arguments.   So we can see the logEvent as a function which takes an event and returns a new function, which we will name f here. This function f expects as many arguments as there are placeholders in the event, each with the appropriate type. It will return the resulting announcement message as a string.   To illustrate this, we can use :t (in the REPL) to query the type of the function f returned by the partial application of logEvent on an event:   birthDay : Event birthDay = MkEvent \"Happy BirthDay\" [IntVar, StrCst \" years old, \", StrVar]  -- In the REPL: &gt; :t logEvent birthDay    -- Query the type of logEvent applied to the birthDay event Int -&gt; String -&gt; String   -- The type of a function expecting an integer and a string to produce a string   Writing logEvent consists in finding how to write this function f. We will proceed in two phases:     We will first see how to compute the type of this function f, provided a message specification (ultimately the one of the event).   Then we will complete the implementation.   Computing types   So how do we compute the type of this mysterious f function? And what does it mean to compute a type?   In Idris, it means nothing in particular. A perfectly normal function can take a type as input, or return a type as output. Computing a type simply means calling a function which returns a type.   We will now write a function SchemaType to compute the type of f from the schema of a message specification. We recall that a Schema is a list of schema element, where each element is either a known text fragment or a placeholder:   data SchemaElem   = IntVar   | StrVar   | StrCst String  Schema : Type Schema = List SchemaElem   We can use recursion on the list of schema element to slowly build the type of a function. At each recursive call, we will pattern match on the list, until we reach the empty list   -- Function which takes a Schema and returns a function Type SchemaType : Schema -&gt; Type SchemaType [] = String SchemaType (IntVar :: xs) = Int -&gt; SchemaType xs SchemaType (StrVar :: xs) = String -&gt; SchemaType xs SchemaType (_ :: xs) = SchemaType xs      If the list starts with an IntVar placeholder, we recur and add a Int argument in first position   If the list starts with an StrVar placeholder, we recur and add a String argument in first position   If the list starts with known text, we recur, not adding any new argument   We can try our SchemaType function in the REPL to convince ourselves that it works:   &gt; SchemaType [IntVar, StrCst \" years old, \", StrVar] Int -&gt; String -&gt; String   The type of logEvent   Until now, we carefully avoided to define the type signature of the logEvent function. Now, that we defined SchemaType, we can finally do it.   To do so, we extract the message specification from the event given as first argument of the function and call SchemaType on it, inside the type signature of the function:   logEvent : (event: Event) -&gt; SchemaType (messageSpec event) logEvent e = ?unspecified   There are important characteristics of Idris to notice here:      Idris allows to refer to other arguments’ value by name in any type signature   We can call functions such as messageSpec in the type signature of a function   We can call functions such as SchemaType to compute part of the type signature   In our specific case, the return type of logEvent refers to the value of its first argument, event. We then extract the message specification out of it, in order to compute the rest of the type of the function.   Let’s check that we get what we expect:   &gt; :t logEvent birthDay Int -&gt; String -&gt; String -- A function that expects an integer and a string to produce the message   Finishing up the implementation   Now that we have the type signature of logEvent, it is only a small matter of programming to complete the implementation of the function. We just use the same trick we already used: recursion.   Each recursion level looks at a schema element, and builds a lambda which takes one placeholder value (the syntax \\argument =&gt; body_of_the_lambda). Inside the lambda, we simply concatenate the result of serializing the placeholder value with the rest of the message.   logEvent : (event: Event) -&gt; SchemaType (messageSpec event) logEvent e = loop (messageSpec e) (title e ++ \": \")   where     loop : (messageSpec: Schema) -&gt; String -&gt; SchemaType messageSpec     loop [] out = out     loop (IntVar :: rest) out = \\i =&gt; loop rest (out ++ show i)     loop (StrVar :: rest) out = \\s =&gt; loop rest (out ++ s)     loop (StrCst s :: rest) out = loop rest (out ++ s)   We can try it and check that it works fine when correctly used and that it fails when incorrectly used:   &gt; logEvent birthDay 32 \"Quentin\" \"Happy BirthDay: 32 years old, Quentin\"  &gt; logEvent newYearEve 2017 \"New Year's Eve: Happy new year 2017\"   &gt; logEvent birthDay \"Quentin\" 32 \".. Fails to compile ...\"  &gt; logEvent birthDay 32 32 \".. Fails to compile ...\"   We know have a fully type-safe interpolation of values inside the message specification. And we did not break our previous implementation. In fact, both versions can co-exist.   Conclusion   In today’s post we showed some important feature of Idris type system, and of dependent typing in general: being able to compute types based on values.   We applied it to a use case, inspired from real a real one. We showed that it allows to build a stronger type-safety than what is allowed with more traditional type systems.   In addition of stronger type-safety, dependent types also fill the gap between values and types. They allow us to move between runtime and compile time checks in a smooth way. This helps removing some of the costs of using strong types in statically typed languages.   In particular, the risk of having to rewrite entirely an API is reduced substantially (as well as the risk to adapt or migrate its client code) upon changes in the requirements.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/09/20/transforming-data-into-types.html",
        "teaser": null
      },{
        "title": "Why template parameters of dependent type names cannot be deduced, and what to do about it",
        "excerpt":"Following the presentation a type by any other name at the CppCon, a great talk that shows how to incrementally refactor code using tooling and type aliases, I got interested in one of the observation made by Jon Cohen:   Template parameters of dependent type names cannot be deduced.   This short post aims at describing this issue and explaining why it is so. We will explain why C++ cannot do much better considering its type system and some basic mathematics. We will conclude by showing different ways to solve this issue, including one from Haskell.   Introducing the problem   Before we dive into the explanations, we first have to describe the issue raised by Jon Cohen and introduce the notion of dependent names in C++.   Dependent names   Inside the definition of a template, the meaning of some identifiers might depend on one or several template parameters. For instance in the following code, the meaning of const_iterator depends on the type T:   template&lt;typename T&gt; void f(Container&lt;T&gt; const&amp; cont) {    Container&lt;T&gt;::const_iterator it = ...; //Ambiguous (and will not compile) }   We call such identifiers dependent names.   Because C++ syntax uses overloading, such a name could in theory refer to a static member as much as a type. This ambiguity is the reason why the code above does not compile.   Dependent type names   To get rid of the ambiguity, dependent names are not considered as referring to types “unless the keyword typename is used or unless it was already established as a type name” (from cppreference.com).   This is why we have to add the typename keyword to make the code above valid:   template&lt;typename T&gt; void f(Container&lt;T&gt; const&amp; cont) {    typename Container&lt;T&gt;::const_iterator it = ...; // OK, const_iterator refers to a type }   Note: This was a rather quick introduction to dependent names and dependent type names. The reader is encouraged to look at the cppreference.com or this blog post from Eli Bendersky for more detailed information on the subject.   From now on, we will refer to these dependent names qualified with typename as dependent type names.   Dependent type names as arguments   Dependent type names can appear inside the signature of function templates, as shown below in this over-constrained implementation of for_each:   template&lt;typename T, typename Consumer&gt; void for_each(    typename std::vector&lt;T&gt;::const_iterator first, //dependent type on T    typename std::vector&lt;T&gt;::const_iterator last,  //dependent type on T    Consumer consumer) {    for (;first != last; ++first)       consumer(*first); }   While this code may look fine on the surface, there is a problem here. Upon calling for_each, the compiler will be able to deduce the type of the iterator, but not be able to infer the template parameter T.   And so the following code, which looks perfectly valid, will not compile: the compiler will complain “unable to deduce the template parameter T”:   std::vector&lt;int&gt; ints = {1, 2, 3}; for_each(ints.begin(), ints.end(), [](int i) { // Does not compile    std::cout &lt;&lt; i &lt;&lt; '\\n'; });   The problem is what Jon Cohen referred as “template parameters of dependent type names cannot be deduced” in his talk. This kind of error will likely confuse more than one newcomer to C++.   Why can’t the compiler figure out the type of T?   Hidden dependent type names   The previous example featured a case in which the dependent type name was pretty easy to spot. The typename and the ::const_iterator appeared explicitly. But things get more complex when we introduce type aliases.   For instance, we can write an alias template container_t to select a different container depending on the type of element we would like to store in it (we do not use std::conditional_t to show we are dealing with dependent type names):      If the type is copyable, we want to use a std::vector   Otherwise we want to use a std::list   template&lt;class T&gt; using container_t =     typename std::conditional&lt;         std::is_copy_constructible&lt;T&gt;{}(),         std::vector&lt;T&gt;,         std::list&lt;T&gt;&gt;::type;   We can now define a function f which takes as parameter a container_t. As we can see, it gets really hard to spot that we are dealing with a dependent type name from the signature alone:   template&lt;class T&gt; void f(container_t&lt;T&gt; const&amp; v) { /* ... */ }   But hidden or not, the problem still remains. The compiler will be unable to deduce the type of elements stored in the container:   container_t&lt;int&gt; v; f(v);      // KO: Does not compile, compiler cannot deduce T f&lt;int&gt;(v); // OK: Compiles file   This is precisely the tricky case that Jon Cohen raised in his presentation, and this one will most likely annoy C++ beginners for quite a long time.   Again, why can’t the compiler figure out the type of T?   Why the compiler cannot do much better   Type level functions   We can conceive a type name depending on a template parameter as the result of a function applied on the template parameter. The syntax is different, but it obey the same principle (*).   For instance, here is the type-level function that computes the common type between two or more types in C++, followed by what would the syntax of a normal function call:   using result_t = std::common_type_t&lt;t1, t2&gt;;  // In principle similar to: auto result_t = std::common_type_t(t1, t2);   Similarly, the const_iterator dependent type name can be seen as the result of the application of a type-level function on the vector class template:   using iterator_t = std::vector&lt;t1&gt;::const_iterator;  // Could be rewritten as: using iterator_t = std::const_iterator_t&lt;std::vector&lt;t1&gt;&gt;;  // In principle similar to: auto iterator_t = std::const_iterator_t(std::vector&lt;t1&gt;);   (*): The syntax for calling a type-level function is what Odin Holmes refers as the “unicorn call syntax” as a reference to the “uniform call syntax” C++ standard proposal. We just replace using by auto and angle brackets by parentheses to get the normal call syntax.   Injective functions   A function f is injective is for all input $x$ and $y$, $f(x) = f(y) \\implies x = y$.   In plain english, it means that feeding the function with different inputs lead to different outputs. For each outputs of the function, there is only one possible input that could have led to this output.   One interesting consequence is that if a function is not injective, there is no way we can find back the input value that led to a specific output (since there might be several inputs available).   If on the contrary a function is injective, we can build a reverse function on its image (the set of all possible outputs of the function) to find back the input element for a given output.   Type level functions are not necessarily injective   Upon encountering a dependent type name, which as we mentioned could be viewed as a function operating on types, the compiler has unfortunately no guaranty that the function is injective.   In fact, among the examples of type level functions that we talked about earlier, we already found at least an example of non injective function:   // Clearly not injective using result_t = std::common_type_t&lt;t1, t2&gt;;  // Is it really injective? using iterator_t = std::const_iterator_t&lt;std::vector&lt;T&gt;&gt;;   If we consider that std::vector has an additional template parameters for the allocator, the const_iterator_t type level function is clearly not injective either. We do not expect the iterator type to be different for different type of allocator.   The compiler cannot deduce the template parameter of a dependent type   The compiler is unable to ensure that a type-level function is injective (*). And so it cannot reasonably invert the type level function and deduce a parameter type T given only a type which depends on that parameter as there might be several valid T for this same output!   Going back to our bad for_each function template, the compiler will not be able to deduce the template parameter T given only an iterator:   template&lt;typename T, typename Consumer&gt; void for_each(    typename std::vector&lt;T&gt;::const_iterator first, //dependent type on T    typename std::vector&lt;T&gt;::const_iterator last,  //dependent type on T    Consumer consumer) {    for (;first != last; ++first)       consumer(*first); }   There might indeed be several T matching the const_iterator type provided as parameter: the compiler cannot know which overload to select.   (*): This is not even taking into account the possibility of explicit template specialization, which means that even so we could ensure a type level function is injective today, we could not guaranty it would stay that way.   This is not specific to C++   All languages that offer the possibility to compute types depending on some other value or types will face the same kind of issue. For instance, in Haskell, the same issue appears, although in a slightly different form.   The following code declares a typeclass (an interface or type trait if you wish) named Func, with a template parameter a. This type class exposes a type alias Res which depends on the type parameter a.   class Func a where   type Res a :: *   We provide two instances (specialization, or implementation of the interface, if you wish) of this type class for integer and string, which show how it looks like practically:   instance Func Int where   type Res Int = Int -- Res Int is an alias for Int  instance Func String where   type Res String = String -- Res String is an alias for String   The “equivalent” code (in very loose terms) in C++ would be something like:   template&lt;typename T&gt; struct Func {};  template&lt;&gt; struct Func&lt;int&gt; {    using Res = int; };  template&lt;&gt; struct Func&lt;std::string&gt; {    using Res = std::string; };   If we try to define a function taking a Res a as input, we get a compilation error which says that we cannot deduce the type parameter a from Res a, in spirit the same error as we got in C++:   -- Equivalent to -- void f(typename Func&lt;a&gt;::Res)  f :: Res a -&gt; IO () f _ = print \"Does not compile (type `a` is ambiguous)\"   The main difference with Haskell is that we get the compilation error at the very definition of the function, while the error occurs at the call site in C++.   How to circumvent the issue?   There are different ways we can resolve the ambiguity on the compiler side, by giving it some hints on which specialization should be selected. Let us review some of them.   Relying on additional parameters   While the compiler cannot deduce the template parameter of a dependent type name, it is still perfectly able to deduce a template parameter if it appears somewhere else in the signature of the function, as shown in this implementation of std::accumulate:   template&lt;typename T, typename BinaryOp&gt; T accumulate(    typename std::vector&lt;T&gt;::const_iterator first,    typename std::vector&lt;T&gt;::const_iterator last,    T init,    BinaryOp op) {    for (;first != last; ++first)       init = op(init, *first);    return init; }   Thanks to the init parameter, the compiler is able to deduce the template parameter T and the following code compiles:   std::vector&lt;int&gt; ints = {1, 2, 3}; accumulate(ints.begin(), ints.end(), 0, [](int res, int i) {    return res + i; });   But, granted, we do not always have this luxury of having this additional parameter that makes sense.   Explicit template specialization   If we cannot rely on an additional parameter to help the compiler deduce a template parameter, we can always help the compiler and explicitly provide it the template parameter it cannot infer.   We can for instance correct our previous example by explicitly requiring for the specialization of for_each for elements of type integers, and it will compile just fine:   std::vector&lt;int&gt; ints = {1, 2, 3}; for_each&lt;int&gt;(ints.begin(), ints.end(), [](int i) {    std::cout &lt;&lt; i &lt;&lt; '\\n'; });   In some instances, this might be very annoying or even impractical: what if the template parameter to explicitly specialize is not the first one?   Improving the design by removing constraints   In our specific case, we can generalize our for_each function to take the iterator type as template parameter, just like as the STL does:   template&lt;typename Iterator, typename Consumer&gt; void for_each(Iterator first, Iterator last, Consumer consumer) {    for (;first != last; ++first)       consumer(*first); }   A good rule of thumb is to first try to fix our design by removing constraints before relying on the other tricks. Making the algorithm more generic (the less constraints, the more use cases an algorithm can satisfy) will usually removing the dependent type names along the way and thus get rid of the problem.   Proxy parameters   In some languages, such as Haskell, we cannot ask for an explicit template specialization: the template parameters have to be deduced from the arguments. The solution then is to fall back on the idea of providing the compiler an additional parameter, whose only purpose is to guide the compiler.   This parameter does not carry any runtime value. It is parameterized on the type needed to guide the type deduction, and its only purpose is to carry this type. We usually call it a proxy parameter:   template&lt;typename T&gt; struct proxy {}   Or, equivalently, in Haskell:   data Proxy a = Proxy   Thanks to the proxy guiding type deduction, the following code now compiles fine:   f :: Proxy a -&gt; Res a -&gt; IO () f _ _ = print \"Useless function, but compiles fine\"   In some instances, this trick is useful in C++ as well, especially when explicit specialization is awkward (for instance if the template parameter to specialize is not the first one).   Injective type level functions (Haskell only)   The last solution is to find a way to inform the compiler that the type-level function is injective. As of today (October 12, 2017), this capability is not yet available in C++, but is available in Haskell.   How? By explicitly requiring that the dependent type has to be a brand new type, specific to the instantiation of the type-class, and not an alias to an existing type (by using data instead of type in the declaration below).   class Func a where   data Res a :: *   Here are two examples of instances of this type-class for integer and string. In each case, we are required to create a new type (ResInt and ResString here) as output to the type-level function Res:   instance Func Int where   data Res Int = ResInt { wrappedInt :: Int }  instance FuncInj String where   data Res String = ResString  { wrappedString :: String }   Now, because the Haskell compiler knows that the Res type-level function is injective, Haskell will be able to automatically deduced a from its dependent type and therefore will accept the function as valid:   f :: Res a -&gt; () f _ = ()   This is not the perfect solution: creating a new type is a sufficient condition for injectivity, but not a necessary one. So it is a bit over-constraining, but at least offers a solution to this annoying issue.  ","categories": ["modern-cpp"],
        "tags": ["C++"],
        "url": "/blog/2017/10/12/dependent-type-deduction.html",
        "teaser": null
      },{
        "title": "IdrisPipes: a library for composable and effectful stream processing in Idris",
        "excerpt":"Let’s implement a pipe library for Idris, inspired by the great Haskell Pipes and Haskell Conduit libraries. Our goal is to provide Idris with a library for composable and effectful production, transformation and consumption of streams of data.   In short, our IdrisPipes library is an Idris package that aims at providing the means to write:      Effectful programs, with side effects such as IO   Over a stream of data, potentially infinite   Efficiently, by streaming data and controlling memory consumption   In a composable way, allowing problem decomposition and reuse   In this first post, we will illustrate with examples the motivations behind this library, and give a quick overview of the features it offers. Future posts will be dedicated to explain how it works in more details, how to build your own pipes easily, as well as describing some of the difficulties I had implementing it in Idris.   Motivation &amp; Examples   To explain the goal of this library, we will first illustrate how to use it on a small example of effectful code, and see how we can use IdrisPipes to improve on it.   A world without pipes   We will start with a small effectful function, which we will later enrich with additional requirements. This small function is named “echo”:      It acquires some strings from the standard inputs   Echo them back in the standard output   And stops upon receiving the string “quit” as input   Here is one possible implementation of this need, without using pipes:   echo : IO () echo = do   putStr \"in&gt; \"                 -- Write \"in&gt; \" in standard output   l &lt;- getLine                  -- Read the standard input   when (l /= \"quit\") $ do       -- Upon encountering something else than \"quit\"     putStrLn (\"out&gt; \" ++ l)     -- Echo the string in standard output     echo                        -- Recurse to loop again   Let us run it into the REPL. Upon each line entered after the “in” prompt, it echos back the same string in the “out” prompt, and the “quit” string correctly terminates the execution of the function:   in&gt; toto   -- user input out&gt; toto  -- output in&gt; titi out&gt; titi in&gt; quit   Simple enough. Let us now enrich our “echo” function with an additional requirement.   Adding concerns   Our echo function should not repeat the same output twice in a row anymore. In other words, if we write two times in a row the same string, we want it to ignore the second occurrence:   in&gt; toto   -- user input out&gt; toto  -- output in&gt; toto   -- same entry, do not repeat in&gt; quit   We can easily adapt our previous echo function to support this new requirement, with just a few additional lines of code:   echo : IO () echo = loop (const True) where   loop : (String -&gt; Bool) -&gt; IO ()   loop isDifferent = do           -- `isDifferent` refers to the previous string     putStr \"in&gt; \"     l &lt;- getLine     when (l /= \"quit\") $ do       when (isDifferent l) $      -- If the string is different from the previous         putStrLn (\"out&gt; \" ++ l)   -- Echo the string in standard output       loop (/= l)                 -- Track the last read string   While the number of lines did not increase that much, the overall complexity of the function did.   The loop has to maintain a state that allows us to identify whether the new value is different from the previous one. This state is visible from the whole loop, and comes with additional conditional branching. In short, the additional concern is coupled with the rest of the echo function.   Refactoring with IdrisPipes   We will now see how to get rid of this coupling by refactoring the function using IdrisPipes. We will start with our initial “echo” function and then add the additional requirement of deduplicating entries afterwards.   Thinking in streams   IdrisPipes is based on the idea of building small pipes dedicated to one specific task to perform on a stream of data (like production, transformation or consumption). Each pipe is only concerned with dealing with awaiting for new inputs, transforming this piece of data, and yielding resulting outputs.   These pipes can be connected together to form more complex pipes: the outputs of one pipes become the inputs of the next pipe. Ultimately, these pipes are assembled as a complete pipeline, an Effect in the vocabulary of IdrisPipes, a recipe for stream processing.   The key to our refactoring of echo to use IdrisPipes is thus to observe in what way the function corresponds to the processing of a stream of data.   Refactoring   We can easily view our echo function as processing a stream of lines read from the standard input and flowing down to standard output. We can therefore use IdrisPipes to model the recipe matching it:   stdinLn \"in&gt; \"   .| takingWhile (/= \"quit\")   .| mapping (\"out&gt; \" ++)   .| stdoutLn   This recipe is made of several pipes, connected together with the .| pipe operator:      stdinLn feeds the pipe with strings read from the standard input   takingWhile forwards elements passing through it, interrupting the pipeline if it sees the string “quit”   mapping transforms elements passing through it (here to prepend a prompt to each string)   stdoutLn writes in standard output any string which goes through it   Assembled together, these pipes build an Effect that corresponds to the recipe of echoing back strings as long as the string read is not “quit”.   Running a recipe   The Effect we just wrote is but the description for a recipe for processing a stream. This allow us to decouple the specification of the transformation from its execution (and therefore potentially offer several ways to execute a recipe).   To run the recipe in a sequential fashion, and start flowing some data (from left to right) inside it, we use the runEffect function:   echo : IO () echo = runEffect $              -- Run the pipeline which   stdinLn \"in&gt; \"                -- * read the standard input     .| takingWhile (/= \"quit\")  -- * as long as the user does not write \"quit\"     .| mapping (\"out&gt; \" ++)     -- * preprend \"out&gt;\" to the string read     .| stdoutLn                 -- * then write the string in standard output   The code above is equivalent to our initial “echo” function:   echo : IO () echo = do   putStr \"in&gt; \"                 -- Write \"in&gt; \" in standard output   l &lt;- getLine                  -- Read the standard input   when (l /= \"quit\") $ do       -- Upon encountering something else than \"quit\"     putStrLn (\"out&gt; \" ++ l)     -- Echo the string in standard output     echo                        -- Recurse to loop again   The big difference is that each concerns are kept separated: for instance, the acquisition of inputs (stdinLn) and the stop condition (takingWhile) are fully decoupled. As we will see, this will help us a lot when comes to some additional requirements in our program.   Using pipes to decouple concerns   In our initial implement of “echo”, adding the requirement of deduplicating the input strings led to coupled concerns. Using IdrisPipes, we can instead isolate this additional concern into a specific pipe, named deduplicating.   This pipe will await values, keep track of the last value read, and only yield those that are different from the previous one. The full code of deduplicating is shown below as reference (*). We will later explain how to build our own pipelines in more details:   deduplicating : (Eq a, Monad m) =&gt; Pipe a m a deduplicating = recur (the (a -&gt; Bool) (const True)) where   recur isDifferent =     awaitOne $ \\x =&gt; do       when (isDifferent x) (yield x)       recur (/= x)   This deduplicating logic is isolated, decoupled from the rest of the pipeline, and can now be used else where in the code. In particular, we can add this new pipe in our pipeline to support the new requirement, and no other parts of the pipeline need to know about it:   echo : IO () echo = runEffect $   stdinLn \"in&gt; \"                     .| takingWhile (/= \"quit\")       .| deduplicating            -- Remove consecutive repeating calls     .| mapping (\"out&gt; \" ++)          .| stdoutLn     And we are done. We managed to add the requirement of deduplicated entries as a separate concern, decoupled from the rest of the pipeline.   (*) This Pipe is also available in the library in Pipes.Prelude, along with plenty other standard pipes. You should consider taking a look at the rich set of already available pipes before implementing your own.   A Quick tour of IdrisPipes support for stream processing   Let us now do a quick tour of the design and model followed by IdrisPipes and the features it provides to build effectful streaming programs.   A few concepts - One composition operator   A pipeline of data transformation typically consists of three kind of elements: a source that streams pieces of data, intermediary pipes to transform that data, and a sink that consumes the data to produce a single result. Each of these elements can produce some side effects as well.   IdrisPipes defines a type for each of these kinds of pipes. These types are listed below, with m standing for the Monad matching the desired side effects:      A Pipe i m o awaits values of type i and yields values of type o   A Source m o yields values of type o, and cannot await any values   A Sink i m r awaits values of type i to build a result of type m r   A Effect m r cannot yield or await, and produces a m r when executed   In short, an Effect represents the complete pipeline, starting with a Source, ending with a Sink and possibly made of intermediary Pipes, and which can be run using runEffect:   echo : IO () echo = runEffect $   stdinLn \"in&gt; \"                -- Source     .| takingWhile (/= \"quit\")  -- Pipe     .| deduplicating            -- Pipe     .| mapping (\"out&gt; \" ++)     -- Pipe     .| stdoutLn                 -- Sink   All these types compose together nicely using a single .| operator, to produce new pipes that automatically match their associated semantic model:      A Source m a followed by a Pipe a m b is a Source m b   A Pipe a m b followed by a Sink b m r is a Sink a m r   A Pipe a m b followed by a Pipe b m c is a Pipe a m c   A Source m a followed by a Sink a m r is an Effect m r   All these types are in fact type synonyms for the core data type PipeM i o r1 m r2, with some of the type variables replaced by Void. We will explore in future posts what this type represents in more details.   Note: If you look at the API, you will also notice additional types such as SourceM, SinkM, PipeM. These types are more general than Source, Sink and Pipe and give full access to the return type of the pipe, something useful in particular cases. We will explore this in future posts.   Two main primitives: yield and await   Defining a new pipe is rather easy and relies upon just a few ingredients: yield (to send a value downstream) and await (to receive a value from upstream). To complete the picture, we can use tail recursion to build stateful pipes, and the Monad m to produce side-effects.   For instance, we can define an infinite Source that yield the repeated application of a given function (known as the function iterate in Idris) rather easily:   iterating : (Monad m) =&gt; (a -&gt; a) -&gt; a -&gt; Source m a iterating f = recur where   recur a = do     yield a     -- Yield the value downstream     recur (f a) -- Recurse with (f a) as next seed   Similarly, we can easily define a Sink that folds over its inputs to build a result. It just awaits for inputs and combine them with an initial accumulator. Upon await returning Nothing, the stream does not have any more values to stream, and we can return the result:   fold : (Monad m) =&gt; (a -&gt; b -&gt; b) -&gt; b -&gt; Sink a m b fold f = recur where   recur acc = do     ma &lt;- await           -- await for more inputs     case ma of                          Just x =&gt; do        -- in case there is a value to process         acc' &lt;- f x acc   -- * combine it the current accumulator         recur acc'        -- * and recurse with the new value       Nothing =&gt; pure acc -- otherwise, return the result   We can plug these two pipes together to sum the integers from 0 to 4 as follows:   runPure $                 -- Run the pipeline in the Identity Monad (pure)   iterating (+1) 0        -- Generate the integers from 0 to infinity     .| takingWhile (&lt; 5)  -- Take the ones below 5     .| fold (+) 0         -- And sum them   Note: these pipes are already available in IdrisPipes, although the actual implementation is more concise and general. The library also offer a function “awaitOr” that allows to capture the return type of the previous pipe.   Return value and early termination   As demonstrated by the great Haskell Pipes and Haskell Conduit libraries, there is a huge design space for a pipe library such as IdrisPipes.   In particular, there are many design choice we can make regarding the support of early termination inside the core of the library, or the support of return values at different stages of the pipeline.   Following the reading of this great post on the flows of Haskell Pipes and Conduit by Michael Snoyman, I decided to follow the path of Conduit and integrate early termination inside the core of IdrisPipes.   This way, you can define a Sink such as fold, or a pipe such as groupBy, which would not have been possible without the support for early termination, while still allowing for the pipes to return some values.   Pull based stream model   IdrisPipes follows a pull-based streaming model:      The Sink starts processing first   Each pipe gives control to the pipe before it when it awaits a value   Each pipe immediately releases control to the pipe after it when it yields a value   This allows keeping the memory consumption of the pipeline under control. You can tweak it, and exchange memory for speed in some cases, by implementing pipes that group individual pieces of data into chunks. In fact, an implementation of this pipe is available in Pipes.Prelude, named chunking:   chunking : (Monad m) =&gt; (n: Nat) -&gt; {auto prf: GTE n 0} -&gt; Pipe a m (List a) chunking = ?hole -- Defined in Pipes.Prelude   One direct consequence of this pull-based streaming model is that the source might not be totally consumed. The pipeline will only consume as much as the source as needed.   It also means that you can use IdrisPipes to perform pure lazy computation (using runPure), which you can find useful as Idris is strict by default (there are other solutions available for you to do this though).   Large collection of built-in algorithms   In order to avoid you having to re-invent the wheel, IdrisPipes also comes with a large collection of already existing pipes in Pipes.Prelude, which will only grow as time goes by.   Here is a non-exhaustive list of existing pipes you can use:      mapping f maps each element of the pipe with f   filtering p only forward elements satisfying p   groupingBy p build chunks of elements comparable by p   splittingBy p splits in chunk at elements satisfying p   tracing f runs an effectful function f on each element   The library also comes with some helper functions which help you building your own pipes. For instance, some helpers will take care of early termination and automatic forwarding of the return value of the previous pipe. In particular, the following function might prove useful to you:      awaitForever helps building stateless pipes   awaitOne helps building stateful pipes   each helps yielding several values   idP gives you an identity pipe   These helpers are available and documented in Pipes.Core.   Missing features   IdrisPipes does not yet support leftovers, or the prompt release of resources, as Haskell pipes-safe and Haskell conduit allows you to do. These features might be integrated into the library in the coming months.   Conclusion and what’s next?   In this post, we went over the motivations and goals behind IdrisPipes as well as a quick overview of the package and the features it offers.   In future posts, we will zoom into the implementation details of the package to explain how it works, and discuss some of the design choices and some possible alternatives.   You can have a look at the full package in this GitHub repo.   ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/11/02/idris-pipes.html",
        "teaser": null
      },{
        "title": "Free Monads: from the basics to composable and effectful stream processing",
        "excerpt":"In this post, we will embark in a journey from the basics of Free Monads and interpreters, to more advanced examples, up to how to implement the core of IdrisPipes. Through this exercise, we will illustrate some aspects that makes the Free Monad interesting.   This post does not require any previous knowledge of Free Monads. We will start simple, with a first simple example of Free Monad, and slowly introduce more advanced concepts, to finally dive into the internals of IdrisPipes   Free Monads - Prelude &amp; Motivation   We will start with a quick recap on Monads, and a first introduction to what Free Monads are and what makes them special.   Monads as environment of execution   In Haskell and Idris, Monads are a idiomatic way to establish a specific environment of execution for our code, by allowing us to modify the rules of the languages inside the Monad:      Changing the rules of composition (the Monad itself)   Changing the available primitives (selecting available effects)   Allowing for more than one interpretation of a computation(*)   Free Monads allow us to get one step further, and allow us to transform, optimize or combine our computations by manipulating the instructions they are made of.   (*) By using Monad typeclasses instead of concrete Monads. One implementation can interact with the production environment (a real database, etc.), while another can interact with test components (in-memory database, etc.), as described in our previous article about Hexagonal Architecture.   Free Monads &amp; AST transformations   Free Monads are special kinds of Monads which produce an Abstract Syntax Tree upon evaluation, a data structure for a recipe to execute. Instead of performing side-effects, they only emit instructions.   Nothing really happens until an interpreter reads these instructions to interact with the world (or further transform them until we reach a point where we interact with the world).   This offers us a great flexibility in terms of evaluating the Abstract Syntax Tree. The recipe is completely decoupled from the evaluation of the recipe: we can switch back-ends, writing several interpreters to produce different effects out of the same AST.   This also offer us a great flexibility in terms of consultation or modification of the Abstract Syntax Tree. We can modify our Abstract Syntax Tree, transform it, remove or add some instructions inside it, or even combine several trees together (which is key for building a pipe-like library as we will see).   Free Monads - The Basics   To get a first feel for Free Monads, let’s implement a small password guessing function and refactor it to use a Free Monad instead of the IO Monad directly.   Note: The examples below are all in Idris, but are almost portable in Haskell as-is with some minor syntax differences. We use Idris here for convenience: it supports pretty printing lambdas, allowing us to see the AST produced more easily (see 10 things Idris improved over Haskell).   A password guessing game   We will consider the following function, named password. It asks a user for a password in the console, and fails after reaching the maximal number of attempt allowed:   password : Nat -&gt; (String -&gt; Bool) -&gt; IO Bool password maxAttempt valid = recur 1 where   recur n = do     putStrLn \"Password:\"     -- Ask the user for a password     attempt &lt;- getLine       -- Read the password entered by the user     if valid attempt         -- In case of valid password:       then do         putStrLn (\"Successful login after \" ++ show n ++ \" attempt(s).\")         pure True       else do                -- In case of invalid passord:         putStrLn (\"Login failed: \" ++ show n ++ \" attempt(s).\")         if n &lt; maxAttempt           then recur (n + 1) -- * Try again with one less attempt           else pure False    -- * Stop after reaching maximal number of attempt   We can run this function inside the REPL. Here is a trace of the console, in a scenario in which we successfully log in the system at the second attempt, with the password “Scotty”:   Password: Spock Login failed: 1 attempt(s). Password: Scotty Successful login after 2 attempt(s).   Now, this function is rather rigid and hardly testable. Our goal will be to transform it to use a Free Monad, in order to separate the recipe from the evaluation (and later on manipulate its AST).   Defining the Free Monad AST   The first step in defining a Free Monad is to define the structure of its Abstract Syntax Tree. To do so, we need to identify a set of instructions which allows us to write a function such as password.   As for all Monads, all pure computations are automatically supported inside a Free Monad. The AST only needs to encode the instructions which corresponds to the additional desired effects. If we look at our function above, there are only two of them:      Printing a message in the console   Reading a line from the console   Here is one such AST, named IOSpec, which supports these two instructions:   data IOSpec a   = ReadLine (String -&gt; IOSpec a)   | PrintLine String (IOSpec a)   | Pure a      ReadLine represents the instruction of reading a line. It contains a continuation which represents the set of instructions to execute after getting the string from the console.   Writeline represents the instruction of writing a line. It contains the string to print and the set of instructions to execute after the printing is done.   Pure is the marker for the end of the computation. It carries inside the result of the overall computation.   Examples   Below are some examples of IOSpec Abstract Syntax Tree and their corresponding semantic. This should help you better understand how the instructions of our AST work together:   -- Read a line and return it ReadLine (\\x =&gt; Pure x)  -- Print a line \"Hello\" and return 5 WriteLine \"Hello\" (Pure 5)  -- Read a line and print it twice, and return 5 ReadLine (\\x =&gt; WriteLine x (WriteLine x (Pure 5)))   Now, obviously, writing an AST by hand is not such a great experience. To make it feasible to write reasonable sized function producing such an AST, we will need two more ingredients:      Functions to factorize the creation of such instructions   A Monad instance to sequence the instructions: a Free Monad   Emitting instructions   We will start with the first ingredient, i.e. functions to easily create fragments of our AST. We need two here, one for each of our basic instructions, printing a line and writing a line:   readLine : IOSpec String readLine = ReadLine (\\s =&gt; Pure s)   prnLine : String -&gt; IOSpec () prnLine s = WriteLine s (Pure ())   These two functions create ReadLine and PrintLine instructions whose respective continuations do the simplest thing that makes sense:      readLine produces a computation that reads a line and returns it unchanged (the continuation wraps the acquired string inside Pure)   prnLine produces a computation that prints a line and returns an empty tuple afterwards (the continuation returns the empty tuple wrapped in Pure)   Free Monads - Chaining instructions   The second ingredient is to make it easy to combine two AST into a single one, sequencing the instructions of one AST after the other. For instance, in order to print the line returned by readline, we need a PrintLine instruction to be injected in the continuation of the ReadLine instruction:   -- Reading a line (readLine) ReadLine (\\s =&gt; Pure s)  -- Printing a line (\\x =&gt; prnLine x) \\x =&gt; WriteLine x (Pure ())  -- Chaining them together (printing the line read) ReadLine (\\x =&gt; WriteLine x (Pure ()))   We can implement a Monad instance for IOSpec that will do this sequencing of instruction for us. This will let us profit from the convenient do-notation of Haskell and Idris. The implementation is quite simple (*):      It looks for the last instruction of the left operand (a Pure instruction)   And chains to it a new set of instruction that depends on the value Pure contains   implementation Monad IOSpec where   (&gt;&gt;=) ma f = recur ma where     recur (Pure a) = f a     recur (ReadLine cont) = ReadLine (recur . cont)     recur (WriteLine s next) = WriteLine s (recur next)   We can play in the REPL to get a better feel of how it works:   -- Read a line and print it immediately REPL&gt; readLine &gt;&gt;= \\x =&gt; prnLine x ReadLine (\\x =&gt; WriteLine x (Pure ()))  -- Read a line and print it with an exclamation mark REPL&gt; readLine &gt;&gt;= \\x =&gt; let y = x ++ \"!\" in prnLine y ReadLine (\\x =&gt;   WriteLine (prim__concat x \"!\") (Pure ()))   (*) This implementation is incomplete and requires a Functor and Applicative to be defined, as well as some trickeries with assert_total (for Idris). These are provided here as reference. There are also some issues in terms of efficiency, which will not be addressed here.   Refactoring to use our Free Monad   Equipped with our factories for instructions, and a Free Monad to combine them, we can refactor our password function to emit an IOSpec AST instead of performing IO actions directly.   This refactoring does not require much changes:      We replace IO by IOSpec   We replace putStrLn by prnline   We replace getLine by readLine   And this is it. Here is the resulting function after transformation:   password : Nat -&gt; (String -&gt; Bool) -&gt; IOSpec Bool password maxAttempt valid = recur (S Z) where   recur n = do     prnLine \"Password:\"  -- `prnLine` instead of `putStrLn`     attempt &lt;- readLine  -- `readLine` instead of `getLine`     if valid attempt       then do         prnLine (\"Successful login after \" ++ show n ++ \" attempt(s).\")         pure True       else do         prnLine (\"Login failed: \" ++ show n ++ \" attempt(s).\")         if n &lt; maxAttempt           then recur (n + 1)           else pure False   Now, and upon evaluating this function in the REPL, we get an enormous AST out of it, which correspond to the recipe of our password checking logic (linked here as reference). The last remaining part is to write some interpreters for this AST.   Interpreter   We refactored a function performing IO directly, into a function that emits an AST containing the assembly instructions that matches our level of abstraction. For this sequence of instructions to be useful, we need an interpreter to translate it into a lower level language (*).   To complete our example, we will write an interpreter that transforms a computation expressed in the IOSpec Free Monad into a IO computation to execute it. Our interpreter will simply:      Transform each ReadLine into a getLine call   Transform each WriteLine into a putStrLn call   Replace continuations with a IO Monad bind operator (i.e. sequence them)   interpret : IOSpec r -&gt; IO r interpret (Pure a) = pure a interpret (ReadLine cont) = do   l &lt;- getLine   interpret (cont l) interpret (WriteLine s next) = do   putStrLn s   interpret next   (*) We can define other kind of interpreters as well, some to test our function and feed it with fake inputs, some to transform it into another data structure. Interpreters do not even have to evaluate the instructions per say, they can also simply transform the data structure.   Free Monads - Transforming computations   Until know, nothing we did was specific to Free Monads. As mentioned before, it is perfectly possible to have several interpretations of the same computation with regular Monads (for instance, using typeclasses).   We will now look at some additional nice things that we can do with Free Monads, leading us one step closer to understanding how to build a pipe library in Haskell or Idris.   A demonstration robot   Let us say that we want to do a nice live demonstration of our program, in which we have a bot that types characters in the console instead of us, feeding our password function with inputs (and giving us back control after the bot is out of instructions to execute).   We can represent the commands our bot is allowed to do as follows:   data TestBotAction   = Typing String   | Thinking String  data TestBot = MkTestBot (List TestBotAction)      Typing represents our bot typing a line in our console application   Thinking represents our bot thinking out loud, halting and waiting for a notification to continue   Here is an example of instructions for our bot, in which it tries “Spock” as a first password, then thinks, then tries “Scotty”, before giving up on guessing the password:   botSequence : TestBot botSequence = MkTestBot    [ Typing \"Spock\"    , Thinking \"Trying again... (press enter to continue)\"    , Typing \"Scotty\"    , Thinking \"Nore more ideas. I give up.\"]   We will now see how we can combine this sequence of instruction with our password function, yielding another sequence of instructions.   Integrating our Bot Commands   Free Monads allow us to work on a computation by playing with its AST. So we can alter a computation expressed in the IOSpec monad (such as our password function) by inserting into it new IOSpec instructions corresponding our bot commands.   Here is one way to integrate our bot commands into an IOSpec computation:      We will match a Typing bot command with a ReadLine instruction and transform it into            A PrintLine instruction to print the text entered by the bot       A fixed text value to feed into the continuation of ReadLine           We will transform a Thinking bot command into a:            A PrintLine instruction to print the thoughts of the bot       A ReadLine instruction used to wait for notification (and discarding the value read)           The following pipe operator implements this transformation (understanding the whole code is not essential – you can focus on understanding the principle):   (.|) : TestBot -&gt; IOSpec r -&gt; IOSpec r (.|) (MkTestBot actions) prog = pull actions prog where   mutual -- To define mutually recursive functions       pull : List TestBotAction -&gt; IOSpec r -&gt; IOSpec r     pull actions (Pure r) = Pure r     pull actions (WriteLine s next) = do       prnLine s          -- Print the line to display (such as \"Password:\")       pull actions next  -- Keep on traversing the IOSpec computation     pull actions (ReadLine cont) =       push actions cont -- Give control to bot actions       push : List TestBotAction -&gt; (String -&gt; IOSpec r )-&gt; IOSpec r     push [] cont = ReadLine cont     push (Typing x::xs) cont = do       prnLine x         -- Display the value typed by the bot       pull xs (cont x)  -- Send `x` to the main program, and give it control back     push (Thinking x::xs) cont = do       prnLine x         -- Print the thoughts of our bot       readLine          -- Wait for a line (notification to continue)       push xs cont      -- Keep going      pull traverses an IOSpec computation until it meets a ReadLine instruction, at which point it yields control to the push to insert some bot commands   push integrates bot commands until it meets a Typing bot command, at which point it gives the bot’s string to the IOSpec computation and resumes it   The overall implementation produces a new IOSpec computation, based on the initial IOSpec computation, and transformed to replace ReadLine instructions by the values provided by the bot.   Examples   Since combining our bot commands with an IOSpec computation results in a new IOSpec computation, we can use our previous interpreter to evaluate the resulting AST (*).   runBot : IO Bool runBot = interpret (botSequence .| password 3 (== \"Scotty\")) view raw   Here is the console output that correspond to running this runBot function:   Password: Spock Login failed: 1 attempt(s). Password: Trying again... (press enter to continue)  Scotty Successful login after 2 attempt(s).   It is interesting to note that the bot waits for us to press enter (the empty line after “Trying again”. It would also have given us back control for the last password attempt would “Scotty” been invalid.   It is also interesting to look at the resulting AST after the transformation. You will note that it does not contain any traces left of ReadLine instructions: it has been transformed into a AST consisting only of print line instructions.   (*) The closure property (staying in the same type) is a powerful way of abstraction, as we already talked about in our previous articles about Monoids.   Other ideas of transformation   Playing with our bot is just one example of transforming an AST generated by a Free Monad to enrich, transform or combine computations. There are plenty of other transformations we can do (with limits in terms of practicality) such as:      Combining two computations, like injecting some instructions of one computation in another   Compiling the AST of a high-level computation into a lower-level AST   Aspect Oriented Programming, like adding logs around specific instructions automatically (*)   As we will see in the next section, implementing a pipe library such as IdrisPipes will involves making use of Free Monads and the transformation (1) listed above.   (*) Note though, that some of these transformation might just be much easier to do by playing with Monad type-classes instead. But Free Monads can be abstracted behind Monad type-classes as well, and is in fact recommended in many articles such as this one from @jdegoes.   Using Free Monads - Example of IdrisPipes   We covered the basics of Free Monads, and showed how we could play with an AST to transform and enrich a computation. We are now ready to explore a more involved example: the implementation of a stream processing library such as IdrisPipes.   The link with streaming   In our previous example, we combined an IOSpec computation with the commands of a bot, replacing some of the occurrence of the ReadLine with other instructions (such as printing a line). But there are plenty of other transformation we could have done as well.                  For instance, we could also combine two IOSpec computations x and y together to build a new x .       y computation, by plugging the PrintLine instructions of x to the ReadLine instructions y.              A ReadLine instruction in y would ask (or await) for a string coming from x   A PrintLine instruction in x would send (or yield) a string to y‘s ReadLine instruction   data IOSpec a   = ReadLine (String -&gt; IOSpec a) -- Await a value   | PrintLine String (IOSpec a)   -- Yield a value   | Pure a   Now, if we rename ReadLine by Await, PrintLine by Yield and IOSpec by Pipe, we get the basic idea behind the implementation of a streaming library:   data PipeLight a   = Await (String -&gt; PipeLight a)   | Yield String (PipeLight a)   | Pure a   This PipeLight AST only allows for strings to be streamed, it does not support additional side-effects, terminations and so on, but gives the idea behind the implementation of Haskell Conduit, Haskell pipes or IdrisPipes.   IdrisPipes instruction set   The actual instruction set of IdrisPipes and its corresponding AST is obviously a bit more complex than the one described above. We need to integrate effects, the ability to await or yield different types of values, handle early termination, and more:   data PipeM : (a, b, r1 : Type) -&gt; (m : Type -&gt; Type) -&gt; (r2 : Type) -&gt; Type where   Pure    : r2 -&gt; PipeM a b r1 m r2                                 -- Lift a value into the pipe   Action  : m (Inf (PipeM a b r1 m r2)) -&gt; PipeM a b r1 m r2        -- Interleave an effect   Yield   : Inf (PipeM a b r1 m r2) -&gt; b -&gt; PipeM a b r1 m r2       -- Yield a value and next continuation   Await   : (Either r1 a -&gt; PipeM a b r1 m r2) -&gt; PipeM a b r1 m r2 -- Yield a continuation (expecting a value)   The instruction set is slightly enriched:      Await expects an Either value to support early termination of the upstream pipe   Action allows us to perform effects of type m inside the pipe   The type parameters of PipeM are also a bit more involved:      a is the type of the values flowing in from the upstream (left pipe)   b is the type of the values flowing out to downstream (right pipe)   m is the Monad the pipe runs in   r2 is the type of the returned value of the pipe   r1 is the type of the upstream pipe return value (left pipe)   Overall, the syntax may look a bit different (due to the use of Inf and the use of Generalized Algebraic Data Types), but the basic idea is the same.   Emitting, Sequencing, Combining   As we saw through the example of IOSpec, we need to add a few ingredients to make the construction of an AST practical. We need factory functions for the common instructions, and a Monad instance for sequencing instructions. In IdrisPipes:      yield, await and lift (from the Monad transformation type-class) are the factory functions   The Monad instance of PipeM is available in Pipes.Core   Finally, the .| pipe operator allows us to combine two pipes into one, by plugging together the Yield of the left pipe to the Await of the right pipe:   (.|) : (Monad m) =&gt; PipeM a b r1 m r2 -&gt; PipeM b c r2 m r3 -&gt; PipeM a c r1 m r3 (.|) = pull where   mutual       pull : (Monad m) =&gt; PipeM a b r1 m r2 -&gt; PipeM b c r2 m r3 -&gt; PipeM a c r1 m r3     pull up (Yield next c) = Yield (up `pull` next) c         -- Yield downstream     pull up (Action a) = lift a &gt;&gt;= \\next =&gt; up `pull` next   -- Produce effect downstream     pull up (Await cont) = up `push` cont                     -- Ask upstream for a value     pull up (Pure r) = Pure r       push : (Monad m) =&gt; PipeM a b r1 m r2 -&gt; (Either r2 b -&gt; PipeM b c r2 m r3) -&gt; PipeM a c r1 m r3     push (Await cont) down = Await (\\a =&gt; cont a `push` down)   -- Await upstream     push (Action a) down = lift a &gt;&gt;= \\next =&gt; next `push` down -- Produce effect upstream     push (Yield next b) down = next `pull` down (Right b)       -- Give back control downstream     push (Pure r) down = Pure r `pull` down (Left r)            -- Termination, send pipe result downstream      pull traverses the downstream PipeM computation until it meets an Await instruction, at which point it gives the control to the upstream pipe (via push) to insert its own instructions   push inserts the upstream instruction until it meets a Yield instruction, at which point it connects it to the downstream pipe’s Await instruction and gives back control downstream   You can note that the type signature of the .| operator makes sure that we cannot plug together pipes that would not connect together in terms of values exchanged.   Running a pipe - Interpreter   At this point, the last missing piece is the interpreter, the function that runs a pipeline, and execute the streaming recipe it represents. As described in our previous article on IdrisPipe, we can only running a complete pipeline, i.e. a self sufficient pipe which does not await or yield anything.   IdrisPipes defines a type alias to represent such pipes. An Effect is an alias over PipeM, where Void is used in place of the type of the values flowing in and out of the pipeline (*):   Effect : (m: Type -&gt; Type) -&gt; (r: Type) -&gt; Type Effect m r = PipeM Void Void Void m r   Because we cannot construct a value of type Void, the interpreter of a complete pipeline only has to deal with two instructions:      An Action to execute some side effect, followed by a continuation   The Pure instruction for the termination of the computation   While the other instructions lead to an absurd statement   runPipe : (Monad m) =&gt; Effect m r -&gt; m r runPipe (Pure r) = pure r                         -- Done executing the pipe, return the result runPipe (Action a) = a &gt;&gt;= \\p =&gt; runPipe p        -- Execute the action, run the next of the pipe runPipe (Yield next b) = absurd b                               -- Absurd runPipe (Await cont) = runPipe $ Await (either absurd absurd)   -- Absurd   (*) The Source and Sink are similarly defined, with Void in place of the type for the values flowing in for the Source, and the values flowing out for the Sink.   Conclusion and what’s next   At this point, you should now enough about Free Monads to understand the concept and even build your own. You should have a basic idea of what Free Monads are about, what an interpreter is, and why it might be interesting for you to look further at Free Monads.   You should also know enough about the implementation of IdrisPipes to read its implementation in full, understand it, and maybe even contribute to it if you are interested.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/11/13/free-monads-intro.html",
        "teaser": null
      },{
        "title": "Answering r/haskell: How to unit test code that uses polymorphic interfaces?",
        "excerpt":"This short post is an answer to the following question asked on r/haskell. The original question is about how to test code that lives in a Monad class with polymorphic functions.   I highly encourage you to read the post. Its different answers are full of technical gems which we are not going to explore here in this post. Instead, our goal will be to provide a simpler solution to the problem, by just playing and reworking some abstractions.   The original problem   The OP came with the following need. She needs to model some notion of secure token management. The real implementation of the secure token management makes use of complex encryption and decryption algorithms, which she would like to abstract away from her unit tests.   Monad type class   To abstract away the details of the encryption and decryption, and make it possible to test her code without having to deal with their real implementation, the OP introduced the following MTL-like type-class:      encryptToken maps a polymorphic token to a string   decryptToken maps back a string to a polymorphic token   And a Token is something that can be serialized to and from JSON   class Monad m =&gt; MonadToken m where   encryptToken :: Token t =&gt; t -&gt; m String   decryptToken :: Token t =&gt; String -&gt; m (Maybe t)  class FromJSON a where   fromJson :: JSON -&gt; a   class ToJSON a where   toJson :: a -&gt; JSON  class (FromJSON t, ToJSON t) =&gt; Token t   Let us see of example of use of this Monad. The following code encrypts a token to decrypt it immediately after and return the result of the operation (agreed, it is not really useful, except maybe for some property based testing needs):   backAndForth :: (MonadToken m, Token t) =&gt; t -&gt; m (Maybe t) backAndForth t = do   s &lt;- encryptToken t   decryptToken s   The whole approach described by the OP follows a typical Hexagonal-like Architecture, which is interesting for it decouples the code from the implementation of the services it relies upon (the encryption and decryption of tokens), allowing us to test it more easily.   Testing polymorphic classes   The problem with the approach above, pointed by the OP, is that testing code that makes use of the MonadToken typeclass gets pretty complex due to the polymorphic functions.   A typical fake implementation would use a Map to associate tokens with their corresponding encrypted string (and vice-versa for the decryption). The problem is that building a map with polymorphic keys in Haskell is not an easy task.   There are ways to do this, and you can check some of the great answers available in r/haskell. They make use of advanced and pretty interesting features of Haskell (such as Data.Typeable or Data.Constraint). We will instead explore a simpler solution.   Another take at the problem   Let us try a simpler solution, that does not require using any advanced Haskell features, but instead relies on rethinking the design just a little bit.   Looking at the types   Let us start from our use case. We are really interested in testing some code that makes use of the encryption and decryption of token, such as this code:   backAndForth :: (MonadToken m, Token t) =&gt; t -&gt; m (Maybe t) backAndForth t = do   s &lt;- encryptToken t   decryptToken s   This code makes use of the encryptToken and decryptToken polymorphic functions, whose type are given below (using :type in the REPL):   encryptToken :: (Token t, MonadToken m) =&gt; t -&gt; m String decryptToken :: (Token t, MonadToken m) =&gt; String -&gt; m (Maybe t)   Now, the fact that our code makes use of these function does not imply in any way that these functions must be part of the MonadToken interface. Instead, these functions could be based on lower-level function available in the MonadToken interface.   This is the option we will be exploring below.   Another Monad interface   We can transform slightly our Monad interface by realizing that the only thing that we know form the token given to the encryptToken and decryptToken polymorphic functions is that:      Our token must be serializable to JSON   Our token must be de-serializable from JSON   So there is no loss in generality in transforming our interface MonadToken into the following MonadCypher interface, which deals with concrete JSONs instead of polymorphic tokens:   class Monad m =&gt; MonadCypher m where   encryptJson :: JSON -&gt; m String   decryptJson :: String -&gt; m (Maybe JSON)   To keep our original code working, we can then build our encryptToken and decryptToken polymorphic function on top this MonadCypher type class:   encryptToken :: (Token t, MonadCypher m) =&gt; t -&gt; m String encryptToken = encryptJson . toJson  decryptToken :: (Token t, MonadCypher m) =&gt; String -&gt; m (Maybe t) decryptToken str = (fmap . fmap) fromJson (decryptJson str)   In fact, we can simplify further these two functions. We can generalize them by realizing that encryptToken only needs the ToJSON constraint, and decryptToken only needs the FromJSON constraint. I linked the implementation here.   Now, let us see now how this design helps with testing.   Testing with a Reader Monad   The key aspect in our new design is that our MonadCypher does not rely on polymorphic tokens anymore, but instead relies on concrete JSON values. It makes testing much easier.   To define a fake interface, we can start by defining a Cyphers data type that contains the necessary maps to associate JSON values to encrypted values, and vice-versa:   data Cyphers = Cyphers {   encryptMap :: M.Map JSON String,   decryptMap :: M.Map String JSON } deriving (Show, Eq, Ord)   From there, you know the drill. We simply wrap this data type inside a FakeCypher type, and implements the necessary Monad type class instances:   — Wrapping a Reader Monad transformer (test environment) newtype FakeCypher m a = FakeCypherT (ReaderT Cyphers m a)   deriving (Functor, Applicative, Monad, MonadTrans)  — MonadCypher instance for our test environment instance Monad m =&gt; MonadCypher (FakeCypher m) where   encryptJson json = do     cyphers &lt;- FakeCypherT ask     pure (encryptMap cyphers M.! json)   decryptJson str = do     cyphers &lt;- FakeCypherT ask     pure (M.lookup str (decryptMap cyphers))  — To run a `MonadCypher` computation in our test environment runFakeCypher :: (Monad m) =&gt; FakeCypher m a -&gt; Cyphers -&gt; m a runFakeCypher (FakeCypherT f) r = runReaderT f r   Here we are. We managed to make our code testable. And we also avoided to rely on advanced features such as Data.Typeable or Data.Constraint to do so.   Additional benefits &amp; going further   In additional of being more easily testable, our MonadCypher interface also has additional benefits in comparison to the previous MonadToken interface.   A first advantage we get is that we are able to test more things. The faking of the encryption does not involve the faking of the serialization to JSON. A second advantage is that this design imposes less constraints on the implementation: encrypting does not require anymore the FromJSON constraint.   We could go a bit further and try to get to the essence of encryption and decryption, by relaxing some more constraints and being more generic. For instance, we could try to define our MonadCypher so that it is not defined in terms of JSON (and rather use Data.ByteString for instance).   Conclusion   There is a great deal of freedom in the way we can define type-classes or interfaces. Following the precepts of programming against abstraction helps us make our test more testable, but some abstractions are easier to test against than other.   Depending on the host language, and as shown by the OP of the initial r/haskell post, the choice of the mean of abstraction (the notion being abstracted being the same) leads to different level of sophistication in order to implement it or fake it.   Ultimately though, we can often drastically reduce the complexity of a solution by reworking it even just slightly, typically to avoid falling into the dark corners of the language we use.  ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/12/01/test-polymorphic-haskell.html",
        "teaser": null
      },{
        "title": "Continuation passing style Free Monads and direct style Free Monads",
        "excerpt":"Generalized Algebraic Data Types gives us the power to develop type-safe Free Monads, without having to rely on continuation passing style when using simple Algebraic Data Types.   In today’s post, we will revisit the first Embedded Domain Specific Language (EDSL) example of our previous Free Monad tutorial post. We will look at its Abstract Syntax Tree (AST) again, and show its similarities to the continuation passing style (CPS) of programming.   We will then explore another way we can define an AST for the same language, only this time in direct style, the opposite of continuation passing style, using Generalized Algebraic Data Types.   We will talk about the advantages of defining an AST in direct style, and conclude by giving a small recipe we can use to almost automatically create a Free Monad from a set of instructions we want to support in a Domain Specific Language (DSL).   Quick summary of the last episode   This post is a follow up of our previous Free Monad tutorial post in which we first introduced the basics of Free Monads and interpreters, before discussing more advanced examples where Free Monads are especially interesting.   We will start with a summary of the last episode, just enough for our purpose here. If you read the previous post or are familiar enough with Free Monads, you should skip this section.   Free Monads (in short)   Free Monads are special kinds of Monads which produce an Abstract Syntax Tree (AST) upon evaluation, a data structure for a recipe to execute. They do not perform side-effects directly, they only emit instructions. Nothing really happens until an interpreter reads these instructions to interact with the world.   As shown in our previous post, it gives us a great flexibility in terms of evaluation of the AST. We can switch back-ends, and write several interpreters to produce different effects out of the same AST (recipe).   We also illustrated the great power it offers us in terms of consulting, transforming or even combining recipes before evaluating them with an interpreter.   Free Monads in 3 steps   We previously showed in 3 steps how to decouple the recipe for an IO computation, asking the user for a password, from its execution.   password : Nat -&gt; (String -&gt; Bool) -&gt; IO Bool password maxAttempt valid = do   putStrLn \"Password:\"     — Ask the user for a password   attempt &lt;- getLine       — Read the password entered by the user   if valid attempt         — In case of valid password:   — More code   Our first step was to identify and isolate the side-effects needed to express this computation. We identified two of them: reading a string from and writing a string to the standard output. We then created an AST containing of the instructions needed to support the side-effect we identified.   Here is the AST we developped for our IOSpec Domain Specific Language (DSL):   data IOSpec a   = ReadLine (String -&gt; IOSpec a)   | PrintLine String (IOSpec a)   | Pure a      ReadLine represents the instruction of reading a line. It contains a continuation which represents the set of instructions to execute after getting the string from the console.   Writeline represents the instruction of writing a line. It contains the string to print and the set of instructions to execute after the printing is done.   Pure is the marker for the end of the computation. It carries inside the result of the overall computation.   The second and third steps were respectively to create some factory functions and to make our IOSpec AST a Monad. These two steps completed the construction of our Free Monad, making it easy to emit an IOSpec AST by writing imperative looking code that uses the do-notation.   Intepreting our Free Monad   For a sequence of instructions emitted by a Free Monad to be useful, we need an interpreter to translate the AST instructions into a lower level language, such as IO.   We illustrated this by developing a simple interpreter which transforms a computation expressed in the IOSpec Free Monad into a IO computation to execute it:   interpret : IOSpec r -&gt; IO r interpret (Pure a) = pure a interpret (ReadLine cont) = do   l &lt;- getLine   interpret (cont l) interpret (WriteLine s next) = do   putStrLn s   interpret next   This was a short summary of the first part of our previous post on Free Monads. You can have a look at the rest of the post if you are interested in transformation on Free Monads AST.   Continuation Passing Style AST   Let us now explore in what aspects the IOSpec Abstract Syntax Tree we just defined resembles the continuation passing style (CPS) of programming.   What is Continuation Passing Style?   The Continuation passing style of programming consists in explicitly passing to each function a continuation which is a function that represents the rest of the computation to perform.   In direct style, a function returns its result of type a directly. It just returns the value. This is the default style in most programming languages:   parens : String -&gt; String parens s = \"(\" ++ s ++ \")\"  — In the REPL: parens \"Hello\" &gt; \"(Hello)\"   In continuation passing style, a function takes an additional function – named a continuation – from a to an arbitrary type r as parameter, and calls it on its result of type a:   parensCps : String -&gt; (String -&gt; r) -&gt; r parensCps s cont = cont (\"(\" ++ s ++ \")\")   We will not go in details over the advantages of switching to continuation passing style (which include for example turning stack recursion into heap recursion). Instead, we will look at the overall pattern, abstract it, and see how this abstraction relates to our IOSpec AST.   Abstracting Continuation Passing Style   Looking back at the definition of our parensCps continuation passing style function, we can see a pattern. The return type of the function follows the pattern (a -&gt; r) -&gt; r, where:      a is the result type the function would have in direct style   a -&gt; r is the type of the continuation   r is the result type of the continuation   In the case of parensCps, a matches the string type (the return type of parens written in direct style), while our continuation has the type String -&gt; a:   parensCps : String -&gt; (String -&gt; r) -&gt; r parensCps s cont = cont (\"(\" ++ s ++ \")\")   We can capture this pattern through the type (or type alias in our case) Cont r a, and adapt the type of parensCps accordingly:   — Type alias in Idris (a function on types) Cont : Type -&gt; Type -&gt; Type Cont r a = (a -&gt; r) -&gt; r  parensCps : String -&gt; Cont r String parensCps s cont = cont (\"(\" ++ s ++ \")\")   In the code above, the type Cont r a should be understood as “the type of a continuation passing style function returning a a“ with r being the return type of the continuation. Alternatively, we could see Cont r a as the type of a function that leads us one step closer to a final result of type r, where:      a is an intermediary step on the way to compute the final result of type r   The continuation a -&gt; r represents the rest of the computation to get to the final result   This continuation pattern is the one we will try to find in IOSpec.   IOSpec continuation passing style   Looking back at the AST of the IOSpec Free Monad, let us see in what aspects it resembles the continuation passing style of programming. We will start with the definition of the AST:   data IOSpec a   = ReadLine (String -&gt; IOSpec a)   | PrintLine String (IOSpec a)   | Pure a   We can  refactor this Algebraic Data Type (ADT) to use the more general syntax of Generalized Algebraic Data Type (GADTs), yielding the following equivalent definition for IOSpec:   data IOSpec : Type -&gt; Type where   ReadLine  : (String -&gt; IOSpec a) -&gt; IOSpec a   PrintLine : String -&gt; (() -&gt; IOSpec a) -&gt; IOSpec a   Pure      : a -&gt; IOSpec a   Now, if you look at this carefully, you should start to see that:      ReadLine resembles a function written in continuation passing style, returning a string   WriteLine resembles a function written in continuation passing style, returning an empty tuple   In fact, we can rewrite our AST using our Cont type alias:   data IOSpec : Type -&gt; Type where   ReadLine  : Cont (IOSpec a) String   PrintLine : String -&gt; Cont (IOSpec a) ()   Pure      : a -&gt; IOSpec a   Note: We cheated a bit. For PrintLine, we replaced an IOSpec computation by a function taking an empty tuple and returning an IOSpec computation. These things are however semantically equivalent.   Toward direct style AST using GADTs   Continuation passing style is arguably a bit complex to understand. Thankfully, we can very often transform a CPS function into a function written in direct style, usually much easier to understand. The same way, we can often refactor an AST written in continuation passing style to an AST written in direct style.   Using GADT for a direct style AST   Generalized Algebraic Data Types allow us to write down the type of the constructors. Each of our constructors is free to return a different type. We can use this to define an AST made of instructions that are not of the same type.   This allows us to do something rather nifty. We can turn any function into an instruction of our AST by lifting the name of the function into a type constructor:   — Turning the following functions: writeLine : String -&gt; IOSpec () readLine : IOSpec String  — Into data constructors: data IOSpec : Type -&gt; Type where   WriteLine : String -&gt; IOSpec ()   ReadLine : IOSpec String   As we did for our continuation passing style AST, we can hide the construction of the AST using factories functions. These functions are much easier to write than previously: they just map instructions back to their corresponding functions.   readLine : IOSpec String readLine = ReadLine  prnLine : String -&gt; IOSpec () prnLine s = WriteLine s   Starting from this base, we can build a new Free Monad that encode the same language as our previous AST, by simply adding the support for the Monad interface.   Making it a Monad   To transform our AST into a Free Monad, we can almost mechanically add two additional constructors for our AST, Pure and Bind, which mimic the Monad interface:   data IOSpec : Type -&gt; Type where   Pure : a -&gt; IOSpec a   Bind : IOSpec a -&gt; (a -&gt; IOSpec b) -&gt; IOSpec b   WriteLine : String -&gt; IOSpec ()   ReadLine : IOSpec String   Now, the Monad implementation of IOSpec almost writes itself. It only consists in calling the appropriate constructors, and is much simpler to write than the Monad instance needed for our continuation passing style AST. It is provided here as reference.   A specification for the interpreters   A value of type IOSpec a represents a computation that returns a result of type a. Our GADT-based AST therefore encodes (and enforces!) the following:      Interpreting the ReadLine instruction should return a String   Interpreting the PrintLine instruction should return empty tuple   Somehow, this same information was also encoded, although a bit differently, in our initial continuation passing style AST:   data IOSpec a   = ReadLine (String -&gt; IOSpec a)   | PrintLine String (IOSpec a)   — Missing constructors   It however required to know a bit about continuations passing style in order to recognize the pattern, and notice it was effectively equivalent to:   data IOSpec : Type -&gt; Type where   ReadLine  : Cont (IOSpec a) String   PrintLine : String -&gt; Cont (IOSpec a) ()   — Missing constructors   Our direct style AST is therefore at the same time easier to derive (just lift function to constructors) and easier to read as a specification for an interpreter to translate it into lower-level code.   Simpler interpretation   Because our AST now encodes the specification of its interpretation in a more direct way, writing an interpreter is also much easier. The translation in a lower level language is almost straightforward:      Pure translates to pure in the lower level language   Bind translates into &gt;&gt;= between two interpretations   The other instructions translate to their corresponding lower level instructions   interpret : IOSpec r -&gt; IO r interpret (Pure a) = pure a interpret (Bind a f) = interpret a &gt;&gt;= interpret . f interpret ReadLine = getLine interpret (WriteLine s) = putStrLn s   Each instruction but Bind is translated into a non-compound expression. This is simpler than with our continuation passing style AST, whose interpretation involved both translating instructions and chaining their result with their corresponding continuation.   Bind factors the continuation   The astute reader might have recognized some continuation passing style creeping in our GADT-based AST, through the Bind constructor.   data IOSpec : Type -&gt; Type where   Bind : IOSpec a -&gt; (a -&gt; IOSpec b) -&gt; IOSpec b  — Or, using our Cont type alias\t data IOSpec : Type -&gt; Type where   Bind : IOSpec a -&gt; Cont (IOSpec b) a   This is no accident. We can see the same continuation in the very definition of a Monad (*):   class Monad m where   (&gt;&gt;=) : m a -&gt; (a -&gt; m b) -&gt; m b  — Or, using our Cont type alias class Monad m where   (&gt;&gt;=) : m a -&gt; Cont (m b) a   What our GADT-based AST does is in fact to factorize the continuation which used to appear in the ReadLine and PrintLine constructors, into a single Bind single constructor. This is partly what makes the AST simpler to understand and the interpreters easier to write.   (*) Basically, we could see the bind operator of a Monad as mapping between a Monadic value and a continuation. In addition, continuations form a Monad too. This connection between Monads and continuations is expressed in more details in The mother of all Monads.   The end of our journey   There are many different ways to write the same code. Similarly, there is more than one way we can write our Free Monad. In particular, there are two broad categories of Abstract Syntax Trees: continuation passing style ASTs, and direct style ASTs.   Continuation Passing Style   While continuation passing style is rarely encountered in the wild world of programming, it is relatively more present in the context of Free Monads.   The reason is that constructors of an algebraic data type must all return the same type, such as AST a where a stands for the result type of the overall computation. Therefore, encoding the return type of each instruction is not possible unless:      We rely on something like continuation passing style   We enable Haskell type extensions such as GADTs   Switching to Direct Style   Turning up the GADTs extensions gives us the choice not to dive into the tricky world of continuation passing style (which is arguably harder to understand), and get some additional benefits such as:      An almost automatic way to build an AST from the instructions we want it to support   An AST that acts as easily to understand specification for its interpreters   Simpler interpreters, factory functions, and Monad instances   These benefits makes it much easier to introduce the concept of Free Monad to newcomers to Haskell or Idris, refer to this article as an example, and make GADT-based AST a great alternative to continuation passing style ASTs.   ","categories": ["functional-programming"],
        "tags": ["Functional-Programming","Haskell"],
        "url": "/blog/2017/12/08/cps-free-monads.html",
        "teaser": null
      },{
        "title": "Small programming faults can overflow an entire system",
        "excerpt":"Many years back, in a different company… My company had been doing a shift toward the use of Service Oriented Architecture for the past few years.   In this context, we built a micro-service A that maintained a view on some financial information. The goal was to asynchronously create a data representation that offered better performance for some very common query patterns we had.   At the time, we had been testing the service extensively. We had a demo coming the next days, to show all the progress that we had made.   The code had not changed since the last tests we made. Still, we decided to make a last run of the demo. And it failed miserably. The same test case as before failed. The system was not even responsive.   The error that threw the entire system astray turn out to be ridiculously small.   The context   Our service A was a stateless service, fed by a message broker to receive a feed of real-time updates (from services X and Y below).   Its goal was to aggregate asynchronously these updates and serve queries to other services (service Z below) via a REST API:      The goal of the demo was to trigger an update on service X (via GUI interactions) and show that it correctly updates the view maintained in the service A (again via GUI interactions).   Technically, it was meant to demonstrate that service X correctly sends update messages to service A and that our new service A correctly processes them, and importantly processes them faster than the previous implementation as a monolythic service.   Following the log trail   But our service that was so quick to react in our previous tests now was apparently completely irresponsive. Or was it?   The symptoms   After a quick investigation, it turned out that our service did not crash. In fact, it would still service queries! But the queries would return data that remained invariably stale, and so the GUI was not changing, giving us the impression that the service was dead.   In reality, all services were running, but the view maintained by the service A was not impacted by GUI updates performed on service X.   The rules of the 4 Rs   We naturally tried the rules of the 4 Rs: Retry, Restart, Reboot, Re-deploy… but it did not clear the error away. Not this time. Something was stuck, something that was not in the transient memory of the services.   So we started to look into the logs to identify the guilty service.   Producer or consuner fault? Neither…   We first looked into the log of the service X, hoping to find why it did not send any update messages to service A. Instead, we found that the service X did correctly send the messages.   We then looked the logs on the consumer side, hoping to find why the service A did not receive or process any of the messages. Instead, we found that the service A was being overwhelmed with tons of messages from the broker, conveying updates of service X.   Looking these messages in details, to our surprise, they all looked the same! The service A was in fact consuming tons of update messages (several hundreds per second), but these messages were always the same ten or so.   Maybe a message acknowledgment issue? No…   Our next hypothesis was that our service was not correctly acknowledging the messages it received. In such case, the message broker would always serve the same messages over an over again.   We verified the logs of the service and it was not the case: it was correctly acknowledging the messages sent to it. Digging deeper, it was also clear that the broker was correctly dropping these messages after receiving the acknowledgment and not serving them again.   Back to the emitter (service X), we made sure that it was not sending those updates over and over. But no, it was doing the correct thing: one update, one notification message.   So which services was responsible to send those messages to the message broker?   Looking for the guilty emitter   Something, somewhere, must have been sending these same messages over and over again. They are not appearing out of thin air.   At this point, we decided to proceed by elimination.   We stopped, one by one, each and every service that could possibly send data to the service A through the messaging system, until we noticed a reduction of the traffic. And so we found the guilty service: it was service Y.      Once Y was shut down, we saw the queue being slowly consumed by service A. A few minutes later, the whole garbage was gone. And finally the update of service X was processed.   It’s all clear now!   Now at that point, we could finally understand why our service A had not been very responsive to any updates during our demo rehearsal. It was actually responsive but was instead completely overwhelmed by the traffic it was facing. The resulting latency was so high that the service was not able to react to these updates in real-time.   It was clear why the error first looked like a lost update issue. Because the service had been built with an idempotent business logic, the 10 repeating messages that were flowding the system had no observable effect other than overwhelming the service.   And because the service had separate thread pools for processing updates and serving queries (which is a good design principle called the bulkhead), the query side was still responding with stale data.   Debugging the Sweeper service   Now, time to understand why service Y suddenly started to flood the messaging infrastructure with a continuous flow of identical messages. First, we have to understand what service Y is for.   Sweeping unsent messages   The service Y, guilty of flooding the messaging system, was a technical service acting as a Sweeper. Its goal was to make sure that messages that could not have been sent to the message broker (because the broker was not alive at the time or not reachable) would eventually be sent to the broker when it would come back online.   Basically, any service wanting to send a message to service A (or any other service) through the message broker, would first need the messaging infrastructure (the message broker) to be alive. But would the broker be down, we could not afford to halt all services.   So instead, the transmitting service, service X in our case, would fall back to writing the message in the Sweeping table, a table stored in database (1).      The Sweeper task was to poll periodically the sweeping table, to fetch and transmit these messages that could not have been sent and remove those messages from the sweeping table after successful transmission.   (1) The Sweeper can have another role as well. By writing in the sweeper table inside a DB transaction local to the transmitting service, this pattern allows to make sure we only send messages if the rest of the commit was successful (a useful pattern if the transmitting service has to write in his own DB and wants to make sure an update is sent if and only if this commit is successful).   Digging into the Sweeper code   In principle, the code of a Sweeper is really simple. It regularly polls the sweeping table, fetch the unsent messages, sends them, wait for the acknowledgment of the message broker, and then mark these messages as being sent (we marked them as sent after acknowledgement for guaranteed delivery (2)).   In our case, the code was written in Java, and roughly looked like this:   private void pollSweeperTable(Session session) {     List&lt;Message&gt; unsentMessages = messageRepository.fetchUnsentMessages();     for (Message message : unsentMessages)         sendMessage(session, message);     messageRepository.markSent(unsentMessages); }      The load and save of unsent entries is done using JPA (via the message repository of JPA)   The messages are sent using JMS (the Session object passed as parameter of the function)   These might seem as details, but they are not. The failure mode of our APIs are often what makes the difference in how a failure propagate in our system.   (2) And yes, as you have guessed, this means you can have double transmission, as often in distributed systems. So the the receiver of messages must do deduplication or be idempotent or else this pattern is dangerous to use.   JPA saving errors   It turns out that when JPA tries to save an object, it throws an exception if the ID of the object is not unique in the table. Basically, JPA uses the ID to know which record to replace, and does not know which one to replace, so it panics.   The overall incident started like this: one service managed at some point to corrupt the Sweeping table. The direct consequence was that two messages now shared the same ID in the sweeper table (yes, there should have been a unique index, we will come back to that).   So when the sweeper encountered these messages, it managed to load them, send them, but failed to save them, marked as “sent” for there were two messages with the same ID. So the next sweeper loop would load the same two messages, send them again, and fail to save them again.   Basically, we got an infinite loop sending the same messages over and over again.   Interacting with transactions   This infinite loop does not yet explain everything. There were 2 corrupted messages. Why are there 10 messages being sent repeatedly instead of 2?   A quick look at the code gave us the answer: the sweeper marked all the messages as sent in the same DB transaction. Therefore, a single corrupted message makes the whole transaction fails.   private void pollSweeperTable(Session session) {     List&lt;Message&gt; unsentMessages = messageRepository.fetchUnsentMessages();     for (Message message : unsentMessages)         sendMessage(session, message);     messageRepository.markSent(unsentMessages); // One DB transaction }   As a consequence, instead of just sending the two corrupted messages over and over again, the Sweeper sends all the unsent messages of the Sweeping table over and over again. And guess what? There were about 10 messages in the sweeping table during the incident.   Note: This behavior was motivated by performance. Marking all the messages as sent inside a single commit limits the impact on the database. It was an interesting bet knowing that sending the same messages twice – occasionally – is not a problem: idempotent receivers were already needed by the “at least once” guarantee of our messaging infrastructure.   Here comes the pokemon catch   To finish up, there was a last issue that made everything much much worse. The Sweeper iteration loop was surrounded by a wonderful Pokemon try-catch, logging and swallowing all exceptions:   try {    pollSweeperTable(Session session);    // … } catch (Exception e) {    // Log the exception }   For sure, not swallowing the exception would not have solved the issue. The Sweeper would have crashed upon marking the messages as sent, and then would have been revived by the supervisor, and then would have sent the messages again before crashing again.   The sweeper would still have flooded the messaging system. But it would have shown on the monitoring. Instead, absorbing the exception made the identification of the root cause of the system failure much less obvious. The first visible sign was another service that stopped responding.   What lessons is there to be learned?   Dealing with errors, not anticipating them   Distributed systems are a weird beast. We cannot anticipate most errors in a distributed systems. As illustrated here, some errors are not even necessarily symmetric.   We may be able to connect to the DB to load a record, but not to save the record, the same way that we may be able to send a message through a network link but not receive an answer. Some errors are out of our control (another service corruption our DB in our case).   Therefore the important thing is to put in place mechanisms that limit errors from propagating and lead to a system failure, and try to detect and report these errors as soon as possible.   Dealing with the errors that we anticipated, and pokemon catching the other cases, is a recipe for incidents such as this one.   The way to fix it   In that case, a number of different things would have helped.   First, adding a unique index on the sweeper table to prevent corruption of the message IDs and identify the source of the corruption (at the time of writing, we did not find it).   We customized our JPA repository to use a JQL update where request. Now, whenever there are messages with conflicting IDs in the sweeper table, both duplicates will be marked as “sent” (we will lose a corrupted message instead of losing the entire system):   @Modifying @Query(    value = \"update SweeperTable set sent = 1 where messageId in (:messageIds)\",    nativeQuery = true) void markSent(@Param(\"messageIds\") List&lt;Long&gt; messageIds);   Adding back-pressure on the broker message queue, so that we get clear overflow errors when the situation gets out of control.   And of course remove the Pokemon catching try-catch block ;)  ","categories": ["system-design"],
        "tags": ["system-design","Java"],
        "url": "/blog/2018/07/28/cost-of-ignoring-errors.html",
        "teaser": null
      },{
        "title": "Distributed agreement on random order: Lamport Timestamps",
        "excerpt":"If we succeed in this task, we will have succeeded in building what easily qualifies as one of the world most wasteful way to random shuffle. We now have a stupid task to do, and a perfect architecture to do it. We just miss the perfect language for the task…   It is quite astonishing that some very simple algorithms are able to solve what seem to be very complicated problems. Take the ordering of events in a distributed system.   We cannot accurately synchronize clocks between several devices. And yet, there is a simple and beautiful algorithm which allows to define a total ordering on the events occurring in these devices: Lamport timestamps.   Today’s post is dedicated to illustrating this algorithm through a simple (and arguably completely absurd) example, all implemented in Elixir.   Ordering events in a distributed system   Say we want to process a bunch of event in a distributed system which works in a multi-leader setting:      There are several nodes of the cluster on which we can process events   Event are processed and request are answered before every other leader is notified   Leaders asynchronously notify of these events to all the other nodes   We would like all the nodes of the cluster to eventually agree on an total order on the events, a total order that is consistent which what actually happened in the system (i.e. that makes sense in terms of causality):      For two events E1 and E2 on the same node, if E1 was processed before E2, all nodes must agree that E1 happened before E2   For two events E1 on node N1 and E2 on node N2, if N2 had knowledge of E1 (via notification from N1) when E2 was processed, all nodes must agree that E1 happened before E2   The Lamport timestamps algorithm (also known as Lamport clock) is an astonishingly simple and clever algorithm that gives us just that.   Lamport timestamp algorithm   The algorithm itself is very simple to follow. It only requires each node to maintain a counter (also known as a logical clock) and update it as follow:   Upon receiving an event E on node N:      Increment the logical clock of the node Clock(N) by 1   Log this event E with Time(E) = Clock(N) and Origin(E) = N   To send a replicate of an event E that occurred on node N:      Send the full log of the event E with its time Time(E) and origin Origin(E)   Upon receiving a event log replica E with Time(E) and Origin(E):      Update the logical clock of the receiving node Clock(N) to: 1 + max(Clock(N), Time(E))   After a while, all nodes will have the same event logs. At this point, to retrieve an ordered history of the events, we just need to ask any node for its log of event, and sort them by their time and then their origin.   Note: For a more detailed description of the algorithm and its not-that-obvious implications in terms of ordering and capture of causality, you can refer to Wikipedia or better, look at the original publication.   Absurtity begins - Shuffling a sentence using Lamport timestamps   As explained earlier, Lamport timestamps allow us to totally order a sequence of event in a distributed multi-leader system, in such a way that it respects causality. We will consider the specific case of such a system to illustrate the algorithm.   A wasteful way to shuffle   For the rest of this post, we will build a simplistic distributed multi-leader in-memory buzzword compliant data store, where events being processed are insertion commands. We will insert in this data store all the words of a given sentence, distributing our writes evenly among its different nodes.   We will then demonstrate how Lamport timestamps make sure that our nodes eventually agree on the order of word insertions in the system.   Now, if our nodes agree on an order of insertion of the words of a sentence, they agree on the order of the words of the sentence. In other words, and thanks to Lamport timestamps, the nodes of our distributed in-memory data store will eventually agree on a given random shuffling of the words of the sentence.   If we succeed in this task, we will have succeeded in building what easily qualifies as one of the world most wasteful way to random shuffle – and without any good random properties built-in.   Yes, this is absurd. But also quite fun.   Architecturing the mess   To build our eccentric random shuffler, we need a bit of infrastructure. In addition to our N database replicate (which we will call workers), we will need:      A load balancer: to dispatch the insertion of words among our workers   A pub / sub messaging system: to replicate the logs of one node to other nodes   This is how it will work. We will send all our insertion request through the load balancer, which will be in charge of dispatching these requests among the workers. Workers will send their replicate log through the PubSub messaging system to broadcast it to all other workers asynchronously:      At the end of our experiment, we will ask each of our workers for their individual version of the history of event (and to do so, our load balancer will also need to be able to list of all the workers) and make sure they agree.   A practical implementation of absurdity   We now have a stupid task to do, and a perfect architecture to do it. We just miss the perfect language for the task: Elixir.   A word on Elixir   Elixir is a dynamically typed functional programming language built on top of BEAM, the virtual machine of Erlang. Thanks to this, it inherits from the powerful capabilities of Erlang and its actor model in terms of fault tolerance and parallelism.   Elixir also have a strong similitude with Clojure. It puts the emphasis on being able to easily manipulate data rather than forcing data into types (I just wished it would have inherited from the amazing persistent vector of Clojure). It also has a powerful meta-programming model through macros.   Today, we will mostly use Elixir for its ability to easily instantiate actors, which will be of great help to build our distributed over-engineered sentence shuffling algorithm.   What is an actor?   We will let aside here the formal definition of actors (which is a really good read) and go straight to the implementation of actors in Elixir.   Actors are asynchronous independent light-weight processes, that each have their own state (and garbage collection), and can only communicate with other actors by sending messages or reacting to messages sent to them (in particular, actors cannot share state).   They are like objects (instances, not classes) that each run asynchronously and whose method calls are replaced by message passing. To “run a method”, we send a message containing the name of the method and the value of its arguments. To get back a result, we wait for an answer message.   The plan   We will now implement our random-shuffling workers as actors, maintaining a state of the event they know about, and communicating with the external world (such as other actors) through messages.   These worker actors will need to react to the following kind of messages:      A add message to insert of a new word in the data base   A get_history message to retrieve the history of event as seen by the worker   A replication_log message to transmit the replication log to others worker   Our worker actors will also need to emit replication_log messages (and not only react to them), as well as maintaining a logical clock to implement the Lamport timestamp algorithm.   Starting a worker   Our first task is to do what needs to be done to correctly instantiate new workers and initialize their state. The following code defines the equivalent of a constructor for an actor (*), the init method:   def init(_) do   PubSub.subscribe(@replication_log_topic, self())   {:ok, %State{ name: self(), clock: 1, eventLog: [] }} end   The init method is called at the instantiation of an actor, to perform the appropriate side effects at initialization and return the initial state of the actor. In our case, at startup, our worker:      Needs to subscribes to the replication log notifications (line 1)   Init its state (line 2) with an logical clock starting at 1 and an empty event log   The event log represents what happened in the system, as viewed by the worker. Each log entry in this log contain the payload of an event, tagged with the time at which the event was processed, and its origin (where it was first processed). Here is the Elixir data type corresponding to a LogEntry:   defmodule LogEntry do   defstruct origin: nil, time: 0, event: nil end   (*) In fact, this is the method used to initialize the state of a specific kind of actors, GenServers. This detail is not relevant here, but you are encouraged to follow the Elixir tutorial or the Erlang docs for more information.   Note: There is actually more logic to be done in the constructor, like getting the old history back (if a worker pops after events started flowing). We skipped this here for simplicity.   Querying for the history   Now that we are able to instantiate an actor, let us see how we can communicate with it. As seen earlier, actors can only communicate by sending messages to each other.   To handle and answer a given request in a actor, we need to implement a given callback (*) for this type of message. Technically, here is the code we need to react to the get_history message:   def handle_call(:get_history, _from, worker) do   sortedLog = Enum.sort_by(worker.eventLog, fn event -&gt; {event.time, event.origin} end)   {:reply, sortedLog, worker} end   Let’s take it step by step. First, the prototype. The function handle_call is the name of the callback we must implement, and it takes 3 parameters:   def handle_call(:get_history, _from, worker) do   … end      The message received: here we pattern match on the :get_history constant   The origin of the message: the argument named _from   The state of the actor at reception of the message: the argument named worker   Now let us look at the content of the function. We recognize the Lamport timestamp total ordering we talked about earlier: the history of event is obtained by sorting the event log by time and then origin.   sortedLog = Enum.sort_by(worker.eventLog, fn event -&gt; {event.time, event.origin} end)   The callback handle_call must then return a tuple of 3 elements (the last line of a function is always the returned piece of data of a function):   {:reply, sortedLog, worker}      At the first position: whether or not the message was successfully handled (:ok for success)   As the second position: the answer to the request, the sorted event log   As the third position: the new state of the worker, which we keep unchanged here   Assembled together, this callback will make our workers react to the get_history message by answering a sorted event log (the history as the worker sees it), and keep the state of the actor unchanged.   (*) There are three main callbacks in a GenServer actor, named handle_call, handle_cast, and handle_info. handle_call is for synchronous requests, those for which the caller expects an answer.   Receiving events   To handle the insertion of a word of a sentence, we need to react to the add message. As before, we need to implement handle_call, but this time pattern matching on a message starting with the constant :add and containing a word as a payload:   def handle_call({:add, event}, _from, worker) do   logEntry = %LogEntry{     origin: worker.name,     time: worker.clock,     event: event   }   newWorkerState = %{ worker |     clock: worker.clock + 1,     eventLog: [logEntry | worker.eventLog]   }   PubSub.broadcast(@log_replication_topic, {:replication_log, logEntry})   {:reply, :ok, newWorkerState } end   There are three main parts in this function. First we create a new log entry for the event we just received, tagged with the worker clock and the worker name:   logEntry = %LogEntry{   origin: worker.name,   time: worker.clock,   event: event }   Then we construct the new worker state by appending the new entry in the log, and incrementing the logical clock of the worker by one:   newWorkerState = %{ worker |              # Update worker state   clock: worker.clock + 1,                # – increment clock by one   eventLog: [logEntry | worker.eventLog]  # – prepend log entry to event log }   Finally, we broadcast this new log entry to all other workers, before answering positively (:ok for success) to the request:   PubSub.broadcast(@log_replication_topic, {:replication_log, logEntry})   Receiving logs   Now for our last message, the replication log message. This time, we have to catch messages starting with :replication_log and containing a log entry payload:   def handle_info({:replication_log, logEntry}, worker) do   newWorkerState =     if logEntry.origin == worker.name do       worker     else       %{ worker |         clock: max(worker.clock, logEntry.time) + 1,         eventLog: [logEntry | worker.eventLog] }     end   {:noreply, newWorkerState } end   Because we use a broadcast for the replication log, this function first has to check whether or not the worker is in fact the emitter of the replication log (logEntry.origin == worker.name).   In case the emitter is the receiver, the function does nothing. On the other hand, if the emitter is some other worker, it implements the Lamport timestamp logic:   %{ worker |   clock: max(worker.clock, logEntry.time) + 1,   eventLog: [logEntry | worker.eventLog] }      The replicated log entry is appended to the log of the worker   The worker clock is updated according to Lamport timestamp’s algorithm   Note: The astute code reader might have noticed we used handle_info instead of handle_call. This is no mistake. I will refer you to the GenServer documentation regarding why it is so.   The remaining pieces of infrastructure   At this point, our worker is fully implemented, but for some technical details we skipped here for clarity. You can find the full code here if you are interested.   To run our tests, we only miss our Pub/Sub messaging infrastructure and our Load Balancer. Fortunately, Elixir has quite a good ecosystem and there are some high quality libraries available, such as Phoenix.PubSub. A few lines of code to wrap them (you can find the full code here) and we get our infrastructure for free.   The whole project is available on GitHub.   Testing eventual stupidity   All of this work has not been in vain: it is now time to test our eccentric shuffling algorithm.   Example of random shuffling   Here is an example of sorted event log I got after sending the words of the sentence “hello my dear friend how are you in this glorious and beautiful day ?” to our eccentric shuffling algorithm:   [   %Worker.LogEntry{event: \"friend\", origin: #PID&lt;0.183.0&gt;, time: 1},   %Worker.LogEntry{event: \"dear\", origin: #PID&lt;0.184.0&gt;, time: 1},   %Worker.LogEntry{event: \"my\", origin: #PID&lt;0.185.0&gt;, time: 1},   %Worker.LogEntry{event: \"hello\", origin: #PID&lt;0.186.0&gt;, time: 1},   %Worker.LogEntry{event: \"how\", origin: #PID&lt;0.186.0&gt;, time: 5},   %Worker.LogEntry{event: \"are\", origin: #PID&lt;0.185.0&gt;, time: 6},   %Worker.LogEntry{event: \"in\", origin: #PID&lt;0.183.0&gt;, time: 7},   %Worker.LogEntry{event: \"you\", origin: #PID&lt;0.184.0&gt;, time: 7},   %Worker.LogEntry{event: \"glorious\", origin: #PID&lt;0.185.0&gt;, time: 9},   %Worker.LogEntry{event: \"this\", origin: #PID&lt;0.186.0&gt;, time: 9},   %Worker.LogEntry{event: \"beautiful\", origin: #PID&lt;0.183.0&gt;, time: 11},   %Worker.LogEntry{event: \"and\", origin: #PID&lt;0.184.0&gt;, time: 11},   %Worker.LogEntry{event: \"today\", origin: #PID&lt;0.186.0&gt;, time: 12},   %Worker.LogEntry{event: \"?\", origin: #PID&lt;0.185.0&gt;, time: 14} ]   In other words, all workers ended up agreeing on this random shuffling:   “friend dear my hello how are in you glorious this beautiful and day ?”   This, of course, is just one example of random shuffling of our original sentence. You can test other example by yourself: the code is available in GitHub.   The fascinating bit   What is interesting (and fascinating for me) is that, whatever the random order we end up having, all the workers will eventually always agree on the same. In fact, we can even write unit tests on it, and it will be green:   Eventually.assertUntil 100, 5, fn() -&gt;   same_history =     Dispatcher.get_workers()       |&gt; Enum.map(fn w -&gt; Worker.get_history(w) end)       |&gt; all_equal   assert same_history == true end   We therefore managed to build a buzzword compliant, distributed sentence shuffling algorithm, all based on Lamport timestamp algorithm. Amazing, right?   Conclusion and what to read next   Beside having some random fun, I hope this post gave you the desire to read the original publication of Lamport: Time, Clocks, and the Ordering of Events in a Distributed System, which is truly an amazing paper to read.   This notion of ordering is obviously quite useful in distributed systems. For instance, generalizations of Lamport clocks, such as vector clocks, allow to identify concurrent modifications in a distributed systems, which is tremendously useful to resolve write conflicts (although they are not without problems).   The paper also shows an interesting application of Lamport timestamps, to implement a replicated state machine. This limited consensus algorithm is not fault tolerant (and is completely supplanted by algorithms such as Zookeeper Atomic Broadcast or Raft) but nevertheless quite smart and interesting to read.   Read this paper, try Elixir as well, you won’t regret it.   ","categories": ["system-design"],
        "tags": ["Functional-Programming","system-design","Elixir"],
        "url": "/blog/2018/09/13/distributed-agreement-on-random-order.html",
        "teaser": null
      },{
        "title": "Pythagorean Triples in Modern C++",
        "excerpt":"The post of Eric Niebler on standard ranges and the answer post of Aras Modern C++ lamentations generated quite a lot of heat in the C++ community lately.   The discussion it triggered was quite interesting, with amazing answers such as the one of Ben Deane, but no answer was as intriguing to me as the answer of Sean Parent, in his blog post Modern C++ rumination. In particular, this sentence “primitive Pythagorean triples can be generated efficiently using linear algebra”.   So let’s try and write a somehow efficient and modern C++ Pythagorean Triples generator, based on linear algebra, and using the modern multi-dimensional array C++ library xtensor (inspired from the great numpy Python library).   Linear algebra and Pythagorean triples   The connection between linear algebra and Pythagorean Triples is described in this Wikipedia article, so we do not need to go into the details here.   For the sake of this article, we just need to know that the 3 following linear transformations, represented below as three matrices, generate 3 new Pythagorean triples from a known Pythagorean triple [a, b, c]:   $\\begin{pmatrix} a_1 \\\\ b_1 \\\\ c_1 \\end{pmatrix} = \\begin{pmatrix} -1 &amp; 2 &amp; 2 \\\\ -2 &amp; 1 &amp; 2 \\\\ -2 &amp; 2 &amp; 3 \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix}$   $\\begin{pmatrix} a_2 \\\\ b_2 \\\\ c_2 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 2 &amp; 2 \\\\ 2 &amp; 1 &amp; 2 \\\\ 2 &amp; 2 &amp; 3 \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix}$   $\\begin{pmatrix} a_3 \\\\ b_3 \\\\ c_3 \\end{pmatrix} = \\begin{pmatrix} 1 &amp; -2 &amp; 2 \\\\ 2 &amp; -1 &amp; 2 \\\\ 2 &amp; -2 &amp; 3 \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix}$   For the rest of this article, we will use the following notation for matrices. A matrix will be represented as a “stack” of row vectors, where each vector is represented in square brackets. For instance, our representation of the 3 matrices above are:       [[-1, 2, 2],        [[1, 2, 2],        [[1, -2, 2] A =  [-2, 1, 2],    B =  [2, 1, 2],    C =  [2, -1, 2]      [-2, 2, 3]]         [2, 2, 3]]         [2, -2, 3]]   Now, if we take the row vector V = [3, 4, 5], transpose it to make it a column vector Vt, and multiply it with the matrices A, B and C, we obtain the following new column vectors (written as row vectors to make it readable):   [15,  8, 17], [21, 20, 29], [5, 12, 13]   We can easily check that the triples generated are indeed valid Pythagorean triples.   Pythagorean Triples in Modern C++   Now that we know about linear algebra and Pythagorean triples, we can think about how to implement it. Instead of just doing it naively, we will add some some key refinements (where would be the fun otherwise?) to make our code both shorter, more elegant and more efficient as well.   Stacking matrices   Having a row vector V representing a Pythagorean triple, do we really need to perform 3 different matrix products with the 3 separate matrices A, B and C to get the 3 next Pythagorean triples?   We don’t. Our first trick will be to stack the matrices A, B and C on top of each other to form one big matrix D:       [[-1, 2, 2],      [-2, 1, 2],      [-2, 2, 3],      [1, 2, 2], D =  [2, 1, 2],      [2, 2, 3],      [1, -2, 2],      [2, -1, 2],      [2, -2, 3]]   Now, if multiply our column vector [3, 4, 5] with this matrix D, we get a column vector of size 9, which we can then transpose and split into 3 vectors of size 3.                                                   [[15, 8, 17] [15, 8, 17, 21, 20, 29, 5, 12, 13]  ----------&gt;  [21, 20, 29]                                       (split)    [ 5, 12, 13]]   Now, with one single matrix product, we can get our 3 next Pythagorean triples. While the complexity of the operation is exactly the same as doing 3 separate matrix products, the resulting code will be shorter and faster.   Transforming several vectors at once   In Data Oriented Design in C++, Mike Acton said: “when there is one, there are many”. In short, when considering a particular operation, this operation rarely occurs only once. It often occurs many times, spread around a short time frame. In such cases, we often benefit from bulking these operations.   For instance, and in the context of linear algebra, we will often be interested in applying the same transformation (like a rotation) to a bunch of points (like the points of a triangle) at once.   In our case, we will be interested in generated the next Pythagorean triples for a bunch of previously computed Pythagorean triple (and not a single one in isolation):      We will multiply our matrix D with a single vector [3, 4, 5] and get three vectors back   We will then multiply our matrix D with these 3 previously computed vectors and get 9 vectors back   And so on until we decide to stop generating triangles…   Batching linear transformations   So how do we bulk these linear transformations? We just concatenate our column vectors $V_1$, $V_2$ up to $V_n$ side by side as a matrix U and multiply our stacked matrix D by U.   For instance, if we want to generate the next Pythagorean triples for the row vectors [5, 12, 13], [15, 8, 17] and [21, 20, 29], here is the matrix U we have to multiply the matrix D with:       [[-1, 2, 2],      [-2, 1, 2],      [-2, 2, 3],      [1, 2, 2],        [[ 5, 15, 21] D =  [2, 1, 2],    U =  [12,  8, 20]      [2, 2, 3],         [13, 17, 29]]      [1, -2, 2],      [2, -1, 2],      [2, -2, 3]]   The result of this multiplication, correctly reshaped and transposed (cf the “stacking matrices” paragraph) will give us the expected result:   [[ 35  12  37]  [ 65  72  97]  [ 33  56  65]  [ 77  36  85]  [119 120 169]  [ 39  80  89]  [ 45  28  53]  [ 55  48  73]  [  7  24  25]]   We can then feed this matrix to the next iteration, multiplying them with our stacked matrix D to get the 27 next Pythagorean triples, and so on…   Implementation with xtensor   The following function implements one iteration of the process of generating Pythagorean triples.   It takes as input the previously generated Pythagorean triples (for instance [[3, 4, 5]]) and generates the next Pythagorean triples (for instance [[5, 12, 13], [15, 8, 17], [21, 20, 29]]). This next result can in turn be fed to the function again for the Pythagorean cycle of life to continue.   #include &lt;xtensor/xtensor.hpp&gt; #include &lt;xtensor-blas/xlinalg.hpp&gt;  xt::xarray&lt;int&gt; next_pytharogian_triples(xt::xarray&lt;int&gt; const&amp; previous_stage) {    static const xt::xarray&lt;int&gt; stacked_matrices = {       { –1, 2, 2 },       { –2, 1, 2 },       { –2, 2, 3 },       { 1, 2, 2 },       { 2, 1, 2 },       { 2, 2, 3 },       { 1, –2, 2 },       { 2, –1, 2 },       { 2, –2, 3 }    };     auto shape = previous_stage.shape();    xt::xarray&lt;int&gt; next_three = xt::transpose(xt::linalg::dot(stacked_matrices, xt::transpose(previous_stage)));    next_three.reshape({ 3 * shape[0], shape[1] });    return next_three; }   It makes use of the following xtensor elements:      stacked_matrices is our matrix D, concatenation of matrices A, B and C   xt::linalg::dot is the matrix product   xt::transpose is the matrix transpose   reshape decomposes the result of the multiplication by D in the results of what would have been the separate multiplication by the matrices A, B and C   The code is pretty short, and quite comparable the equivalent Python numpy implementation:   def next_pythagorean_triples(previous):     matrices = np.array(         [[–1, 2, 2],          [–2, 1, 2],          [–2, 2, 3],          [1, 2, 2],          [2, 1, 2],          [2, 2, 3],          [1, –2, 2],          [2, –1, 2],          [2, –2, 3]])      next_triples = np.transpose(matrices @ np.transpose(previous))     next_triples = next_triples.reshape((3 * previous.shape[0], previous.shape[1]))     return next_triples   (The @ operator above is used for the matrix multiplication in numpy)   Sticking it in a loop… or elsewhere   We can now integrate next_pytharogian_triples into an iterator, or a simple loop to generate as many triples as we wish. The one thing we cannot do quite yet is integrate it inside a coroutine (*) to generate an infinite stream of triples, as demonstrated below in Python:   def pythagorean_triples():     current = np.array([[3, 4, 5]])                     # Initial seed     yield from current                                  # Yield first triple     while True:         current = next_pythagorean_triples(current)     # Next iteration         yield from current                              # Yield each triple   This creates a generator that lazily produces an infinite stream of Pytharogean triples like so:   [3 4 5] [15  8 17] [21 20 29] [ 5 12 13] [35 12 37] [65 72 97] [33 56 65] [77 36 85] ...   We could also add some filtering (for example to only keep triples with values below 1000 if we are only interested in small triangles) and run the next iterate with the reduced set of triples:   def pythagorean_triples(filter):     current = np.array([[3, 4, 5]])                     # Initial seed     yield from current                                  # Yield first triple     while current.shape[0]:                             # While work to do         current = next_pythagorean_triples(current)     # Next iteration         current = filter(current)                       # Filter desired triples         yield from current                              # Yield each triple   (*) As mentioned in Ranges, Code Quality, and the Future of C++, coroutines might be more appropriate than ranges for lazy consumption of a stream of data. In Python, a language in which we have both, I find coroutines much easier to write and read than their range algorithm counterpart for use cases where both are usable. I suspect it will apply the same in C++.   What about performance?   How does the linear algebra based implementation compares to a raw loop?   Runtime performance   In Visual Studio 2017 Debug build, we can generate around 30,000 Pythagorean triples in less than 33 milliseconds. In Release build, this time goes down to 1,5 milliseconds (*). Said differently, it takes around 50 nanoseconds to generate a Pythagorean triple, which is amazingly fast!   What happens if we do not batch our linear transformations (one separate multiplication for each input triple)? The performance drops to 638 milliseconds in Debug build (20 times slower) and 29 milliseconds in Release build (20 times slower). Batching linear operations does matter, and quite a lot!   There are other linear algebra tricks we could have used as well, such as fast matrix exponentiation or eigenvector decomposition, which are useful if we want to get just a bunch of big Pythagorean triples really fast (and not enumerate all of them).   (*) This is the time it would take for the naive raw loop algorithm to find around tens of Pythagorean triples.   Build times   In terms of build times, again in Visual Studio 2017, the Debug build takes around 2,4 seconds. The Release build takes also around 2,4 seconds.   This can be seen as the curse of using header only libraries. But it also makes xtensor (as well as xtl and xtensor-blas used here as well) really good in term of performance (*).   (*) As reference, the equivalent Python code, based on the pretty optimized numpy, takes around 2,6 milliseconds to run, almost twice the time needed for xtensor to complete the task.  ","categories": ["modern-cpp"],
        "tags": ["C++"],
        "url": "/blog/2019/01/11/pythagorean-triples-cpp.html",
        "teaser": null
      },{
        "title": "CPPP19 Trip report - The first edition of the first french C++ conference",
        "excerpt":"Last Saturday marked the first occurrence of the CPPP, the first ever conference dedicated to C++ on the French soil, organized by Frédéric Tingaud and Joel Falcou.   It was one of the lucky to be there for this very first edition, and it was quite an special moment to experience the birth of what promises to be one of the great C++ conference of tomorrow.   In this post, I would like to share with you my trip report at CPPP 2019, talks I felt were interesting (actually, all of them were interesting, so that’s easy) and what I enjoyed from the spirit of the conference.   The talks and the speakers - the heart of the conference   The conference was short (it lasted one day) but full of interesting talks and interesting speakers. Here is a short feedback on the ones I was lucky to attend, hoping that it will encourage you to see more of it when the talks will be online (and maybe come to Paris to attend next year).   Emotional Code   Kate Gregory started this first edition with a keynote on Emotional Code. I believe this is the same talk she gave at the ACCU this year.   This talk showed some great examples of the impact of the emotional state of developers on the code they produce. It showed how we should avoid judging others solely based on the code they wrote, for we rarely know the social context in which things happened, and this social context matters a lot.   Fear, working environments with lack of consideration, short-gun deadlines, or misguided metrics, can explain a great deal why people never dare refactoring code, wrote a piece of code without a second look, refuse to give feedback, or avoid participating in some team or company activities.   On the contrary, inspiring figures showing great confidence in the ability to break down and accomplish a daunting task, emphatic or supporting colleagues and manager, and great team dynamic will make most of the difference between a successful project and a failed one.   I only regret that the end of the talk seemed to focus mostly on improving ourselves as individual. I would have loved to hear more about how a group can learn to complete and accept each other’s weaknesses, or influence as a group the culture in which they are in, or just when to quit and find a better working environment. Maybe in a future talk, in which case I would be quite interested.   The state of compile time regular expressions   Hana Dusíková gave one of the most technically impressive talk of the conference itself.   From LL(1) parsers to non deterministic finite automatons, from constexpr functions to template meta-programming, this talk was at the same time very interesting and very rewarding. It was also very intellectually demanding: it goes fast and I wish I had a way to pause during the talk, but the good news is that we can do this on Youtube after the talks are online.   Toward the end of the talk, the performance metrics about the many REGEX engines available as library, as well as the performance measures on constexpr function were quite interesting as well. I did not know that std::regex was so inappropriate for performance intensive tasks.   Modules: what you should know   Gabriel Dos Reis talks bout the genesis of the Modules proposal, explains to us the state of the proposal, gives us some good practices on how to use Modules in the coming C++20, as well as some perspectives on what this proposal will change in the C++ world.   Should we use “import” or “include” for header files in our modules? What remains to be done for build systems to cope with modules? What are the unique opportunities that modules offers for tooling (*) or improving compilation times? Why are modules one of the most important change since the apparition of classes in C++?   This talk will give you a broad overview of these numerous topics, as well as some funny anecdotes on why and how modules originated at Microsoft.   (*) Gabriel Dos Reis proposes a standardized format for the result of compilation of modules, which would allow tools to exploit it, and also to build other languages on top of it (much like .class in Java allowed to build languages like Kotlin, Clojure or Scala on top of the JVM). This was quite interesting.   The anatomy of an exploit   Patricia Aas shows us some tricks that have been known to be used to exploit a program, by putting it in an unexpected state and trying to hack it from there.   If you are new to secure coding practices, this talk will show you why you need to pay attention to this, and how easy it becomes to exploit a program if you did not care enough.   Through a bunch of example and demos, it demonstrate the basics of an attack by buffer overflow, shell code, tries to give a picture of the mindset of an attacker, and explain why fuzzing is so interesting as attacker or as developer to defend against such attacks.   And as a bonus, the slides are beautiful and the presentation both fun and joyful. It never hurts.   Identifying Monoids: Exploiting compositional structure in code   The last talk I attended was from Ben Deane and concerned one of my favorite topic, functional programming and more specifically in this talk, Monoids and Foldables.   In this talk, he shows plenty of examples of Monoids, from the basic ones (integer under addition/multiplication, or strings under concatenation) to more advanced ones:   Program options or command line arguments (maps in general) Statistics: top N, min, max, mean, histograms and more Or more advanced data structure like HyperLogLog or Parsers The talk also shows some example of Foldables (data structures you can summarize to a single value – or alternatively, data structures on which you can implement an equivalent of std::accumulate) and how it combines well with Monoids, giving us the ability to fold a collection of monoidal values to a single value.   The associative property of a Monoids allows us to reorder instructions (select a parenthesisation strategy) when folding them, and therefore take advantage of parallized or optimization tricks we could not afford otherwise.   Bonus: Adding a new clang tidy check - Live Demo   Jeremy Demeule presented how to implement a new check and fix-it to Clang-Tidy, with a live demo, on a non-trivial example, from the beginning to the end.   If you are curious on how you can automate changes on a large codebase (for instance to refactor some part of your code to use the newest C++ features) with a tooling much more powerful that simple regex, you might be interested in watching this workshop.   Jeremy shows how to use clang-query to discover the clang AST interactively and implement your matcher, demonstrates how to generate a fix-it, and gives you a basic workflow you can follow to successfully test and deploy your checks on production.   In summary, if you are new to clang-tidy and are interested in getting started quickly and on the right foot, this is a really good talk to start from.   Final words on the spirit of the conference   A conference is about talks, but not only. It is also about the people there, the venue, the food, and the spirit, and everything that makes people enjoy their stay and enjoy their conversations.   And I must say that everything on that regards was quite impressive.   The venue was very nice and very well located. The food was quite good (thanks a lot for the vegetarian risotto). And above all, the spirit was really nice.   I really loved the fact that the organizers had taken into consideration the attendees. A simple color coding on the badges allowed to identify those who were okay to appear on photos from those who did not, as well as allowing to identify the french speaker from the English speaker, helping everyone to chat.   This was a nice idea that I wish could be ported to all other conferences.   And I wish a good long life to the CPPP.  ","categories": ["modern-cpp"],
        "tags": ["C++"],
        "url": "/blog/2019/06/17/trip-report-cppp19.html",
        "teaser": null
      },{
        "title": "By how much is my smart watch overestimating my distance?",
        "excerpt":"If you happens to run and own a smart watch with GPS tracking, you might have noticed that depending on the quality of the GPS, the track registered by the smart watch does not exactly match the real track you followed.   In my case, I noticed that my (poor quality) watch does tend to oscillate around the trajectory I really followed. In particular, when I run alongside a road, it tends to report that I switched side repeatedly, as if I followed a sinusoidal track, like so:      After noticing that, I started to doubt the distance reported by my watch. By how much my watch has been overestimating my performance all these years?   Stating the problem   Looking at the GPS tracking of my watch, I can easily measure the length of the wave (noted $l$ below) and the amplitude (noted $\\Delta$ below).      Based on these values, how much additional distance is reported by my watch? And consequently, how should I correct for reported distance and speed to find my actual performance?   The stupid way   Let’s approximate the pattern of oscillation by a sinusoidal function. We can note that in the case of a sinus with wave length $2l$, the same pattern of length $0.5 l$ is repeated 4 times:      And so we can zoom on that part and apply some basic math to see how much additional distance $dy$ is reported for a small increment $dx$:      Since we assumed that the GPS tracking produce a sinus of amplitude $\\Delta$ and wave length $2l$, we have:   $\\displaystyle y(x) = \\Delta sin \\big(\\frac{\\pi}{l} x \\big)$   And therefore the small increment is:   $\\displaystyle \\frac{dy}{dx} = \\Delta \\frac{\\pi}{l} cos (\\frac{\\pi}{l} x \\big)$   To find out how much additional distance is overestimated over the segment of length $0.5 l$, we integrate this small displacement:   $\\displaystyle T = \\int_0^{0.5 l} \\Delta \\frac{\\pi}{l} cos (\\frac{\\pi}{l} x \\big) dx = \\Big[ \\Delta sin \\big(\\frac{\\pi}{l} x \\big) \\Big]_0^{0.5 l}$   $\\displaystyle T = \\Delta sin \\big(\\frac{\\pi}{l} \\frac{l}{2} \\big) = \\Delta sin \\frac{\\pi}{2} = \\Delta$   And so for a real distance $l$, the smart watch will report me $l + 2 \\Delta$ leads to an overestimation ratio equal to:   $\\displaystyle r = \\frac{l + 2 \\Delta}{l} = 1 + 2 \\frac{\\Delta}{l}$   And I simply need to divide the reported distance (and speed!) by this ratio to get a corrected estimate of my real performance.   Oh wait… what did I just do?   Did you feel that we complicated our work for nothing above? Does the derivative followed by an integral sound just stupid? It’s because it is.   As it turns out, we can derive the same result in a much simpler way. Since we now that on this portion of the curve $y(x)$ is continuous and monotonous, we know that the additional distance is $\\Delta$:      There is simply no other way: $y$ has to go through $\\Delta$ distance. We therefore find that for every $0.5 l$ actual distance, the watch adds $\\Delta$ to it, leading to the same result as before:   $\\displaystyle r = \\frac{0.5 l + \\Delta}{0.5 l} = 1 + 2 \\frac{\\Delta}{l}$   The interesting thing to notice is that this does not depend on the actual shape of the curve: as long as the segment considered is such that $y(x)$ is monotonous and continuous, we get the same result.   Practical case   In my case, I noticed that the wave length was approximately 100 meters to 200 meters depending on the segments, with the amplitude being of the width of the road, so let’s say approximatively 5 meters.   And so we have $l = 50$ (or $l = 100$ for the 200 meters case) and $\\Delta = 5$, leading to:   $\\displaystyle r_{high} = 1 + 2 \\frac{\\Delta}{l} = 1 + 2 \\frac{5}{50} = 1.2$   $\\displaystyle r_{low} = 1 + 2 \\frac{\\Delta}{l} = 1 + 2 \\frac{5}{100} = 1.1$   On those segments where my watch does this weird behavior, it report 10% to 20% more distance than what I really do!   ","categories": ["random-rambling"],
        "tags": ["random-rambling","maths"],
        "url": "/blog/2021/06/15/smart-watch-overestimation.html",
        "teaser": null
      },{
        "title": "COVID cases from COVID test results",
        "excerpt":"Each time the COVID positive test cases have been going up again, I’ve heard the same sentence: “they largely understimate the actual number of cases, there is at least 10 times more!”.   So out of fun, I decided to create a small statistical model, to quantify how things evolve under reasonnable assumptions.   Interestingly, under this very simple model, it becomes impossible to say “it’s at least 10 times more” in a general way: the underestimation of cases highly depends on the actual number of positive tests detected!   A realistically naive statistical model for COVID   Let’s try to estimate how many real cases of COVID are being a given number of positive tests at the national level. To be able to perform such evaluation, we first need to defined a model which will encode our assumptions.   We will consider the following random variables:      C: indicates whether or not a person has COVID   S: indicates whether or not a person has symptoms related to COVID   T: indicates whether or not the person got tested   R: indicates whether or not the person got a positive test result   The causal diagram of our model is as follows:         The presence of symptoms S depends on whether you have COVID (50% percentage chance to have some if you have COVID C or else 10% due to some other disease)   Whether you get tested T depends on whether you have symptoms S: 50% of people with symptoms go get a test while the non-symptomatic are 1% percent likely to get a test for administrative reasons   Getting tested positive R depends on whether you got tested T (you have 0% to be positive if your not tested) and also on whether you have COVID C (with 2% false positive and 5% false negative)   Our goal now will be to use this model to deduce the number of persons who do have COVID (our unknown) from the number of positive tests that are reported.   Bayesian Networks   The causal diagram (1) above actually defines a Bayesian network. It encodes the decomposition of the joint probability of all those random variables:   $p(C,S,T,R) = p(R|T,C) p(T|S) p(S|C) p(C)$   Instead of the normal joint probability decomposition that follows from the chain rule of probabilities:   $p(C,S,T,R) = p(C|S,T,R) p(S|T,R) p(T|R) p(R)$   Thanks to this joint probability decomposition, we will be able to simplify our calculations, as we known that some variables are either indepent or conditionally independent from each other.   In particular, we have:   $p(R) = \\sum_T \\sum_S \\sum_C p(R|T,C) p(T|S) p(S|C) p(C)$   $p(R) = \\sum_T \\sum_C p(R|T,C) \\sum_S  p(T|S) p(S|C) p(C)$   (1) Bayesian networks don’t have to be causal, but they are usually better designed as causal because it helps reduce the number of edges they have, hence simplifying the formula for the joint probability.   Working out the numbers   We can easily code a Python program that computes this loop and encodes the conditional probabilities that appear in the diagram above.   Here is what we find:         If everyone has COVID, only $24.225$% of the population will report a positive test   If noone has COVID, $0.118$% of the population will still report a positive test   So as we can see, the saying “the number of case is 10 times higher than the one that is reported” is wrong. Depending on the actual number of COVID cases, the number of positive tests reported at the national level will either overestimate or underestimate the real count.   Since the plot is clearly linear, we can infer from those two points that the linear formula linking $p(R)$ and $p(C)$ is:   $p(R) = 0.24107 p(C) + 0.00118$   And from it we can deduce at which point the reported number of cases goes from being an overestimation to being an underestimation:   $p(R) = 0.24107 p(C) + 0.00118 = p(C)$   $0.00118 = 0.75893 p(C) \\implies p(C) \\simeq 0.00155482$   So starting from $0.15$% of the population being infected, the number of reported positive COVID cases starts to underestimate the real number of cases.   Working out the formula (without computer)   To do so, we need to go back to the joint probability distribution formula that we have written before:   $p(R) = \\sum_T \\sum_C p(R|T,C) \\sum_S  p(T|S) p(S|C) p(C)$   Instead of unrolling the formula at once, let’s simplify it. We know that to get a positive test result, we first have to be tested:   $p(R=\\text{true}|T=\\text{false},C) = 0$   And since we are only interested in positive test results (because that’s what we observe), we can drastically simply the formula like so:   $p(R=\\text{true}) = \\sum_C p(R=\\text{true}|T=\\text{true},C) \\sum_S  p(T=\\text{true}|S) p(S|C) p(C)$                  Case       S       C       $p(T=\\text{true}|S) p(S|C) p(C)$                       Symptoms and COVID       True       True       $0.5 * 0.5 * x = 0.25 x$                 No Symptoms but COVID       False       True       $0.01 * 0.5 * x = 0.005 x$                 Symptoms no COVID       True       False       $0.5 * 0.1 * (1 - x) = 0.05 (1 - x)$                 No Symptoms no COVID       False       False       $0.01 * 0.9 * (1 - x) = 0.891 (1 - x)$           So, after multilying the cases where we have COVID with 0.95 and the others with 0.02 (the false positive rate), we end up with the following formula:   $p(R) = 0.95 * (0.25 + 0.005) x + 0.02 (0.05 + 0.009) (1 - x)$   $p(R) = 0.24225 x + 0.00118 (1 - x) = 0.00118 + 0.24107 x$   Thanksfully, the same formula as before ;)  ","categories": ["machine-learning"],
        "tags": ["machine-learning","maths"],
        "url": "/blog/2021/07/29/covid-cases.html",
        "teaser": null
      },{
        "title": "How wind affects your speed on a bike",
        "excerpt":"If you are into biking, you’ve probably noticed that the relative wind that slows you down seem to appear all of a sudden. Slow down a little bit and it seems okay, accelerate back 5 km/h higher, and it feels really painful.   You probably have noticed as well that on some windy days, the way back you go almost 10 km/h faster in average, with the same amount of efforts applied.   Let’s quicky look at the physics behind this.   The Physics   TLDR; The power needed to maintain a given speed is cubic in the relative speed of the wind. The energy expenditure over a given distance is quadratic in the relative speed of the wind.   The drag force   From Wikipedia, we get the following equation for the drag force:   $\\displaystyle F = {\\tfrac {1}{2}}\\,\\rho \\,v^{2}\\,C_{D}\\,A$   where we have:      $\\rho$  is the density of the fluid   $v$ is the speed of the object relative to the fluid   $A$ is the cross sectional area   $C_{D}$ is the drag coefficient (which depends on the shape)   So the intensity of the force is quadratric in the speed of the relative wind the cyclist is facing.   The work   The force applies on a given position, and we have to integrate this over the trajectory to get the total work of the force.   $\\displaystyle W = \\int F(x) . dx$   Which, if we assume a straight line trajectory, gives us:   $\\displaystyle W = F(x) . \\vec{x}$   So we can see that the work done for a given distance grows quadratically with the speed at which we travel relative to the wind.   The power   Then, to get the power, we have to compute at the work done over time (the derivative of the work with respect to time).   $\\displaystyle P = \\frac{dW}{dt} = F . \\frac{d \\vec{x}}{dt} = F . \\vec{v}$   And so we see that the power is not quadratic with respect to the relative speed of the wind, but cubic instead. To go twice as fast against the wind, you need to generate 8 times the power against the wind, which is quite substantial!   Consequences (if the drag force dominates)   For speeds at which the drag force dominates over the other forces (typically at high speed, the drag force is the main slowing factor), the following holds.   Going 10% as fast requires 33% more power   To accelerate from $v_1$ to $v_2 = 1.1 v_1$, the relative increase in power is given by the ratio of $P_2$ divided by $P_1$:   $\\displaystyle \\frac{P_2}{P_1} = \\frac{v_2^3}{v_1^3} = 1.1^3 = 1.331$   So you need to sustain 33.1% more power to gain a mere 10% speed. We can generalize and get a feel of this cubic cost by looking at the following table:                  Relative Speed Increase       Relative Power needed                       +10%       +33%                 +20%       +73%                 +30%       +120%                 +40%       +174%                 +50%       +338%           Resting by slowing down might not degrade your average speed so much   This is the same observation as the previous section but here we consider slowing down instead of speeding up:                  Relative Speed Increase       Relative Power needed                       -10%       73%                 -20%       51%                 -30%       34%           In short, if I divide my power expenditure by 2 temporarily to catch my breath, my speed will only decrease by 20%, which is not so much. This will not show too much too significantly on my average speed if done for a short period of time.   Doubling the power only means going 26% faster   We can obviously inverse the question: how fast could I go if I double the amount of power I can sustain? (in the limit where other forces are negligible)   $\\displaystyle \\frac{P_2}{P_1} = 2 = \\frac{v_2^3}{v_1^3} = \\frac{f^3 v_1^3}{v_1^3} = f^3$ where $f$ is the speed increase factor   The only real solution of $\\sqrt[3]{2}$ is approximatively 1.2599 and so doubling our amount of sustainable power (by increasing our VO2 max, our muscle efficiency with respect to oxygen consumption, our strength, etc) would “only” give us 26% increase in speed.   Doing the same parcours 10% faster requires 21% more energy   Because of the work grows quadratically with the relative speed of the wind, for a fixed distance in straight line (and in the limit where we can neglect the effect of other forces than the drag force, for instance at high speed), we have:   $\\displaystyle \\frac{W_2}{W_1} = \\frac{v_2^2}{v_1^2} = f^2$ where $f$ is the speed increase factor   And so if we go 10% faster, $f^2 = 1.1^2 = 1.21$, and so we spend 21% more energy in doing so.   Another way to derivate the same result is considering that power will increase with the cube of $f$, but dividing by $f$ because we have to sustain that power for $f$ less amount of time (since we go through the distance $f$ times faster).   Calories burned are not only a function of distance   The previous section showed us that merely saying “I did a 40 km bike this week-end” does not really allow to compute for the total energy expenditure (and so the real intensity of the workout).   In fact, someone could have done twice your distance and burn as much calories as you did by going slower. How slower? Let’s compute that:   $\\displaystyle W \\propto v^2 d$ where $v$ is the speed and $d$ the distance   And so if the two persons spent equally as much energy but one person did twice the distance as the other, we have:   $\\displaystyle d_1 v_1^2 = d_2 v_2^2$ and $d_1 = 2 d_2$ $\\displaystyle \\implies \\frac{v_2^2}{v_1^2} = 2$   And so the person that did travel half the distance did it $\\sqrt{2} \\simeq 1.44$ times faster.   Aerodynanism also hits the same dimishing returns but remains of paramount importance   The power as well as the energy are proportional to the “aerodynamism” factor $K$ as the power follows this equation:   $P = K v^3$ and $W = K v^2$   And so for the same speed, improving aerodynamism by 20% will decrease your power and energy expenditure by the same 20%.   But aerodynamism also hits the same diminishing returns as increasing power when we want to increase our speed.   For instance, for the same amount of sustained power (i.e. the same amount of energy or calories burned over a period of time) improving aerodynamism by 20% leads to going 7.7% faster:   $P_1 = K_1 v_1^3 = P_2 = K_2 v_2^3$ where $K_2 = 0.8 K_1$   $\\displaystyle \\implies \\frac{v_2^3}{v_1^3} = \\frac{K_1}{K_2} = \\frac{1}{0.8}$ $\\displaystyle \\implies \\frac{v_2}{v_1} = \\sqrt[3]{1.25} \\simeq 1.077$   Note that aerodynamism still remains of paramount importance, because if you want to increase your speed by 7.7%, you can either improve aerodynamism by 20% or increase your sustained power by 25%.  ","categories": ["random-rambling"],
        "tags": ["random-rambling","maths"],
        "url": "/blog/2022/05/24/cycling-drag-force.html",
        "teaser": null
      },{
        "title": "Auto-regressive language models don't necessarily sample the most probable sentences",
        "excerpt":"The year 2020 saw the coming of GPT-3. Since then, a lot of increasingly powerful language or language-image models (sur as Chinchilla or Flamingo) have been released.   What these models have in common is the auto-regressive nature of their sequence generation process. Each word is generated by conditioning on the previous words.   Although very powerful, these models, even if sampled in a greedy fashion (i.e. pick the next most probable word as next token), will not necessarily generate the most probable sentence or answer. Let’s see why.   Back-ground on language models   Language models are trained to model the probability distribution of the next word in the sentence given the previous ones:   $P(x_N | x_{N-1}, …, x_1)$   We call such models auto-regressive. These models are elequant for at least two reasons. The first one is that we can easily sample from them to produce a sentence (write english, code, cooking recipes, etc).   The second is that their formulation corresponds to a specific decomposition of the joint probability of the sequence, which follows directly from the chain rule of probability, and always holds true:   $P(x_1, x_2, … , x_N) = \\prod P(x_i | x_{i-1}, …, x_1)$   Greedy does not lead to most probable   Say our language model manages to perfectly match the conditional distribution of next word in the natural language.   $P(x_N | x_{N-1}, …, x_1)$   We now decide to generate the next sentence by repeatedly sampling the next most probable token from this distribution until the end of sequence token is reached. Why are we not guaranted to generate the most probable sentence?   Let’s start with an example   In the example below, the prefix represents what our auto-regressive would have generated so far, and provide the next tokens with associated probabilities:                  Prefix       Next token       Probability                       A       B       60%                 A       C       40%                 AB       A       33%                 AB       B       33%                 AB       C       33%                 AC       C       100%           Say we are given the prefix “A” (which for example represents the question being asked to our language model) and we want to generate 2 tokens.   By greedy behavior, our model will select “B” as next token (probability 60%). Then it will be cornered and have to pick a token with probability 33%. The overall probability of the answer will be 20%.   But the most probable sentence to generate in that case is “CC” (first token with probability 40% then second with 100%) leading to an overall probability of 40%, much higher than what the greedy algorithm would have done.   But why?   As discussed above, the probability of a sentence of $N$ tokens can be decomposed using the chain rule of probability like so:   $P(x_1, x_2, … , x_N) = \\prod P(x_i | x_{i-1}, …, x_1)$   In the general case, maximizing this quantity cannot be done by successfully maximizing the quantity with regard to any of the variables in isolation (even by selecting a “clever” ordering of variables with regard to which to maxinize).   This is one of the reason why it is so important not to sample in a greedy manner. But to me, there is another intuitive reason as well…   Greedy is boring   The greedy sampling of the next probable sentence is likely to select the most boring next possible word.   Remember from information theory that the information content $\\mathcal{I}$ of an event $X$ is the logarithm of the reciprocal of the probability:   $\\mathcal{I(X)} = - \\log P(X)$   A very probable event conveys a very low amount of information when it occurs. Telling you that the sun will rise and fall tomorrow is quite boring. Telling you that a comet will appear in the sky tomorrow is much more interesting. Adding the time in the sentence will add some more information and makes it even more interesting.   In short, if you want an interesting conversation, the minimum requirement would be surprise and information content. Those are reason why greedy should be avoided.   So should we instead generate the next word with the smallest probability? It’s obviously not a good idea either. If this next word has very low probability it is likely that adding it to the end of the sentence is not gramatically correct.   The solution used in most paper is to sample from the distribution using a temperature in the softmax so that a reasonnable diversity is achieved, without endangering the syntactic correctness of the sentence.   Links to similar phenomena   For those familiar with Hidden Markov Models (HMM), this phenomena is very reminiscent of the difference between “filtering” and the “Viterbi” algorithm.   Given a sequence of observations, the filtering algorithm will give you the most probable current state. But repeatedly “filtering” on very position in the sequence will not given you the most probable succession of states, to do so, you must use the Viterbi algorithm.  ","categories": ["machine-learning"],
        "tags": ["machine-learning","maths"],
        "url": "/blog/2022/06/16/lm-joint-probability.html",
        "teaser": null
      },{
        "title": "Understanding perplexity and its relation to cross-entropy and compression",
        "excerpt":"Modern conditional and unconditional language models often report their perplexity as validation metrics.   Let’s see what it means intuitively and how it connects to other important measures of information theory such as cross entropy or compression.   Definition of perplexity   The perplexity of a sequence of observation is defined as:   $\\displaystyle \\mathcal{P} = P(x_1, x_2, … , x_N) ^ {- \\frac{1}{N}}$   Mathematically, it is the reciprocal of the probability of this sequence to appear in natural language, nornalised so that the number of elements in the sequence does not push this probability to zero as we add more terms (and consequently push the perplexity to infinity as we add more terms).   Back-ground on language models   Language models are trained to model the probability distribution of the next word in the sentence given the previous ones:   $P(x_N | x_{N-1}, …, x_1)$   We call such models auto-regressive. These models are elequant for at least two reasons. The first one is that we can easily sample from them to produce a sentence (write english, code, cooking recipes, etc).   The second is that their formulation corresponds to a specific decomposition of the joint probability of the sequence, which follows directly from the chain rule of probability, and always holds true:   $P(x_1, x_2, … , x_N) = \\prod P(x_i | x_{i-1}, …, x_1)$   To train these model we use the standard cross entropy loss, written as so:   $\\mathcal{C} = - \\frac{1}{N} \\sum P(x_i | x_{i-1}, …, x_1)$   Which we can identify as the $\\log$ of the joint probability of the sequence. Elequant!   Connecting perplexity to cross entropy   As mentionned above, language models (conditional or not) are typically trained with cross entropy. Let see how perplexity is connected to this cross-entropy.   First, recall the definition the perplexity:   $\\displaystyle \\mathcal{P} = P(x_1, x_2, … , x_N) ^ {- \\frac{1}{N}}$   Now, let’s take the log of the perplexity:   $\\displaystyle \\log \\mathcal{P} = \\log P(x_1, x_2, … , x_N) ^ {- \\frac{1}{N}} = - \\frac{1}{N} \\log P(x_1, x_2, … , x_N)$   Next we can decompose the joint probability of the sequence with the chain rule of probability, the same decomposition used in auto-regressive models:   $\\displaystyle \\log \\mathcal{P} = - \\frac{1}{N} \\log \\prod P(x_i | x_{i-1}, …, x_1) = - \\frac{1}{N} \\sum \\log P(x_i | x_{i-1}, …, x_1)$   We recognize here the auto-regressive cross entropy objective. Hence the perplexity is the exponential of the cross entropy of the language model.   Ok, but what does it mean?   In terms of distance   The cross-entropy of a given sequence is a mesure of how far this sequence is from the probablity distribution modelled by the language model (*).   The bigger the cross entropy is, the further away the sequence being tested is from being generated by the language model.   Since the exponential is monotonously increasing, the same holds for the perplexity. The higher the perplexity the worse the language model is at modelling the sequence being evaluted.   Note that this does not directly judge the quality of the sentences being generated by the language model. This is a very important point.   The language model could generate perfectly correct sentences, syntactically perfect and meaningful, and still get a very high perplexity. One extreme example is when the model only generates a single sentence. Its perplexity would be infinite on any other sentence.   (*) In truth, the cross entropy is a measure of distance between two probability distributions, but we take this shortcut here for simplicity.   In terms of choice   Say there is only a single word in our language. The perplexity of the sequence containing this single word would be 1.   $\\displaystyle \\mathcal{P} = P(x_1) ^ {- \\frac{1}{1}} = \\frac{1}{P(x_1)} = \\frac{1}{1.0} = 1$   If the vocabulary had two words equally probable the perplexity of one of those words would be 2.   $\\displaystyle \\mathcal{P} = P(x_1) ^ {- \\frac{1}{1}} = \\frac{1}{P(x_1)} = \\frac{1}{0.5} = 2$   Intuitively, the perplexity of a sentence corresponds to the average numbers of samples the language models would have to draw per word in order to generate this sentence. Or said differently, the average of the number of choices the language would have faced at each word in order to generate this sentence.   The higher this number, the less likely the language model would have to been to generate the given sentence. Again, note the inversion: we don’t judge the quality of generated text by the language model as much as the generality of the language model.   In terms of information content and compression   The cross-entropy of a given sequence is a mesure of how many bits are needed in order to encode this sentence given the probability distribution defined by the language model.   The higher the cross entropy is (equivalently the higher the perplexity is), the less the sentence can be compressed by the language model.   In this sense, perplexity and cross-entropy are a measure of compressibility of natural language text under the probability distribution defined by the language model.   A perfect language model would be able to compress natural language with the least amout of bits, thanks to its perfect modelling of the joint probability distribution of language.  ","categories": ["machine-learning"],
        "tags": ["machine-learning","maths"],
        "url": "/blog/2022/06/19/perplexity.html",
        "teaser": null
      },{
        "title": "Statistical gender bias",
        "excerpt":"I recently stumbled on a debate where Jordan B. Peterson argues, based on a statistical argument, that the gender pay gap is mostly not due to gender bias. Let’s see what’s wrong with this statistical argument.   The argument as I understood it   The host interviewing Jordan B. Peterson intially mentions around minute 5:55 that the gender pay gap in the UK is around 9% between men and women (women are payed 9% less).   Jordan B. Peterson answers that the gap this is not due to gender bias alone. To him, gender bias is only one of the causes and does only account for a fraction of the gender pay gap (minute 7:21).   He argues that, although there definitely a 9% pay gap between men and women, concluding this is only due to gender bias is too simplisitic. He argues that we need to perform a multi-variate analysis (with more than just 2 factors pay and gender) and look at the influence of the different factors.   He then affirms that if we do this, we can see that the other factors (which are correlated with behing a woman) explain this pay gap and that the gender bias itself only explain a fraction of the pay gap.   He takes the example of the agreable-ness personality trait, which encompasses being compassionate and polite. His argument is that because women are more agreeable, they are not asking for pay raise as often as men do, and are getting a lower wages in the end. He estimates this accounts for 5% of the pay gap.   He concludes that traits such as agreable-ness are causes of the gender pay gap, perhaps more so that the gender bias itself, which he thinks is actually much less than 9%.   Does this argument makes sense from a statistical point of view?   Asked different, to the extreme where the multivariate analysis would show that 100% of the pay gap can be “explained” by the “agreable” trait, would that means that gender bias does not exist?   What’s wrong with the argument?   The issue with the argument lies with the multi-variate analysis itself. What kind of analysis is being done is undefined in this talk but we might presume some kind of multivariate linear regression. Whatever the analysis itself, let’s see why it cannot help conclude that gender bias is not the core issue.   “Explain” does not mean “cause”   Statistical models can only tell you about correlation and not causation. In addition to that, statistically models will usually pick on the “simplest explanation” based on their expressiveness (their representational power).   Here is one typical example that is often used in Machine Learning communities, camel and cows:      Camels are most often photographed with a desert background   Cows are most often photographed with a grass background   Because it is very easy to discriminate on background colors and texture rather than shape, typical machine learning algorithms will “explain” the cow-ness or camel-ness of the photo (the observation) based on the background.   Does that means that, even if cows are always on grass and camel always in the desert, that the background determines the animal? Of course not! But statistical techniques will unfortunately pick up on that: when you present them with a cow in the desert, most models will likely answer “camel”.   An arbitrary causal model   To make claims like Jordan B. Peterson does, you need a causal model. Here is the causal model that Jordan B. Peterson proposes during the debate, consisting of two factors:      “Gender” between 0 and 1 (both included): 0 means being looking 100% masculine, and 1 means looking 100% feminine.   “Agreeable” between 0 and 1 (both included): 0 means not being agreable at all and 1 means being 100% agreable.      In short, gender influence being agreable-ness. Both factors influence the pay.   But causal models like this cannot be tested by just observational data. You would need something like interventions to test the model: for instance modify the agreable-ness of a person and measure the influence of the pay.   Without such intervention, this causal model has no more value than any causal model that we could propose (adding / deleting / inversing arrows, etc).   To see why, let’s propose a different model.   Radically different models can fit the same data   Here is a different causal model than the one proposed by Jordan B. Peterson. In this causal diagram, the agreable-ness is a side effect of the gender that has no direct influence on the pay:      Now, what’s interesting is that both causal diagrams displayed until now are completely undistinguishable with just observational data. Let’s show this by plugging some numbers in those causal diagrams:       Diagram 1: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $a = 0.2 + 0.8 g$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $p = 1 - 0.1 a - 0.1 g$          Diagram 2: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $a = 0.2 + 0.8 g$ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $p = 0.98 - 0.18 g$      Put whatever number you want as gender $g$ and we get the same values for agreeable-ness $a$ and pay $p$.   In other words, you could learn the coefficient of one model even if the data was generated from the other model, and fit both models perfectly to the same observational data.   Those two models are thus basically undistinguishable with just observational data… but lead to very different conclusions!   Time makes conclusion even more complex   Everything we discussed so far is in the context of static models: the causal model is unchanged as time passes. But change is the only constant: things are even more complex in practice!   We know for certainty that gender bias was huge just a few decades ago: plenty of countries did not even gave vote to women before the second world war… It is very likely that this gender bias persists through education and is behind the agreeable-ness between a trait more associated to women.   Here is one possible way it happened: women were seen as inferior as men and educated to be agreeable to men because they were taught men were superior. And now, the prejudice against women, abolished by law, is hidden behind the numbers on the diagram 1 above.   If that’s the case, the causal diagram today may look like Jordan B. Peterson causal diagram, but the main cause of gender pay gap remains gender bias: the factor behind the arrows might just be a matter of gender biased education.   The conclusion is in the eyes of the beholder   When dealing with observational data, causality is not achievable. In the absence of interventions, it is impossible to distinguish against multiple causal diagrams with just data.   In such instances, interpretation such as the one Jordan B. Peterson draws, are not strongly supported: they might agree with the data, but agreeing with the data is not enough as other models will do as well.   In such cases, any conclusion we make based on the data actually only shows our own preconceptions on what the causal model should be (we might be blinded by our own convictions, or prefer one conclusion to another) and does not make our conclusion valid.  ","categories": ["random-rambling"],
        "tags": ["random-rambling","maths"],
        "url": "/blog/2022/09/05/statistical-gender-bias.html",
        "teaser": null
      }]
